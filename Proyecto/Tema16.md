# Tema 16. PROYECTO FINAL: APLICACIÃ“N COMPLETA BASADA EN MICROSERVICIOS CON FASTAPI

* [Tema 16. PROYECTO FINAL: APLICACIÃ“N COMPLETA BASADA EN MICROSERVICIOS CON FASTAPI](Tema16.md#tema-16-proyecto-final-aplicaciÃ³n-completa-basada-en-microservicios-con-fastapi)

    * [16.1 DefiniciÃ³n de dominio y bounded contexts](Tema16.md#161-definiciÃ³n-de-dominio-y-bounded-contexts)
    * [16.2 DivisiÃ³n en microservicios independientes](Tema16.md#162-divisiÃ³n-en-microservicios-independientes)
    * [16.3 Contratos REST, eventos y gRPC entre servicios](Tema16.md#163-contratos-rest-eventos-y-grpc-entre-servicios)
    * [16.4 DDD + arquitectura hexagonal en cada servicio](Tema16.md#164-ddd--arquitectura-hexagonal-en-cada-servicio)
    * [16.5 Desarrollo de API Gateway y orquestador de eventos](Tema16.md#165-desarrollo-de-api-gateway-y-orquestador-de-eventos)
    * [16.6 IntegraciÃ³n de DB relacional y no relacional](Tema16.md#166-integraciÃ³n-de-db-relacional-y-no-relacional)
    * [16.7 Seguridad, validaciÃ³n y pruebas completas](Tema16.md#167-seguridad-validaciÃ³n-y-pruebas-completas)
    * [16.8 Colas con Kafka y WebSockets para real-time](Tema16.md#168-colas-con-kafka-y-websockets-para-real-time)
    * [16.9 Despliegue automatizado con CI/CD en Kubernetes](Tema16.md#169-despliegue-automatizado-con-cicd-en-kubernetes)
    * [16.10 DocumentaciÃ³n y repositorio versionado](Tema16.md#1610-documentaciÃ³n-y-repositorio-versionado)


## 16.1 DefiniciÃ³n de dominio y bounded contexts

Este es el momento de cristalizar todo lo aprendido en un proyecto cohesivo. Siguiendo tu directriz, no nos extenderemos en teorÃ­a abstracta, sino que **plantearemos un proyecto con una idea actual y describiremos cÃ³mo se abordarÃ­a cada punto de este tema dentro de ese proyecto**.

El proyecto se desarrollarÃ¡ conceptualmente con **Python 3.12, FastAPI y MariaDB** como base relacional, pero incorporaremos otros servicios y tecnologÃ­as segÃºn sea necesario para ilustrar una arquitectura de `microservices` moderna y completa.

**Nombre del Proyecto Propuesto:** ðŸ…¿ï¸ **ParkWise - Smart Urban Parking Platform**

**VisiÃ³n del Proyecto ParkWise:**\
Una plataforma integral que conecta a conductores que buscan estacionamiento con proveedores de espacios (particulares, garajes comerciales), optimizando el uso del espacio urbano, facilitando reservas, pagos, y ofreciendo `features` en tiempo real como disponibilidad y notificaciones. IncluirÃ¡ soporte para `EV charging spots` y potencial para `dynamic pricing`.

Comencemos a desglosar ParkWise a travÃ©s de los puntos del Tema 16.

***

Para el proyecto **ParkWise**, el primer paso es sumergirnos en su dominio y delimitar sus fronteras conceptuales mediante `Bounded Contexts`, un concepto clave de `Domain-Driven Design (DDD)`. Esto nos ayudarÃ¡ a entender las diferentes partes del problema y a sentar las bases para una divisiÃ³n lÃ³gica en `microservices`.

**A. Dominio Principal de ParkWise:**

El **dominio central** de ParkWise gira en torno a la **gestiÃ³n eficiente y la intermediaciÃ³n de espacios de estacionamiento urbano**. Su objetivo es resolver los problemas de:

* **Conductores (`Drivers`):** Encontrar y reservar estacionamiento de forma fÃ¡cil y fiable, accediendo a informaciÃ³n en tiempo real sobre disponibilidad y precio.
* **Proveedores de Estacionamiento (`Providers`):** Maximizar la utilizaciÃ³n de sus espacios (ya sean privados, comerciales o pÃºblicos gestionados), gestionar listados, precios y recibir pagos de forma segura.
* **La Plataforma ParkWise:** Facilitar esta interacciÃ³n, asegurar la confianza, gestionar transacciones y proveer valor aÃ±adido (como `smart features`, notificaciones, analÃ­ticas).

Las `core capabilities` incluirÃ¡n:

* BÃºsqueda geoespacial de `parking spots`.
* VisualizaciÃ³n de disponibilidad en tiempo real.
* Sistema de reservas y `booking management`.
* Procesamiento de pagos y `payouts`.
* GestiÃ³n de perfiles de `users` (`drivers` y `providers`).
* Notificaciones instantÃ¡neas.
* Soporte para caracterÃ­sticas especiales como `EV charging spots` y potencial para `dynamic pricing` basado en demanda u hora.

**B. `Bounded Contexts` Identificados para ParkWise:**

Un `Bounded Context` es un lÃ­mite conceptual dentro del cual un modelo de dominio particular es consistente y aplicable. Para ParkWise, podemos identificar los siguientes `Bounded Contexts` iniciales:

1. **ðŸ‘¤ Identity & Access Management (IAM) Context:**
   * **Responsabilidades:** GestiÃ³n de `users` (conductores, proveedores, administradores de la plataforma), `authentication` (registro, `login`, `logout`), `authorization` (roles, `permissions`), gestiÃ³n de perfiles de `user`.
   * **Lenguaje Ubicuo (`Ubiquitous Language`) Clave:** `User`, `DriverProfile`, `ProviderProfile`, `Role`, `Permission`, `Credential`, `AuthToken`.
   * **LÃ³gica Central:** ValidaciÃ³n de credenciales, gestiÃ³n de `sessions` o `tokens`, asignaciÃ³n de `roles`.
2. **ðŸ…¿ï¸ Parking Spot & Availability Context:**
   * **Responsabilidades:** GestiÃ³n del inventario de `parking spots` por parte de los `Providers`. Esto incluye la creaciÃ³n y actualizaciÃ³n de listados de `spots` (ubicaciÃ³n, tamaÃ±o, tipo - regular, `EV charging`, cubierto, etc.), definiciÃ³n de reglas de precios base, y, crucialmente, la gestiÃ³n de su **disponibilidad en tiempo real**.
   * **Lenguaje Ubicuo Clave:** `ParkingSpot`, `Location` (GeoJSON), `AvailabilitySlot`, `PricingRule`, `SpotType` (EV, Handicap), `ProviderListing`.
   * **LÃ³gica Central:** Algoritmos de actualizaciÃ³n de disponibilidad, validaciÃ³n de datos de `spots`, gestiÃ³n de `amenities`.
3. **ðŸ“… Booking & Reservation Context:**
   * **Responsabilidades:** Manejar el proceso completo de reserva de un `parking spot` por un `Driver`. Esto incluye la bÃºsqueda de `spots` disponibles (posiblemente interactuando con el `Parking Spot Context`), la creaciÃ³n de una reserva para un horario especÃ­fico, la gestiÃ³n del ciclo de vida de la reserva (`PENDING`, `CONFIRMED`, `ACTIVE`, `COMPLETED`, `CANCELLED`), y el manejo de modificaciones o cancelaciones.
   * **Lenguaje Ubicuo Clave:** `Booking`, `ReservationRequest`, `TimeSlot`, `BookingStatus`, `CancellationPolicy`.
   * **LÃ³gica Central:** LÃ³gica de validaciÃ³n de reservas (ej. no `double booking`), aplicaciÃ³n de polÃ­ticas de cancelaciÃ³n, cÃ¡lculo de costes preliminares.
4. **ðŸ’³ Payment & Billing Context:**
   * **Responsabilidades:** Procesar los pagos de los `Drivers` por las reservas, gestionar los `payouts` a los `Providers`, manejar facturas, reembolsos y disputas. IntegraciÃ³n con `payment gateways` externos.
   * **Lenguaje Ubicuo Clave:** `Payment`, `Transaction`, `Invoice`, `Refund`, `Payout`, `PaymentMethod`, `GatewayResponse`.
   * **LÃ³gica Central:** InteracciÃ³n segura con `payment gateways`, cÃ¡lculo de comisiones, seguimiento de transacciones financieras.
5. **ðŸ“£ Notification Context:**
   * **Responsabilidades:** Enviar comunicaciones proactivas a los `users` sobre eventos importantes.
   * **Lenguaje Ubicuo Clave:** `Notification`, `NotificationChannel` (Email, SMS, `WebSocket Push`), `NotificationTemplate`, `UserPreferences` (para notificaciones).
   * **LÃ³gica Central:** `Templating` de mensajes, enrutamiento a travÃ©s de diferentes `channels`, gestiÃ³n de intentos de entrega, respeto de las preferencias del `user`. (Este `context` podrÃ­a evolucionar a un `Notification Microservice` dedicado, como vimos en 10.6).
6. **ðŸŒŸ Review & Rating Context:**
   * **Responsabilidades:** Permitir a los `Drivers` calificar y escribir reseÃ±as sobre los `parking spots` y/o `Providers` despuÃ©s de una reserva completada. Permitir a los `Providers` ver sus calificaciones.
   * **Lenguaje Ubicuo Clave:** `Review`, `RatingScore`, `Comment`, `ReviewableEntity` (Spot, Provider).
   * **LÃ³gica Central:** ValidaciÃ³n de reseÃ±as, cÃ¡lculo de puntuaciones promedio, moderaciÃ³n (opcional).
7. **(Futuro Potencial) ðŸ“ˆ Analytics & Reporting Context:**
   * **Responsabilidades:** Recopilar datos de los otros `contexts` para generar informes y analÃ­ticas para los `Providers` (ej. ocupaciÃ³n, ingresos) y para los administradores de la plataforma ParkWise (ej. crecimiento de `users`, `revenue streams`, `patterns` de uso).
   * **Lenguaje Ubicuo Clave:** `Report`, `Metric`, `DataPoint`, `AnalyticsDashboard`.
   * **LÃ³gica Central:** AgregaciÃ³n de datos, generaciÃ³n de informes, `data visualization APIs`.

**Diagrama de `Bounded Contexts` de ParkWise (Simplificado):**

```mermaid
graph TD
    subgraph ParkWise_Platform
        IAM[Identity and Access Management Context]
        PSA[Parking Spot and Availability Context]
        BRC[Booking and Reservation Context]
        PBC[Payment and Billing Context]
        NC[Notification Context]
        RRC[Review and Rating Context]
        ARC[Analytics and Reporting Context - Futuro]

        DriverUser[Driver - Usuario]
        ProviderUser[Provider - Usuario]
        AdminUser[Admin - Usuario]

        DriverUser --> IAM
        ProviderUser --> IAM
        AdminUser --> IAM

        ProviderUser --> PSA
        DriverUser -->|Busca disponibilidad| PSA
        
        DriverUser -->|Reserva| BRC
        BRC -->|Consulta disponibilidad| PSA
        BRC -->|Consulta usuario| IAM
        
        BRC -->|Inicia pago| PBC
        PBC -->|Consulta usuario| IAM
        
        PBC -->|Notifica resultado| NC
        BRC -->|Notifica estado| NC
        PSA -->|Notifica disponibilidad| NC
        NC -->|Notifica a| DriverUser
        NC -->|Notifica a| ProviderUser
        
        DriverUser -->|Escribe reseÃ±a| RRC
        RRC -->|Relacionado con| PSA
        ProviderUser -->|Lee reseÃ±as| RRC

        PSA --> ARC
        BRC --> ARC
        PBC --> ARC
        ARC --> AdminUser
    end

    style IAM fill:#D5F5E3,stroke:#2ECC71
    style PSA fill:#AED6F1,stroke:#3498DB
    style BRC fill:#FAD7A0,stroke:#F39C12
    style PBC fill:#FFCDD2,stroke:#C62828
    style NC fill:#E8DAEF,stroke:#8E44AD
    style RRC fill:#FFF9C4,stroke:#F1C40F
    style ARC fill:#CFD8DC,stroke:#37474F


```

**Consideraciones Adicionales:**

* **EvoluciÃ³n:** Estos `bounded contexts` pueden evolucionar. Algunos podrÃ­an subdividirse mÃ¡s a medida que la complejidad crece. Por ejemplo, la "GestiÃ³n de Precios" dentro de `Parking Spot & Availability` podrÃ­a volverse lo suficientemente compleja (con `dynamic pricing`, reglas promocionales) como para justificar su propio `bounded context` (y `microservice`).
* **SuperposiciÃ³n y ComunicaciÃ³n:** Aunque los `bounded contexts` buscan el desacoplamiento, inevitablemente necesitan comunicarse. Esto se gestionarÃ¡ a travÃ©s de APIs bien definidas y/o `event-driven architecture` (que veremos en 16.3).

Esta definiciÃ³n inicial del dominio y sus `bounded contexts` nos da un marco sÃ³lido para empezar a pensar en la divisiÃ³n en `microservices` (16.2) y los contratos entre ellos. Es un ejercicio iterativo; a medida que profundicemos en cada aspecto del proyecto, podrÃ­amos refinar estos lÃ­mites.



## 16.2 DivisiÃ³n en microservicios independientes



La meta aquÃ­ es traducir cada `bounded context` (o un grupo coherente de ellos) en un `microservice` con responsabilidades claras y lÃ­mites bien definidos.



BasÃ¡ndonos en los `Bounded Contexts` identificados para **ParkWise** en la secciÃ³n 16.1, proponemos la siguiente divisiÃ³n inicial en `microservices` independientes. Cada servicio serÃ¡ responsable de su propio dominio de datos y lÃ³gica de negocio, exponiendo sus capacidades a travÃ©s de APIs.

1. **`Identity Service` (Basado en IAM Context)**
   * **Responsabilidades Principales:**
     * GestiÃ³n de `user accounts` (`drivers`, `providers`, `admins`).
     * `Authentication` (`user registration`, `login`, `token issuance` - ej. `JWT`).
     * `Authorization` bÃ¡sica (gestiÃ³n de `roles` y `permissions`).
     * GestiÃ³n de perfiles de `user` (datos bÃ¡sicos, preferencias de contacto no relacionadas con notificaciones especÃ­ficas).
   * **`Database` Propia:** MariaDB (para `user credentials`, perfiles, `roles`).
   * **API Expuesta:** `Endpoints` para `register`, `login`, `get_user_profile`, `update_profile`, gestiÃ³n de `roles` (para `admins`).
2. **`Parking Lot Service` (Basado en Parking Spot & Availability Context)**
   * **Responsabilidades Principales:**
     * GestiÃ³n del `inventory` de `parking spots` por parte de los `Providers`.
     * CreaciÃ³n, actualizaciÃ³n, y eliminaciÃ³n de `listings` de `spots` (ubicaciÃ³n `GeoJSON`, tamaÃ±o, tipo - regular, `EV charging`, cubierto, `amenities`).
     * GestiÃ³n de la disponibilidad de `spots` en tiempo real (marcar como `disponible/ocupado/reservado`, `bloqueos temporales`).
     * DefiniciÃ³n de `pricing rules` base asociadas a los `spots` o `lots`.
   * **`Database` Propia:**
     * MariaDB para datos estructurales de `spots` y `providers`.
     * (Potencial) Redis para `tracking` de disponibilidad en tiempo real de alta velocidad y/o MongoDB para `GeoJSON queries` si MariaDB no es suficiente.
   * **API Expuesta:** `Endpoints` para `providers` para gestionar sus `spots`, `endpoints` para buscar `spots` (con filtros geoespaciales, por tipo, etc.), `endpoints` para actualizar disponibilidad (puede ser interno o llamado por otros servicios).
3. **`Booking Service` (Basado en Booking & Reservation Context)**
   * **Responsabilidades Principales:**
     * Orquestar el proceso de reserva: buscar `spots` disponibles (interactuando con `Parking Lot Service`), validar la solicitud de reserva.
     * Crear y gestionar el ciclo de vida de las reservas (`PENDING_PAYMENT`, `CONFIRMED`, `ACTIVE`, `COMPLETED`, `CANCELLED`).
     * Aplicar polÃ­ticas de cancelaciÃ³n y modificaciÃ³n.
     * Calcular costes de reserva.
   * **`Database` Propia:** MariaDB (para `bookings`, `reservation details`, `status history`).
   * **API Expuesta:** `Endpoints` para `drivers` para crear y gestionar sus reservas, `endpoints` para `providers` para ver las reservas de sus `spots`.
4. **`Payment Service` (Basado en Payment & Billing Context)**
   * **Responsabilidades Principales:**
     * IntegraciÃ³n con `external payment gateways` (Stripe, PayPal, etc.).
     * Procesar pagos para reservas.
     * Gestionar reembolsos.
     * Orquestar `payouts` a los `Providers`.
     * GeneraciÃ³n de `invoices` (simplificado inicialmente).
   * **`Database` Propia:** MariaDB (para `transaction records`, `payment status`, `payout records`).
   * **API Expuesta:** `Endpoints` internos para ser llamados por `Booking Service` para iniciar pagos, `endpoints` para manejar `webhooks` de `payment gateways`, `endpoints` para `providers` para ver su historial de `payouts`.
5. **`Notification Service` (Basado en Notification Context)**
   * **Responsabilidades Principales:**
     * Consumir `events` de negocio de otros servicios (ej. `BookingConfirmedEvent`, `PaymentSuccessfulEvent`, `NewSpotAvailableEvent`).
     * Consultar preferencias de notificaciÃ³n del `user` (podrÃ­a interactuar con `Identity Service`).
     * Formatear y enviar notificaciones a travÃ©s de mÃºltiples `channels` (`WebSockets`, Email, SMS - inicialmente `WebSockets` y Email).
   * **`Database` Propia:** MariaDB (para `notification templates`, historial de notificaciones enviadas, `user notification preferences` si no estÃ¡n en `Identity Service`).
   * **API Expuesta:** Principalmente consume `events`. PodrÃ­a tener una API interna para `trigger` notificaciones especÃ­ficas si es necesario, pero el `pattern` principal es `event-driven`.
6. **`Review Service` (Basado en Review & Rating Context)**
   * **Responsabilidades Principales:**
     * Permitir a los `drivers` enviar `reviews` y `ratings` para `parking spots` despuÃ©s de una reserva completada.
     * Calcular `average ratings`.
     * Exponer `reviews` y `ratings`.
     * (Opcional) ModeraciÃ³n de `reviews`.
   * **`Database` Propia:** MariaDB o MongoDB (MongoDB podrÃ­a ser bueno aquÃ­ por la flexibilidad de los `reviews` y `nested comments` si se aÃ±aden). Inicialmente MariaDB.
   * **API Expuesta:** `Endpoints` para crear `reviews`, obtener `reviews` para un `spot` o `provider`.

**Diagrama `Mermaid` de la DivisiÃ³n en `Microservices` para ParkWise:**

```mermaid
graph TD
    APIGW[API Gateway / BFFs]

    subgraph Service Cluster
        IdentitySvc["Identity Service<br/>(MariaDB)"]
        ParkingLotSvc["Parking Lot Service<br/>(MariaDB, opc. Redis/Mongo)"]
        BookingSvc["Booking Service<br/>(MariaDB)"]
        PaymentSvc["Payment Service<br/>(MariaDB)"]
        NotificationSvc["Notification Service<br/>(MariaDB)"]
        ReviewSvc["Review Service<br/>(MariaDB)"]
    end

    APIGW --> IdentitySvc
    APIGW --> ParkingLotSvc
    APIGW --> BookingSvc
    APIGW --> ReviewSvc
    
    BookingSvc -- Llama API / Eventos --> ParkingLotSvc
    BookingSvc -- Llama API / Eventos --> PaymentSvc
    BookingSvc -- Publica Evento --> EventBus[(Event Bus<br/>Kafka/RabbitMQ)]
    PaymentSvc -- Publica Evento --> EventBus
    ParkingLotSvc -- Publica Evento --> EventBus
    ReviewSvc -- Publica Evento --> EventBus 
    IdentitySvc -- Publica Evento UserUpdated --> EventBus

    EventBus --> NotificationSvc

    style IdentitySvc fill:#82E0AA,stroke:#1E8449
    style ParkingLotSvc fill:#AED6F1,stroke:#3498DB
    style BookingSvc fill:#FAD7A0,stroke:#F39C12
    style PaymentSvc fill:#FFCDD2,stroke:#C62828
    style NotificationSvc fill:#E8DAEF,stroke:#8E44AD
    style ReviewSvc fill:#FFF9C4,stroke:#F1C40F
    style APIGW fill:#D6DBDF,stroke:#2C3E50
    style EventBus fill:#E5E7E9,stroke:#5D6D7E
```

**Consideraciones Clave para esta DivisiÃ³n:**

* **AutonomÃ­a:** Cada servicio gestiona su propio `schema` de base de datos y puede ser desplegado y escalado independientemente.
* **ComunicaciÃ³n:**
  * **SÃ­ncrona (API Calls):** En algunos casos, un servicio podrÃ­a necesitar llamar a la API de otro directamente para obtener informaciÃ³n que necesita _inmediatamente_ para completar una operaciÃ³n (ej. `Booking Service` podrÃ­a consultar la disponibilidad en `Parking Lot Service`). Esto debe usarse con moderaciÃ³n para evitar acoplamiento fuerte.
  * **AsÃ­ncrona (`Event-Driven`):** Para la mayorÃ­a de las interacciones de "reacciÃ³n" y para desacoplar servicios, se usarÃ¡ un `Event Bus` (Kafka o RabbitMQ). Cuando un servicio completa una acciÃ³n significativa, publica un `event`. Otros servicios interesados se suscriben a estos `events`. (MÃ¡s en 16.3 y 16.8).
* **`API Gateway`:** Un `API Gateway` (o `Backend-For-Frontend - BFFs`) se situarÃ¡ frente a estos `microservices` para exponer una API unificada y adecuada a los `clients` (web, mÃ³vil). (MÃ¡s en 16.5).
* **EvoluciÃ³n:** Esta es una divisiÃ³n inicial. A medida que ParkWise crezca, algunos servicios podrÃ­an subdividirse mÃ¡s (ej. `Pricing Service` separado) o podrÃ­an surgir nuevos servicios.

Esta divisiÃ³n busca un equilibrio entre cohesiÃ³n (agrupar funcionalidades relacionadas) y desacoplamiento (permitir desarrollo y despliegue independiente).



## 16.3 Contratos REST, eventos y gRPC entre servicios

Vamos directos al **16.3** para el proyecto **ParkWise**. Habiendo definido el dominio, los `bounded contexts` (16.1) y la divisiÃ³n inicial en `microservices` (16.2), ahora es crucial definir **cÃ³mo estos servicios van a "hablar" entre sÃ­ y con el mundo exterior**. Los contratos de comunicaciÃ³n son las reglas del lenguaje que aseguran que la colaboraciÃ³n sea posible y fiable.



En un ecosistema de `microservices` como ParkWise, no existe una Ãºnica forma de comunicaciÃ³n. Se elegirÃ¡ el estilo mÃ¡s adecuado (sÃ­ncrono, asÃ­ncrono, `request/response`, `event-driven`) segÃºn la naturaleza de la interacciÃ³n. Para cada estilo, un **contrato bien definido** es esencial.

**1. Contratos `RESTful API` para ComunicaciÃ³n SÃ­ncrona (Interna y Externa) ðŸ“ž**

* **Uso en ParkWise:**
  * **APIs PÃºblicas (vÃ­a `API Gateway`):** Los `clients` (aplicaciones mÃ³viles, `web frontends`) interactuarÃ¡n con ParkWise principalmente a travÃ©s de `endpoints` RESTful expuestos por un `API Gateway`. Este `gateway` enrutarÃ¡ las peticiones a los `microservices` internos correspondientes.
  * **ComunicaciÃ³n `Service-to-Service` SÃ­ncrona (Selectiva):** En algunos casos donde un servicio necesita una respuesta inmediata de otro para completar su operaciÃ³n.
    * Ejemplo: El `Booking Service`, al intentar crear una reserva, podrÃ­a necesitar consultar en tiempo real al `Parking Lot Service` sobre la disponibilidad exacta de un `spot` especÃ­fico para el `timeslot` solicitado.
    * Otro ejemplo: El `API Gateway` podrÃ­a necesitar obtener detalles del `user` del `Identity Service` antes de procesar una peticiÃ³n.
* **DefiniciÃ³n del Contrato REST para cada `Microservice` ParkWise:**
  * **OpenAPI Specification (Generada por FastAPI):** Cada `microservice` FastAPI (ej. `IdentityService`, `ParkingLotService`, `BookingService`) expondrÃ¡ su propia `OpenAPI specification` (disponible en `/openapi.json`). Este `schema` es el contrato formal.
  *   **Pydantic Models (`DTOs - Data Transfer Objects`):** Como vimos en el Tema 11.3, los modelos Pydantic definirÃ¡n rigurosamente los `schemas` para los `request bodies` y `response models`. Estos son la `source of truth` para la estructura de los datos intercambiados.

      ```python
      # Ejemplo: DTO para solicitar disponibilidad en Parking Lot Service
      # (usado por Booking Service o API Gateway)
      # from pydantic import BaseModel
      # from datetime import datetime

      # class SpotAvailabilityRequest(BaseModel):
      #     spot_id: str
      #     start_time: datetime
      #     end_time: datetime

      # class SpotAvailabilityResponse(BaseModel):
      #     spot_id: str
      #     is_available: bool
      #     estimated_price: Optional[float] = None
      ```
  * **HTTP Methods y `Status Codes`:** Se seguirÃ¡n estrictamente las buenas prÃ¡cticas RESTful (Tema 11.1 y 11.6) para el uso de `GET`, `POST`, `PUT`, `DELETE`, `PATCH`, y los `status codes` apropiados.
  * **Versioning de API (vÃ­a URI Path):** Se usarÃ¡ `versioning` en la URI para gestionar la evoluciÃ³n de los contratos API de cada servicio (ej. `/parking/v1/spots/{spot_id}/availability`). (Tema 11.2).
* **Consideraciones para ParkWise:**
  * Para las llamadas `service-to-service` sÃ­ncronas, se utilizarÃ¡n `HTTP clients` asÃ­ncronos (como `httpx`) dentro de los servicios FastAPI para no bloquear el `event loop`.
  * Se implementarÃ¡n patrones de resiliencia como `retries` (con `exponential backoff`) y `circuit breakers` (ej. usando librerÃ­as como `pybreaker` o `resilience4j`-like patterns) para estas llamadas internas.

**2. Contratos de `Events` para Desacoplamiento y Flujos AsÃ­ncronos ðŸ“£**

La comunicaciÃ³n `event-driven` serÃ¡ la espina dorsal para el desacoplamiento y la reactividad en ParkWise, utilizando **Kafka** como `message broker` principal (como se anticipa en 16.8).

* **Uso en ParkWise (ComunicaciÃ³n AsÃ­ncrona Primaria):**
  * `IdentityService` publica `UserRegisteredEvent`, `UserProfileUpdatedEvent`.
  * `ParkingLotService` publica `ParkingSpotListedEvent`, `ParkingSpotUpdatedEvent`, `ParkingSpotAvailabilityChangedEvent`.
  * `BookingService` publica `BookingRequestedEvent`, `BookingConfirmedEvent`, `BookingCancelledEvent`, `BookingCompletedEvent`.
  * `PaymentService` publica `PaymentProcessedEvent`, `PaymentFailedEvent`, `PayoutInitiatedEvent`.
  * `ReviewService` publica `ReviewSubmittedEvent`.
  * El `NotificationService` serÃ¡ un consumidor clave de muchos de estos `events` para informar a los `users`. Otros servicios tambiÃ©n se suscribirÃ¡n a los `events` relevantes para mantener su propio `state` o `trigger` lÃ³gica de negocio.
* **DefiniciÃ³n del Contrato de `Event`:**
  *   **`Event Schema` (Pydantic Models):** Cada tipo de `event` se definirÃ¡ con un modelo Pydantic, asegurando una estructura clara y validable.

      ```python
      # from pydantic import BaseModel, Field
      # from typing import List, Dict, Any, Literal
      # from uuid import UUID, uuid4
      # from datetime import datetime, timezone

      # class EventMetadata(BaseModel):
      #     event_id: UUID = Field(default_factory=uuid4)
      #     event_type: str # El nombre del tipo de evento, ej. "BookingConfirmed"
      #     event_version: str = "1.0"
      #     timestamp: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
      #     source_service: str # Nombre del servicio que originÃ³ el evento
      #     correlation_id: Optional[UUID] = None

      # class BookingConfirmedEventPayload(BaseModel):
      #     booking_id: str
      #     user_id: str
      #     spot_id: str
      #     start_time: datetime
      #     end_time: datetime
      #     total_price: float

      # class BookingConfirmedEvent(BaseModel):
      #     metadata: EventMetadata
      #     payload: BookingConfirmedEventPayload
      ```
  * **SerializaciÃ³n:** Los `events` se serializarÃ¡n a **`JSON`** para su publicaciÃ³n en Kafka.
  * **`Broker` (Kafka):**
    * **`Topics`:** Se definirÃ¡n `topics` Kafka bien nombrados y con una granularidad adecuada (ej. `parkwise.booking.events`, `parkwise.parking.events`, `parkwise.user.events`). Se podrÃ­a considerar un `topic` por `aggregate type` o por `bounded context`.
    * **`Message Keys`:** Se usarÃ¡n `keys` apropiadas en los mensajes Kafka (ej. `booking_id`, `spot_id`, `user_id`) para asegurar que los `events` relacionados con la misma `entity` vayan a la misma `partition` (garantizando el orden para esa `entity`).
  * **Versioning de `Events`:**
    * El `field` `event_version` en `EventMetadata` es crucial.
    * Se necesitarÃ¡n estrategias para la evoluciÃ³n del `schema` de `events` (ej. `upcasting` de `events` antiguos, consumidores que pueden manejar mÃºltiples versiones, o un `schema registry` como Confluent Schema Registry si se usa Avro/Protobuf en lugar de JSON para `payloads` mÃ¡s complejos y con `schema evolution` robusta).
* **Consideraciones para ParkWise:**
  * Todos los `event consumers` _deben_ ser idempotentes (14.7).
  * Se configurarÃ¡n `Dead Letter Topics (DLTs)` en Kafka para manejar `events` que no se pueden procesar.
  * La trazabilidad (`correlation_id` propagado a travÃ©s de `events`) serÃ¡ fundamental.

**3. Contratos `gRPC` para ComunicaciÃ³n Interna de Alto Rendimiento (Uso Selectivo y Avanzado) ðŸš€**

`gRPC` (Google Remote Procedure Call) podrÃ­a considerarse para interacciones `service-to-service` internas muy especÃ­ficas donde el rendimiento (baja latencia, alto `throughput`) y un contrato fuertemente tipado son primordiales, y la sobrecarga de HTTP/JSON de REST es significativa.

* **Uso Potencial en ParkWise (Ejemplos Especulativos):**
  * Si el `Parking Lot Service` necesita proveer un `stream` de `updates` de disponibilidad de `spots` de muy alta frecuencia a un `Booking Service` (o a un `caching layer` especializado que el `Booking Service` consulta), `gRPC streaming` podrÃ­a ser una opciÃ³n.
  * Llamadas internas entre un `API Gateway` y un `microservice` en una `hot path` si se demuestra que REST es un cuello de botella.
* **DefiniciÃ³n del Contrato (`.proto` files):**
  *   Los servicios, mÃ©todos `RPC`, y `message types` (equivalentes a `DTOs`) se definen usando **`Protocol Buffers`**.

      ```protobuf
      // Ejemplo: parking_spot_availability.proto
      // syntax = "proto3";

      // package parkwise.parking.v1; // Namespace

      // service ParkingSpotAvailabilityService {
      //   // Un RPC para obtener el estado de mÃºltiples spots de una vez
      //   rpc GetSpotsAvailability(SpotsAvailabilityRequest) returns (SpotsAvailabilityResponse);
      //   // Un RPC para un stream de updates (mÃ¡s avanzado)
      //   rpc SubscribeToSpotUpdates(SpotUpdateRequest) returns (stream SpotAvailabilityStreamItem);
      // }

      // message SpotAvailabilityRequest {
      //   repeated string spot_ids = 1;
      // }

      // message SpotAvailability {
      //   string spot_id = 1;
      //   bool is_available = 2;
      //   int64 last_updated_utc_timestamp = 3;
      // }

      // message SpotsAvailabilityResponse {
      //   repeated SpotAvailability spots = 1;
      // }

      // message SpotUpdateRequest {
      //   string spot_id = 1;
      // }
      // message SpotAvailabilityStreamItem {
      //    SpotAvailability spot_update = 1;
      // }
      ```
  * A partir de estos archivos `.proto`, se genera cÃ³digo `stub` (tanto para el `client` como para el `server`) en Python usando el compilador `protoc` y los `plugins` de `gRPC` para Python. FastAPI puede integrarse con `servers` `gRPC` (ej. el `server` `gRPC` corre junto a FastAPI, o FastAPI llama a `clients` `gRPC`).
* **Consideraciones para ParkWise:**
  * **Complejidad:** `gRPC` y `Protocol Buffers` aÃ±aden una nueva tecnologÃ­a al `stack` y tienen su propia curva de aprendizaje.
  * **Tooling:** Requiere `protoc` y gestiÃ³n de los `stubs` generados.
  * **No `Browser-Friendly` Directo:** La comunicaciÃ³n directa desde un `browser` a un `endpoint` `gRPC` generalmente requiere un `proxy` como `gRPC-Web`.
  * **DecisiÃ³n:** Para ParkWise, `gRPC` se considerarÃ­a **solo para `hot paths` internos muy especÃ­ficos** despuÃ©s de un `profiling` que demuestre que REST/eventos son un cuello de botella significativo. La prioridad inicial serÃ¡ REST y `events` sobre Kafka.

**Tabla Resumen: Estilos de ComunicaciÃ³n y Contratos en ParkWise**

| Estilo de ComunicaciÃ³n   | Protocolo Principal        | Formato de Datos ComÃºn | DefiniciÃ³n de Contrato Principal                                    | Casos de Uso Clave en ParkWise                                                                                                                                        |
| ------------------------ | -------------------------- | ---------------------- | ------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **`REST API`**           | HTTP/1.1, HTTP/2           | `JSON`                 | OpenAPI `Spec` (generada por FastAPI desde Pydantic `DTOs`)         | ExposiciÃ³n de `capabilities` a `clients` externos (vÃ­a `API Gateway`); algunas llamadas `service-to-service` sÃ­ncronas (ej. consulta de disponibilidad).              |
| **`Events` (AsÃ­ncrono)** | Kafka Protocol (sobre TCP) | `JSON` (inicialmente)  | `Schema` de `Event` (Pydantic `models`), `Topic Naming Conventions` | Desacoplamiento mÃ¡ximo, `broadcast` de cambios de estado, `trigger` de `workflows` asÃ­ncronos, notificaciones (ej. `BookingConfirmedEvent`, `PaymentProcessedEvent`). |
| **`gRPC` (Opcional)**    | HTTP/2                     | `Protocol Buffers`     | Archivos `.proto`                                                   | (Especulativo/Avanzado) ComunicaciÃ³n interna `service-to-service` de muy baja latencia o `streaming` para `hot paths` especÃ­ficos.                                    |

**ConclusiÃ³n: Estableciendo el Lenguaje ComÃºn para una ColaboraciÃ³n Fluida entre `Microservices`**

La elecciÃ³n del estilo de comunicaciÃ³n y la definiciÃ³n rigurosa de sus contratos son decisiones arquitectÃ³nicas fundamentales en ParkWise. Una mezcla pragmÃ¡tica serÃ¡ la clave:

* **REST APIs** (definidas con OpenAPI/Pydantic) para la mayorÃ­a de las interacciones sÃ­ncronas y la exposiciÃ³n externa.
* **`Events` sobre Kafka** (definidos con Pydantic/JSON) como el mecanismo principal para la comunicaciÃ³n asÃ­ncrona, el desacoplamiento y la resiliencia.
* **`gRPC`** se mantendrÃ¡ como una opciÃ³n especializada a considerar solo si surgen requisitos de rendimiento interno extremo que no puedan ser satisfechos por los otros dos.

Esta estrategia multi-modal, con contratos claros para cada modo, permitirÃ¡ que los `microservices` de ParkWise colaboren eficazmente mientras mantienen su autonomÃ­a.

***

## 16.4 DDD + arquitectura hexagonal en cada servicio

Si el 16.3 definiÃ³ _cÃ³mo_ se comunican nuestros `microservices` de ParkWise, el **16.4** se sumerge en _cÃ³mo estructuramos internamente cada uno de esos `microservices`_. Para construir servicios que sean robustos, mantenibles y evolucionables, aplicaremos los principios de **`Domain-Driven Design (DDD)`** y la **Arquitectura Hexagonal (tambiÃ©n conocida como `Ports and Adapters`)**.

Imagina cada `microservice` no como una simple caja negra, sino como una fortaleza bien diseÃ±ada: un nÃºcleo de lÃ³gica de negocio invaluable, protegido del mundo exterior por murallas (la arquitectura hexagonal) y hablando un lenguaje preciso y especializado (el `ubiquitous language` de DDD).

***

Para cada `microservice` identificado en ParkWise (Identity, Parking Lot, Booking, Payment, Notification, Review), adoptaremos un enfoque interno que priorice la claridad del dominio y el desacoplamiento de la infraestructura.

**1. `Domain-Driven Design (DDD)` en el CorazÃ³n de Cada `Microservice` ParkWise â¤ï¸**

Dentro de los lÃ­mites de cada `microservice` (que ya se alinean con nuestros `Bounded Contexts` de 16.1), aplicaremos los patrones tÃ¡cticos de DDD:

* **`Ubiquitous Language` EspecÃ­fico del `Bounded Context`:**
  * El `Booking Service` hablarÃ¡ de `Bookings`, `TimeSlots`, `ReservationStatus`.
  * El `Parking Lot Service` hablarÃ¡ de `ParkingSpots`, `Availability`, `GeoCoordinates`, `Amenities`.
  * Este lenguaje se reflejarÃ¡ en los nombres de clases, mÃ©todos y variables dentro del `core` de cada servicio.
* **Modelado con `Entities`, `Value Objects`, y `Aggregates`:**
  * **`Entities`:** Objetos con una identidad que persiste a lo largo del tiempo y pueden cambiar de estado (ej. una `Booking` especÃ­fica, un `ParkingSpot` especÃ­fico). En SQLAlchemy, estos serÃ¡n nuestras clases ORM (como `ProductDB` en 13.1).
  * **`Value Objects`:** Objetos inmutables definidos por sus atributos, sin una identidad conceptual (ej. un `TimeSlot` con `start_time` y `end_time`, una `Money` `value object` con `amount` y `currency`, una `GeoCoordinate`).
  * **`Aggregates`:** Un clÃºster de `entities` y `value objects` relacionados que se tratan como una Ãºnica unidad de consistencia transaccional. Tienen una raÃ­z (`Aggregate Root`) que es la Ãºnica `entity` del `aggregate` a la que se puede hacer referencia desde el exterior.
    * **`BookingService`:** `Booking` podrÃ­a ser un `Aggregate Root`, conteniendo `BookingItem` `entities` (si un `booking` puede tener mÃºltiples `spots` o `services` asociados) y `TimeSlot` `value objects`. Todas las operaciones que modifican un `booking` pasarÃ­an a travÃ©s del `Booking aggregate root`.
    * **`ParkingLotService`:** `ParkingSpot` serÃ­a un `Aggregate Root`.
    * **`IdentityService`:** `User` serÃ­a un `Aggregate Root`.
* **`Domain Events` Internos:**
  * Cuando un `Aggregate` cambia de estado debido a una operaciÃ³n de negocio, genera `Domain Events` para seÃ±alar ese cambio. Estos son `events` _internos_ al servicio, que describen algo que ya ha sucedido.
  * Ejemplo: El mÃ©todo `confirm_booking()` en el `Booking Aggregate` podrÃ­a generar un `BookingConfirmedDomainEvent`.
  * Estos `domain events` pueden ser luego usados por la capa de aplicaciÃ³n para desencadenar lÃ³gica adicional o ser traducidos a `integration events` para otros `microservices` (como vimos en 16.3).
* **`Repositories` (Interfaces Definidas por el Dominio/AplicaciÃ³n):**
  * El dominio define cÃ³mo necesita persistir y recuperar sus `Aggregates`, a travÃ©s de interfaces de `Repository` (ej. `IBookingRepository`). La implementaciÃ³n concreta (SQLAlchemy, Motor) reside en la capa de infraestructura. (Como vimos en 13.3).
* **`Domain Services`:**
  * Para lÃ³gica de dominio que no encaja naturalmente en una `Entity` o `Aggregate` (ej. un `PricingCalculationService` que involucra mÃºltiples `entities` o reglas complejas).

**2. Arquitectura Hexagonal (`Ports and Adapters`) por `Microservice` ðŸ°**

Esta arquitectura protege nuestro `domain model` y `application logic` (el hexÃ¡gono) de las dependencias de la infraestructura (bases de datos, `message brokers`, APIs externas, `frameworks` web).

* **El HexÃ¡gono (NÃºcleo del `Microservice`):**
  * Contiene el **`Domain Model`** (las `Entities`, `Aggregates`, `Value Objects`, `Domain Events`, `Domain Services` de DDD).
  * Contiene los **`Application Services`** (o `Use Case Handlers`): Orquestan los `use cases`, interactuando con los `Aggregates` del dominio y los `Repositories`. Esta capa es el punto de entrada principal al `core logic`.
  * **Importante:** El cÃ³digo aquÃ­ es puro Python, sin referencias a FastAPI, SQLAlchemy, Kafka, etc.
* **Puertos (`Ports` - Interfaces Definidas por el NÃºcleo):**\
  Son las "puertas" y "enchufes" del hexÃ¡gono. Son interfaces (ej. `Python Protocols` o `ABCs`).
  *   **`Driving Ports` (Puertos de Entrada / `Use Case Interfaces`):**\
      Definen cÃ³mo el mundo exterior invoca la lÃ³gica del nÃºcleo. Son las APIs que exponen los `Application Services`.

      ```python
      # Ejemplo para el BookingService: application/ports/input/booking_use_cases.py
      from typing import Protocol, Optional # NecesitarÃ­amos DTOs definidos tambiÃ©n
      # from ..dtos import BookingRequestDTO, BookingDetailsDTO # (DTOs de la capa de aplicaciÃ³n)

      class ICreateBookingUseCase(Protocol):
          async def execute(self, user_id: str, request_data: "BookingRequestDTO") -> "BookingDetailsDTO":
              ...

      class ICancelBookingUseCase(Protocol):
          async def execute(self, user_id: str, booking_id: str) -> None:
              ...
      ```
  *   **`Driven Ports` (Puertos de Salida / Interfaces de Infraestructura):**\
      Definen lo que el nÃºcleo necesita del mundo exterior (abstracciones de infraestructura).

      ```python
      # Ejemplo para el BookingService: domain/ports/output/booking_repository.py
      # from ..aggregates.booking_aggregate import BookingAggregate # El Aggregate de dominio
      # from typing import Optional, Protocol

      class IBookingRepository(Protocol):
          async def save(self, booking: "BookingAggregate") -> None: ...
          async def get_by_id(self, booking_id: str) -> Optional["BookingAggregate"]: ...
          # ... otros mÃ©todos necesarios ...

      # Ejemplo: domain/ports/output/event_publisher.py
      # from ..events import DomainEvent # Clase base para eventos de dominio

      class IEventPublisher(Protocol):
          async def publish(self, domain_event: "DomainEvent") -> None: ...
      ```
* **Adaptadores (`Adapters` - En la Capa de Infraestructura, fuera del HexÃ¡gono):**\
  Son las implementaciones concretas de los `Ports`, conectando el nÃºcleo con tecnologÃ­as especÃ­ficas.
  * **`Driving Adapters` (Invocan los `Input Ports` del NÃºcleo):**
    * **Controladores FastAPI REST:** Convierten `HTTP requests` (validados con Pydantic `DTOs` de API) en llamadas a los mÃ©todos de las `Use Case Interfaces` (`ICreateBookingUseCase.execute(...)`).
    * **`Handlers`** **`WebSocket` FastAPI:** Convierten `messages` `WebSocket` en llamadas a `Use Case Interfaces`.
    * **Consumidores de Kafka/RabbitMQ:** Toman `messages` del `broker`, los deserializan y los mapean a llamadas a `Use Case Interfaces`.
  * **`Driven Adapters` (Implementan los `Output Ports` que el NÃºcleleo Necesita):**
    * **Repositorios SQLAlchemy/Motor:** Clases que implementan `IBookingRepository` usando `AsyncSession` para interactuar con MariaDB o MongoDB.
    * **Publicadores de Eventos Kafka/RabbitMQ:** Clases que implementan `IEventPublisher` para tomar `Domain Events` (o `Integration Events` derivados de ellos) y publicarlos en el `message broker`.
    * **Clientes HTTP/gRPC:** Si el `BookingService` necesita llamar, por ejemplo, al `ParkingLotService` de forma sÃ­ncrona, podrÃ­a hacerlo a travÃ©s de un `Port` como `IParkingLotQueryPort`, y habrÃ­a un `ParkingLotHttpClientAdapter` que implementarÃ­a este `port` haciendo una llamada HTTP real.

**3. Estructura de Directorios Sugerida para un `Microservice` ParkWise (ej. `BookingService`):**\
Esta estructura busca reflejar la separaciÃ³n hexagonal.

```
booking_service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py             # FastAPI app setup, lifespan events, DI para adaptadores
â”‚   â”œâ”€â”€ core/               # ConfiguraciÃ³n global del servicio, settings
â”‚   â”‚   â””â”€â”€ config.py
â”‚   â”‚
â”‚   â”œâ”€â”€ domain/             # EL CORAZÃ“N: LÃ³gica y modelos de dominio puros
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ aggregates/     # ej. booking_aggregate.py (clase Booking)
â”‚   â”‚   â”œâ”€â”€ entities/       # Si hay entities que no son aggregate roots
â”‚   â”‚   â”œâ”€â”€ value_objects/  # ej. time_slot.py, money.py
â”‚   â”‚   â”œâ”€â”€ domain_services/ # LÃ³gica de dominio que no encaja en un aggregate
â”‚   â”‚   â”œâ”€â”€ events.py       # Definiciones de Domain Events (ej. BookingConfirmedDomainEvent)
â”‚   â”‚   â””â”€â”€ ports/          # --- PUERTOS DE SALIDA (Interfaces que el dominio necesita) ---
â”‚   â”‚       â””â”€â”€ output/
â”‚   â”‚           â”œâ”€â”€ __init__.py
â”‚   â”‚           â”œâ”€â”€ booking_repository.py  (Define IBookingRepository)
â”‚   â”‚           â””â”€â”€ event_publisher.py     (Define IEventPublisher)
â”‚   â”‚
â”‚   â”œâ”€â”€ application/        # Orquesta el dominio, implementa casos de uso
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ use_cases/      # Implementaciones concretas de los casos de uso
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ create_booking_use_case.py (Implementa ICreateBookingUseCase)
â”‚   â”‚   â”œâ”€â”€ services.py     # (Opcional) Application services si son distintos a los use cases
â”‚   â”‚   â””â”€â”€ ports/          # --- PUERTOS DE ENTRADA (Interfaces de los casos de uso) ---
â”‚   â”‚       â””â”€â”€ input/
â”‚   â”‚           â”œâ”€â”€ __init__.py
â”‚   â”‚           â””â”€â”€ booking_use_cases.py (Define ICreateBookingUseCase, etc.)
â”‚   â”‚   â””â”€â”€ dtos.py         # DTOs usados por los casos de uso (internos a la app core, no necesariamente los de API)
â”‚   â”‚
â”‚   â””â”€â”€ infrastructure/     # --- ADAPTADORES e implementaciÃ³n de detalles externos ---
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ api/            # Adaptadores de entrada HTTP y WebSocket (FastAPI routers)
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ v1/
â”‚       â”‚       â”œâ”€â”€ __init__.py
â”‚       â”‚       â””â”€â”€ booking_endpoints.py # Usa ICreateBookingUseCase, etc.
â”‚       â”œâ”€â”€ persistence/    # Adaptadores de salida para persistencia
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ sqlalchemy_booking_repository.py # Implementa IBookingRepository
â”‚       â”œâ”€â”€ messaging/      # Adaptadores para Pub/Sub
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ kafka_event_publisher.py   # Implementa IEventPublisher
â”‚       â”‚   â””â”€â”€ kafka_event_consumers.py # Adaptadores de entrada si consume eventos
â”‚       â””â”€â”€ dependencies.py # ConfiguraciÃ³n de DI de FastAPI para inyectar adaptadores a los endpoints,
                            # y adaptadores de infraestructura a los casos de uso (si aplica).
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â””â”€â”€ application/
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”œâ”€â”€ persistence/
â”‚   â”‚   â””â”€â”€ api/
â”‚   â””â”€â”€ conftest.py
â””â”€â”€ pyproject.toml
```

* **Flujo de Dependencias:** `Infrastructure` depende de `Application` y `Domain`. `Application` depende de `Domain`. **`Domain` no depende de nada mÃ¡s que de sÃ­ mismo (y quizÃ¡s tipos Python estÃ¡ndar).**

**4. Diagrama `Mermaid`: Arquitectura Hexagonal para un `Microservice` ParkWise (ej. `BookingService`)**

```mermaid
graph TD
    subgraph OutsideWorld [Mundo Exterior / Otros Servicios]
        direction LR
        HTTPClient["HTTP Client<br/>(API Gateway / User Browser)"]
        KafkaConsumerTrigger["Kafka Broker<br/>(Eventos de otros servicios)"]
    end

    subgraph BookingMicroservice ["Booking Microservice (HexÃ¡gono)"]
        direction LR
        
        subgraph Adapters_Infra ["Capa de Infraestructura (Adaptadores)"]
            direction TB
            FastAPIAdapter["FastAPI REST/WS Adapter<br/>(booking_endpoints.py)"]
            KafkaConsumerAdapter["Kafka Consumer Adapter<br/>(Consumidor de eventos externos)"]
            SQLAlchemyRepoAdapter["SQLAlchemy Booking Repository Adapter<br/>(Implementa IBookingRepository)"]
            KafkaEventPubAdapter["Kafka Event Publisher Adapter<br/>(Implementa IEventPublisher)"]
            ParkingAPIClientAdapter["Parking Service HTTP Client Adapter<br/>(Implementa IParkingQueryPort)"]
        end

        subgraph AppCore ["NÃºcleo de AplicaciÃ³n (Puertos y LÃ³gica)"]
            direction TB
            PortIn_UseCase1["Input Port: ICreateBookingUseCase"]
            PortIn_UseCase2["Input Port: IProcessPaymentUpdateUseCase"]
            
            AppService_UseCaseImpl["Application Services / Use Cases<br/>(Implementan Input Ports, orquestan Dominio)"]
            
            DomainModel["Domain Model (DDD)<br/>BookingAggregate, Domain Events,<br/>Value Objects, Domain Services"]

            PortOut_Repo["Output Port: IBookingRepository"]
            PortOut_EventPub["Output Port: IEventPublisher"]
            PortOut_Parking["Output Port: IParkingLotQueryPort"]
        end
        
        FastAPIAdapter -- Invoca --> PortIn_UseCase1
        KafkaConsumerAdapter -- Invoca --> PortIn_UseCase2

        PortIn_UseCase1 --> AppService_UseCaseImpl
        PortIn_UseCase2 --> AppService_UseCaseImpl
        
        AppService_UseCaseImpl -- Usa --> DomainModel
        AppService_UseCaseImpl -- Usa --> PortOut_Repo
        AppService_UseCaseImpl -- Usa --> PortOut_EventPub
        AppService_UseCaseImpl -- Usa --> PortOut_Parking

        PortOut_Repo -- Es implementado por --> SQLAlchemyRepoAdapter
        PortOut_EventPub -- Es implementado por --> KafkaEventPubAdapter
        PortOut_Parking -- Es implementado por --> ParkingAPIClientAdapter

    end
    
    HTTPClient --> FastAPIAdapter
    KafkaConsumerTrigger --> KafkaConsumerAdapter

    SQLAlchemyRepoAdapter --> MariaDB_Booking[(MariaDB para Booking)]
    KafkaEventPubAdapter --> KafkaBroker_Egress["Kafka Broker (Publica Eventos de Dominio/IntegraciÃ³n)"]
    ParkingAPIClientAdapter --> ParkingServiceAPI_Ext["Parking Lot Service API (Externa)"]

    style DomainModel fill:#E8DAEF,stroke:#8E44AD,stroke-width:3px,color:#000
    style AppService_UseCaseImpl fill:#FAD7A0,stroke:#F39C12,stroke-width:2px
    style Adapters_Infra fill:#D6DBDF,stroke:#2C3E50
```

**5. Beneficios de `DDD` + Hexagonal para Cada `Microservice` ParkWise:**

* **`Microservices` Cohesivos y Enfocados:** Cada servicio tiene un modelo de dominio claro para su `bounded context`.
* **Alta Testabilidad:** El `domain` y `application core` (el hexÃ¡gono) se prueban unitariamente en completo aislamiento, `mockeando` los `output ports`. Los `adapters` se prueban en integraciÃ³n.
* **Flexibilidad TecnolÃ³gica en los `Adapters`:** Puedes cambiar de MariaDB a PostgreSQL (modificando el `repository adapter`) o de Kafka a RabbitMQ (modificando el `event publisher/consumer adapter`) con un impacto mÃ­nimo en el `core business logic`.
* **Mantenibilidad y EvoluciÃ³n:** La clara separaciÃ³n de incumbencias facilita entender, modificar y extender cada `microservice` de forma independiente.
* **Resiliencia:** Un `adapter` fallido (ej. no se puede conectar a Kafka) no deberÃ­a corromper la lÃ³gica de `domain` (aunque el `use case` podrÃ­a fallar y necesitar lÃ³gica de compensaciÃ³n).

**ConclusiÃ³n: Construyendo Fortalezas de LÃ³gica Interna â€“ `DDD` y Hexagonal Como Escudo y Espada**

Aplicar los principios de `Domain-Driven Design` y la Arquitectura Hexagonal _dentro_ de cada `microservice` de ParkWise es una inversiÃ³n estratÃ©gica. Asegura que, aunque el sistema general es distribuido y potencialmente complejo, cada componente individual es:

* **Robusto:** Con una lÃ³gica de negocio bien definida y protegida.
* **Bien Estructurado:** Con claras separaciones entre el dominio, la aplicaciÃ³n y la infraestructura.
* **Adaptable:** Capaz de evolucionar sus tecnologÃ­as de infraestructura sin reescrituras masivas del `core`.

FastAPI se integra perfectamente en este modelo, actuando como un `driving adapter` eficiente para las interacciones HTTP y `WebSocket`, mientras que su sistema de `Dependency Injection` facilita la conexiÃ³n de estos `adapters` con los `ports` de entrada de tu `application core`.



## 16.5 Desarrollo de API Gateway y orquestador de eventos

Avanzamos al **16.5** del proyecto **ParkWise**. Habiendo definido la estructura interna de nuestros `microservices` con DDD y Arquitectura Hexagonal (16.4), ahora necesitamos pensar en cÃ³mo los `clients` externos acceden a nuestro ecosistema y cÃ³mo se coordinan los flujos de negocio mÃ¡s complejos que involucran mÃºltiples servicios, especialmente los asÃ­ncronos.

AquÃ­ es donde entran en juego dos componentes arquitectÃ³nicos clave: el **`API Gateway`** y un concepto que llamaremos **`Event Orchestrator/Processor`** para manejar flujos de `events` sofisticados.

***

En una arquitectura de `microservices` como la de ParkWise, tener docenas de servicios exponiendo sus propias APIs directamente a los `clients` (web, mÃ³viles) puede ser una pesadilla en tÃ©rminos de gestiÃ³n, seguridad y experiencia del `client`. De manera similar, los flujos de negocio que requieren la coordinaciÃ³n de varios `microservices` a travÃ©s de `events` pueden necesitar un punto de inteligencia mÃ¡s allÃ¡ de simples reacciones `publish/subscribe`.

**1. El `API Gateway` de ParkWise: El GuardiÃ¡n y Conserje Principal del Ecosistema ðŸ¤µ**

* **PropÃ³sito y Beneficios en ParkWise:**\
  Un `API Gateway` se situarÃ¡ como el **Ãºnico punto de entrada (`single entry point`)** para todas las peticiones de los `clients` externos a la plataforma ParkWise.
  * **`Request Routing`:** Dirige las peticiones entrantes al `microservice` interno apropiado. Ej: `/api/v1/users/...` va al `IdentityService`, `/api/v1/spots/...` va al `ParkingLotService`.
  * **AbstracciÃ³n y Fachada (`Facade`):** Oculta la complejidad de la arquitectura de `microservices` interna a los `clients`. Los `clients` interactÃºan con una API unificada.
  * **`Authentication` y `Authorization` Centralizadas (o Primer Nivel):** Puede manejar la validaciÃ³n inicial de `tokens` (ej. `JWTs`) y aplicar reglas de `authorization` globales antes de que la peticiÃ³n llegue a un `microservice`. (Ver 11.8).
  * **`Rate Limiting` y `Throttling`:** Protege los servicios `backend` de ser sobrecargados.
  * **`SSL Termination`:** Maneja la terminaciÃ³n SSL/TLS, liberando a los `microservices` internos de esta tarea.
  * **`Request/Response Transformation`:** Puede adaptar `payloads` o `headers` si es necesario.
  * **`Caching` de Respuestas Comunes:** Puede cachear respuestas de `endpoints` frecuentemente accedidos.
  * **`Logging` y `Tracing` Centralizados:** Un punto ideal para loguear todas las peticiones entrantes e iniciar `distributed traces`.
  * **`Backend-For-Frontend (BFF)` (Opcional):** El `API Gateway` podrÃ­a incluso tener variantes especÃ­ficas para diferentes tipos de `clients` (ej. un `Mobile BFF`, un `WebApp BFF`), cada uno exponiendo una API optimizada para las necesidades de ese `frontend`, agregando o adaptando datos de mÃºltiples `microservices`.
* **ImplementaciÃ³n Conceptual para ParkWise:**
  * **TecnologÃ­a:** Para mantener la coherencia con nuestro `stack` y para fines didÃ¡cticos, podrÃ­amos conceptualizar el `API Gateway` de ParkWise como **una aplicaciÃ³n FastAPI dedicada**. Esta `app` FastAPI no contendrÃ­a lÃ³gica de negocio `core`, sino que su principal funciÃ³n serÃ­a enrutar, autenticar y posiblemente transformar peticiones a los otros `microservices` ParkWise (usando un `HTTP client` asÃ­ncrono como `httpx`).
  * En un escenario de producciÃ³n a gran escala, se podrÃ­a optar por soluciones de `API Gateway` gestionadas o `software` especializado: Kong, Tyk, AWS API Gateway, Google Cloud API Gateway, Azure API Management, NGINX Plus, Envoy.
  *   **Rutas Ejemplo en el `FastAPI Gateway`:**

      ```
      /gateway/v1/auth/...                 -> IdentityService (para login, register)
      /gateway/v1/users/me                 -> IdentityService 
      /gateway/v1/parking-spots/search     -> ParkingLotService
      /gateway/v1/parking-spots/{spot_id}  -> ParkingLotService
      /gateway/v1/providers/spots/...      -> ParkingLotService (para gestiÃ³n de providers)
      /gateway/v1/bookings/                -> BookingService
      /gateway/v1/payments/process         -> PaymentService
      /gateway/v1/reviews/spot/{spot_id}   -> ReviewService
      ```
* **Diagrama : `API Gateway` en ParkWise**

**2. El "Orquestador de `Events`" (`Event Orchestrator/Processor`) de ParkWise: Dirigiendo Procesos AsÃ­ncronos Complejos ðŸŽ­**

El tÃ©rmino "orquestador de `events`" puede ser un poco ambiguo. No nos referimos al `message broker` (Kafka/RabbitMQ) en sÃ­ mismo, sino a un **componente lÃ³gico o servicio dedicado** que implementa flujos de negocio mÃ¡s complejos que se desencadenan por `events` y que pueden involucrar mÃºltiples pasos o la coordinaciÃ³n de varios `microservices` de forma asÃ­ncrona.

* **Clarificando el Rol en ParkWise:**
  * **No es simple `Pub/Sub` reactivo:** Va mÃ¡s allÃ¡ de que un servicio simplemente reaccione a un `event` de otro.
  * **GestiÃ³n de `Workflows`** **`Event-Driven`:** Si un `event` inicia un proceso de negocio que requiere una secuencia especÃ­fica de acciones en otros servicios, o decisiones basadas en los resultados de pasos intermedios (todo de forma asÃ­ncrona).
  * **Sagas Orquestadas (como en 13.5):** Si optamos por el patrÃ³n de `Saga` orquestada para ciertas transacciones distribuidas (ej. un proceso de `onboarding` de `provider` muy complejo), el orquestador de la `Saga` serÃ­a un ejemplo de este componente.
  * **Procesamiento Complejo de `Events` (`Complex Event Processing - CEP`):** Consumir mÃºltiples `streams` de `events`, correlacionarlos, detectar `patterns` y generar `events` de nivel superior o `trigger` acciones.
* **ImplementaciÃ³n Conceptual para ParkWise:**
  * PodrÃ­a ser un **`microservice` Python dedicado** (posiblemente usando FastAPI para una API de gestiÃ³n interna si es necesario, o simplemente un consumidor robusto de Kafka/RabbitMQ).
  * Este servicio se suscribirÃ­a a `events` de negocio clave de otros `microservices` de ParkWise.
  * Su lÃ³gica interna implementarÃ­a la "coreografÃ­a inteligente" o la "orquestaciÃ³n" del `workflow`.
* **Ejemplo de Flujo Orquestado/Procesado en ParkWise: "Provider Onboarding & Spot Verification"**
  1. `IdentityService` publica `ProviderRegisteredEvent`.
  2. Un `ProviderOnboardingOrchestrator` consume `ProviderRegisteredEvent`.
  3. `Orchestrator` emite un `Command` (o `event`) para el (futuro) `VerificationService` para iniciar la verificaciÃ³n de documentos del `provider`.
  4. `ParkingLotService` publica `InitialSpotListingPendingReviewEvent` cuando un nuevo `provider` lista su primer `spot`.
  5. El `ProviderOnboardingOrchestrator` consume este `event`.
  6. Si la verificaciÃ³n del `provider` (del paso 3) ya fue exitosa, el `Orchestrator` emite un `Command` al `ParkingLotService` para `ApproveSpotListingCommand`.
  7. Si no, espera o maneja el flujo.
  8. Una vez que el `provider` y el primer `spot` estÃ¡n aprobados, el `Orchestrator` podrÃ­a emitir un `ProviderFullyOnboardedEvent` que el `NotificationService` usa para enviar un email de bienvenida completo.
* **Diagrama `Mermaid`: `Event Orchestrator/Processor` Conceptual en ParkWise**

**TecnologÃ­as para Implementar el `API Gateway` y el `Event Orchestrator/Processor` en ParkWise:**

* **`API Gateway`:**
  * **FastAPI mismo:** Para un `gateway` ligero o `BFF`, una `app` FastAPI puede actuar como `proxy` y orquestador de llamadas sÃ­ncronas, usando `httpx` para comunicarse con los `microservices` `backend`.
  * **Soluciones Dedicadas:** Para necesidades mÃ¡s avanzadas (gestiÃ³n de trÃ¡fico sofisticada, `plugins` de seguridad, `analytics` de API), se considerarÃ­a: Kong, Tyk, NGINX Plus, Envoy, o servicios `cloud` (AWS API Gateway, Azure API Management, Google Cloud API Gateway).
  * **Para ParkWise (enfoque didÃ¡ctico):** Conceptualizaremos que una o mÃ¡s `FastAPI applications` pueden tomar el rol de `gateway` o `BFF`.
* **`Event Orchestrator/Processor`:**
  * Un **`microservice` Python/FastAPI** que consume de Kafka (usando `aiokafka`) es una opciÃ³n viable y consistente con el `stack`.
  * Para procesamiento de `streams` mÃ¡s complejos o `stateful`: **Kafka Streams**, **Apache Flink**, o librerÃ­as Python como **Faust**.
  * Para `workflow orchestration` de larga duraciÃ³n con estado explÃ­cito, `retries` y `timeouts` complejos: **Temporal.io**, **Camunda Platform**.
  * **Para ParkWise (enfoque didÃ¡ctico):** Se modelarÃ¡ como un consumidor Kafka (Python/`aiokafka`) con lÃ³gica de decisiÃ³n que puede emitir nuevos `events` o `commands`.

**ConclusiÃ³n: Puntos Centrales de Control para un Ecosistema Coherente y Escalable**

El `API Gateway` y un `Event Orchestrator/Processor` son componentes arquitectÃ³nicos que aportan orden y eficiencia a un sistema de `microservices` como ParkWise.

* El **`API Gateway`** actÃºa como el embajador y protector de tu sistema de cara al mundo exterior, simplificando la interacciÃ³n del `client` y centralizando incumbencias transversales.
* El **`Event Orchestrator/Processor`** (o la lÃ³gica de orquestaciÃ³n distribuida en ciertos `consumers`) permite implementar `workflows` de negocio asÃ­ncronos mÃ¡s sofisticados que una simple cadena de `events`, asegurando que procesos complejos se completen correctamente.

Ambos ayudan a gestionar la complejidad inherente a las arquitecturas distribuidas, permitiendo que ParkWise escale, evolucione y mantenga una alta calidad de servicio.

***

### 16.6 IntegraciÃ³n de DB relacional y no relacional

La idea es mostrar cÃ³mo diferentes `microservices` de ParkWise pueden elegir la tecnologÃ­a de base de datos que mejor se adapte a sus necesidades (`polyglot persistence`), y cÃ³mo `Docker Compose` facilita tener estas bases de datos funcionando localmente para el desarrollo y las pruebas de integraciÃ³n.

***

En ParkWise, no todos los `microservices` tendrÃ¡n las mismas necesidades de persistencia de datos. Algunos se beneficiarÃ¡n de la estructura y las garantÃ­as ACID de una base de datos relacional (MariaDB serÃ¡ nuestra elecciÃ³n principal aquÃ­), mientras que otros podrÃ­an requerir la flexibilidad o las capacidades de `query` especÃ­ficas de una base de datos NoSQL (como MongoDB o Redis). Esto es la **persistencia polÃ­glota (`polyglot persistence`)**.

`Docker Compose` es nuestro aliado para simular este entorno diverso localmente desde el inicio del proyecto.

**1. ElecciÃ³n de `Datastores` por `Microservice` en ParkWise (Ejemplos):**

* **`Identity Service`:**
  * **Necesidades:** Almacenar `user profiles`, credenciales `hashed`, `roles`, `permissions`. Relaciones claras entre `users` y `roles`.
  * **ElecciÃ³n:** **MariaDB**. Ideal por su naturaleza transaccional y estructurada para estos datos crÃ­ticos.
  * **TecnologÃ­a de Acceso:** SQLAlchemy ORM (como en 13.1).
* **`Parking Lot Service`:**
  * **Necesidades:**
    * Datos estructurales de `parking spots` (ID, `provider_id`, direcciÃ³n, tipo, `amenities` base).
    * InformaciÃ³n geoespacial (`GeoJSON` para ubicaciÃ³n) para bÃºsquedas por proximidad.
    * GestiÃ³n de disponibilidad en tiempo real (podrÃ­a ser muy intensivo en escrituras/lecturas).
  * **ElecciÃ³n:**
    * **MariaDB:** Para los datos estructurales y relacionales.
    * **(OpciÃ³n A) MariaDB con `GIS extensions`:** Para `queries` geoespaciales.
    * **(OpciÃ³n B) MongoDB:** Si las `queries` geoespaciales son muy complejas o si los atributos de los `spots` varÃ­an enormemente, MongoDB podrÃ­a ser una mejor opciÃ³n para la parte de "catÃ¡logo" de `spots`.
    * **(OpciÃ³n C) Redis:** Para el `tracking` de disponibilidad en tiempo real de `spots` individuales (ej. contadores o `sets` para `available/occupied spots`). Esto reduce la carga en la base de datos principal para `updates` muy frecuentes.
  * **TecnologÃ­a de Acceso:** SQLAlchemy (MariaDB), `Motor` (MongoDB), `aioredis` (Redis).
  * _Para mantener la simplicidad inicial del proyecto con MariaDB como base, nos enfocaremos en MariaDB con sus capacidades GIS para `Parking Lot Service`, y mencionaremos Redis como un `cache/real-time store` opcional._
* **`Booking Service`:**
  * **Necesidades:** Almacenar reservas, sus `status`, `timeslots`, relaciÃ³n con `users` y `spots`. Transacciones importantes.
  * **ElecciÃ³n:** **MariaDB**. Ideal por las relaciones y la necesidad de consistencia transaccional.
  * **TecnologÃ­a de Acceso:** SQLAlchemy ORM.
* **`Payment Service`:**
  * **Necesidades:** Registrar `transactions`, `payment status`, `payouts`. Alta consistencia y auditorÃ­a.
  * **ElecciÃ³n:** **MariaDB**.
  * **TecnologÃ­a de Acceso:** SQLAlchemy ORM.
* **`Notification Service`:**
  * **Necesidades:** Almacenar `notification templates`, historial de notificaciones (opcional), `user notification preferences`.
  * **ElecciÃ³n:** **MariaDB** (para `templates` y preferencias). El historial podrÃ­a ir a una NoSQL si el volumen es masivo, pero empezamos con MariaDB.
  * **TecnologÃ­a de Acceso:** SQLAlchemy ORM.
* **`Review Service`:**
  * **Necesidades:** Almacenar `reviews` (texto), `ratings` (numÃ©rico), relaciÃ³n con `users` y `spots`. Potencial para `nested comments` o estructuras flexibles.
  * **ElecciÃ³n:** **MongoDB** podrÃ­a ser una buena opciÃ³n aquÃ­ por la flexibilidad del contenido de las `reviews` y las estructuras anidadas. Alternativamente, MariaDB con `JSON fields` o una estructura relacional simple.
  * **TecnologÃ­a de Acceso:** `Motor` (MongoDB) o SQLAlchemy (MariaDB).
  * _Para el proyecto, decidimos usar **MongoDB** para el `Review Service` para ilustrar la persistencia polÃ­glota._

**2. ConfiguraciÃ³n en `docker-compose.yml` para Soportar MÃºltiples `Datastores`:**

Nuestro archivo `docker-compose.yml` (como el que empezamos a esbozar en 15.3) se expandirÃ­a para incluir estos `datastores`.

```yaml
# docker-compose.yml (extracto relevante para datastores)
version: '3.8' # O la versiÃ³n que estÃ©s usando

services:
  # --- Microservice: Identity Service (Usa MariaDB) ---
  identity_service:
    build: ./identity_service # Asume Dockerfile en ese directorio
    ports:
      - "8001:8000"
    environment:
      - DATABASE_URL=mysql+aiomysql://parkwise_user:parkwise_pass@mariadb_identity:3306/identity_db 
      # (aiomysql es el driver async para MariaDB/MySQL con SQLAlchemy)
    depends_on:
      mariadb_identity:
        condition: service_healthy
    networks:
      - parkwise_network

  # --- Microservice: Parking Lot Service (Usa MariaDB, opcionalmente Redis) ---
  parking_lot_service:
    build: ./parking_lot_service
    ports:
      - "8002:8000"
    environment:
      - DATABASE_URL=mysql+aiomysql://parkwise_user:parkwise_pass@mariadb_parking:3306/parking_db
      - REDIS_URL=redis://redis_cache:6379/0
    depends_on:
      mariadb_parking:
        condition: service_healthy
      redis_cache: # Si se usa Redis
        condition: service_started # Redis es rÃ¡pido en iniciar
    networks:
      - parkwise_network

  # --- Microservice: Booking Service (Usa MariaDB) ---
  booking_service:
    build: ./booking_service
    ports:
      - "8003:8000"
    environment:
      - DATABASE_URL=mysql+aiomysql://parkwise_user:parkwise_pass@mariadb_booking:3306/booking_db
    depends_on:
      mariadb_booking:
        condition: service_healthy
    networks:
      - parkwise_network

  # --- Microservice: Review Service (Usa MongoDB) ---
  review_service:
    build: ./review_service
    ports:
      - "8004:8000"
    environment:
      - MONGO_URL=mongodb://mongo_review:27017
      - MONGO_DATABASE_NAME=review_db
    depends_on:
      mongo_review:
        condition: service_started # O un healthcheck mÃ¡s robusto si es necesario
    networks:
      - parkwise_network

  # --- Databases ---
  mariadb_identity:
    image: mariadb:10.11 # Usar una versiÃ³n especÃ­fica
    environment:
      MYSQL_ROOT_PASSWORD: root_password_secure
      MYSQL_DATABASE: identity_db
      MYSQL_USER: parkwise_user
      MYSQL_PASSWORD: parkwise_pass
    volumes:
      - identity_db_data:/var/lib/mysql
    ports: # Exponer solo si necesitas acceso directo desde el host, y con puerto diferente
      - "3301:3306"
    healthcheck:
      test: ["CMD", "mysqladmin" ,"ping", "-h", "localhost", "-u$$MYSQL_USER", "-p$$MYSQL_PASSWORD"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - parkwise_network

  mariadb_parking: # Similar a mariadb_identity, pero para parking_db
    image: mariadb:10.11
    environment:
      MYSQL_ROOT_PASSWORD: root_password_secure
      MYSQL_DATABASE: parking_db
      MYSQL_USER: parkwise_user
      MYSQL_PASSWORD: parkwise_pass
    volumes:
      - parking_db_data:/var/lib/mysql
    ports:
      - "3302:3306"
    healthcheck: # IdÃ©ntico healthcheck
      test: ["CMD", "mysqladmin" ,"ping", "-h", "localhost", "-u$$MYSQL_USER", "-p$$MYSQL_PASSWORD"]
      interval: 10s; timeout: 5s; retries: 5
    networks:
      - parkwise_network

  mariadb_booking: # Similar, para booking_db
    image: mariadb:10.11
    environment:
      MYSQL_ROOT_PASSWORD: root_password_secure
      MYSQL_DATABASE: booking_db
      MYSQL_USER: parkwise_user
      MYSQL_PASSWORD: parkwise_pass
    volumes:
      - booking_db_data:/var/lib/mysql
    ports:
      - "3303:3306"
    healthcheck: # IdÃ©ntico healthcheck
      test: ["CMD", "mysqladmin" ,"ping", "-h", "localhost", "-u$$MYSQL_USER", "-p$$MYSQL_PASSWORD"]
      interval: 10s; timeout: 5s; retries: 5
    networks:
      - parkwise_network
      
  mongo_review:
    image: mongo:6.0 # Usar una versiÃ³n especÃ­fica
    volumes:
      - review_db_data:/data/db
    ports: # Exponer solo si necesitas acceso directo desde el host
      - "27017:27017" 
      # MongoDB tiene un healthcheck mÃ¡s simple por defecto si no se especifica,
      # o se puede aÃ±adir uno con 'mongosh --eval "db.adminCommand("ping")"'
    networks:
      - parkwise_network

  redis_cache: # Si el Parking Lot Service lo usa
    image: redis:7-alpine
    ports:
      - "6379:6379"
    networks:
      - parkwise_network

# Definir volÃºmenes nombrados para persistencia de datos
volumes:
  identity_db_data:
  parking_db_data:
  booking_db_data:
  review_db_data:

# Definir la red compartida
networks:
  parkwise_network:
    driver: bridge
```

**Puntos Clave de esta ConfiguraciÃ³n `Docker Compose`:**

* **Bases de Datos Separadas:** Cada servicio que necesita su propia persistencia tiene una `service definition` para su base de datos (ej. `mariadb_identity`, `mariadb_parking`, `mongo_review`).
* **Nombres de Servicio para ConexiÃ³n:** Los `microservices` se conectan a sus bases de datos usando el nombre del servicio definido en `docker-compose.yml` como el `hostname` (ej. `DATABASE_URL=...@mariadb_identity:3306/...`). Docker Compose maneja la resoluciÃ³n de DNS dentro de la red personalizada `parkwise_network`.
* **`Environment Variables` para ConfiguraciÃ³n:** Las `database URLs`, `usernames`, `passwords` se pasan a los `microservices` y a los `containers` de base de datos a travÃ©s de `environment variables`. (En producciÃ³n, esto se manejarÃ­a con `secrets managers`).
* **`Volumes` para Persistencia:** Se usan `named volumes` (ej. `identity_db_data`) para asegurar que los datos de la base de datos persistan incluso si los `containers` se detienen y se reinician.
* **`Healthchecks`:** Se definen `healthchecks` para las bases de datos MariaDB para que los servicios que dependen de ellas (`depends_on: condition: service_healthy`) esperen hasta que estÃ©n listas antes de arrancar. MongoDB y Redis tambiÃ©n pueden tener `healthchecks`.
* **Red Personalizada (`parkwise_network`):** Todos los servicios estÃ¡n en la misma red `bridge`, lo que facilita la comunicaciÃ³n entre ellos por nombre de servicio.

**3. IntegraciÃ³n en el CÃ³digo del `Microservice` (Recordatorio):**

*   **`IdentityService` (SQLAlchemy):**

    ```python
    # app/core/config.py
    # DATABASE_URL = os.getenv("DATABASE_URL", "mysql+aiomysql://user:pass@localhost:3301/identity_db") 
    # ...
    # app/db/session.py -> usa esta DATABASE_URL para crear el async_engine
    ```
*   **`ReviewService` (`Motor`):**

    ```python
    # app/core/config.py
    # MONGO_URL = os.getenv("MONGO_URL", "mongodb://localhost:27017")
    # MONGO_DATABASE_NAME = os.getenv("MONGO_DATABASE_NAME", "review_db")
    # ...
    # app/db/mongo_db.py -> usa estas variables para crear el AsyncIOMotorClient
    ```

**4. Diagrama `Mermaid`: Persistencia PolÃ­glota en ParkWise con `Docker Compose`**

```mermaid
graph TD
    subgraph "Docker Host (Entorno Local)"
        DC["docker-compose.yml"]

        subgraph "Containers Gestionados por Compose"
            Net[(parkwise_network)]
            
            subgraph IdentityServiceContainer["Identity Service (FastAPI)"]
                IS_App[App Code]
            end
            subgraph ParkingLotServiceContainer["Parking Lot Service (FastAPI)"]
                PLS_App[App Code]
            end
            subgraph ReviewServiceContainer["Review Service (FastAPI)"]
                RS_App[App Code]
            end

            subgraph MariaDB_Identity_Container["mariadb_identity (MariaDB)"]
                MDB_I_Data[(identity_db_data)]
            end
            subgraph MariaDB_Parking_Container["mariadb_parking (MariaDB)"]
                MDB_P_Data[(parking_db_data)]
            end
            subgraph MongoDB_Review_Container["mongo_review (MongoDB)"]
                Mongo_R_Data[(review_db_data)]
            end
            subgraph RedisContainer["redis_cache (Redis)"]
                Redis_Icon[Redis]
            end
            
            IdentityServiceContainer -- "mysql+aiomysql://...@mariadb_identity" --> MariaDB_Identity_Container
            ParkingLotServiceContainer -- "mysql+aiomysql://...@mariadb_parking" --> MariaDB_Parking_Container
            ParkingLotServiceContainer -- "redis://redis_cache..." --> RedisContainer
            ReviewServiceContainer -- "mongodb://mongo_review..." --> MongoDB_Review_Container

            MDB_I_Data -. Montado en .-> MariaDB_Identity_Container
            MDB_P_Data -. Montado en .-> MariaDB_Parking_Container
            Mongo_R_Data -. Montado en .-> MongoDB_Review_Container
            
            Net --- IdentityServiceContainer
            Net --- ParkingLotServiceContainer
            Net --- ReviewServiceContainer
            Net --- MariaDB_Identity_Container
            Net --- MariaDB_Parking_Container
            Net --- MongoDB_Review_Container
            Net --- RedisContainer
        end
        DC -. Define y Orquesta .-> DockerHost
    end
    style DC fill:#FFF9C4,stroke:#F1C40F
```

**ConclusiÃ³n: `Docker Compose` Como Cimiento para la Persistencia PolÃ­glota Local**

Para el proyecto ParkWise, la capacidad de definir y ejecutar localmente un entorno con **mÃºltiples tipos de bases de datos** (`polyglot persistence`) y mÃºltiples instancias de la misma base de datos (una por servicio) es crucial para simular de cerca un entorno de producciÃ³n de `microservices` y para permitir el desarrollo y prueba de la integraciÃ³n de cada servicio con su `datastore` elegido.

`Docker Compose` nos da exactamente eso:

* **Un `stack` de desarrollo completo y reproducible** con un solo comando (`docker compose up`).
* La capacidad de usar **MariaDB para servicios que se benefician de SQL** y **MongoDB para servicios que necesitan flexibilidad de esquema** (como el `ReviewService`).
* La opciÃ³n de aÃ±adir otros `backing services` como Redis fÃ¡cilmente.

Este `setup` local es el primer paso para asegurar que la lÃ³gica de persistencia de cada `microservice` ParkWise (usando SQLAlchemy para MariaDB y `Motor` para MongoDB, como se vio en 13.1 y 13.7) funcione correctamente antes de pasar a `pipelines` CI/CD y despliegues en Kubernetes.



## 16.7 Seguridad, validaciÃ³n y pruebas completas



Para el proyecto **ParkWise**, este punto define las estrategias integrales para asegurar la robustez, fiabilidad y seguridad de la plataforma a travÃ©s de sus `microservices`.

1. **Seguridad (`Security`):**
   * **`Authentication`:**
     * El **`Identity Service`** gestionarÃ¡ la autenticaciÃ³n de `users` (`drivers`, `providers`, `admins`) y `machine-to-machine (M2M)` `clients` (otros servicios).
     * Se utilizarÃ¡n **`JSON Web Tokens (JWT)`** (estÃ¡ndar `RS256` o `ES256`) como `access tokens` y `refresh tokens`.
     * El **`API Gateway`** (16.5) realizarÃ¡ la validaciÃ³n inicial de `JWTs` para peticiones externas. Los `microservices` internos podrÃ¡n revalidar el `token` o confiar en la `authentication` del `gateway` (propagando la identidad del `user` a travÃ©s de `headers` internos seguros o un `context token` simplificado).
     * Se implementarÃ¡ `OAuth2 Password Grant` para el `login` de `users` y `Client Credentials Grant` para `M2M authentication`.
   * **`Authorization`:**
     * Basada en `roles` y `permissions` definidos en el `Identity Service` e incluidos como `claims` en el `JWT`.
     * Cada `microservice` serÃ¡ responsable de aplicar `authorization checks` para sus `endpoints` y `resources` basÃ¡ndose en estos `claims`.
     * Se usarÃ¡n `FastAPI dependencies` para la lÃ³gica de `authorization`.
   * **Seguridad de `Transport`:** `HTTPS/TLS` obligatorio para toda comunicaciÃ³n externa (API Gateway) e interna (`service-to-service`, `WebSocket Secure - WSS`).
   * **Seguridad de `Secrets`:** GestiÃ³n de `secrets` (credenciales de BBDD, `API keys` de terceros, `JWT secrets`) mediante un `secrets manager` (ej. HashiCorp Vault, o los provistos por el `cloud provider` en despliegues K8s).
   * **`Input Validation`:** (Ver abajo).
   * **ProtecciÃ³n contra Vulnerabilidades Comunes OWASP:** Se aplicarÃ¡n las mejores prÃ¡cticas (ej. `rate limiting` en el `gateway`, `headers` de seguridad como `X-Content-Type-Options`, `CSP`, `HSTS`).
2. **ValidaciÃ³n (`Validation`):**
   * **ValidaciÃ³n de `Payloads` de API (Nivel de `Endpoint`):**
     * **Pydantic `models`** se usarÃ¡n exhaustivamente en todos los `endpoints` REST y `WebSocket message handlers` de FastAPI en cada `microservice` para validar la estructura, tipos y `constraints` de los datos de entrada (como en 11.3). Esto incluye `nested models` para `payloads` complejos.
     * FastAPI devolverÃ¡ automÃ¡ticamente errores HTTP `422 Unprocessable Entity` con detalles.
   * **ValidaciÃ³n de Reglas de Negocio (`Business Rule Validation`):**
     * Se realizarÃ¡ dentro de los `Application Services` o `Domain Entities/Aggregates` (como en 16.4).
     * LanzarÃ¡n excepciones de dominio especÃ­ficas que los `adapters` (ej. `API endpoints`) traducirÃ¡n a `HTTP error responses` apropiados (ej. `400 Bad Request`, `409 Conflict`).
   * **ValidaciÃ³n de `Events`:**
     * Los `payloads` de los `events` publicados en Kafka tambiÃ©n se definirÃ¡n y validarÃ¡n con Pydantic `models` (o Avro/Protobuf si se usa un `Schema Registry`) antes de la publicaciÃ³n por el `producer` y al ser consumidos por el `consumer`.
   * **`Database Schema Validation` (MongoDB):**
     * Para el `Review Service` (que usa MongoDB), se definirÃ¡n `JSON Schemas` a nivel de `collection` para los `fields` crÃ­ticos, complementando la validaciÃ³n de Pydantic en la aplicaciÃ³n (como en 13.8).
3. **Pruebas Completas (`Comprehensive Testing`):**\
   Se implementarÃ¡ una estrategia de `testing` multi-capa para ParkWise, automatizada en `CI pipelines` (como en 14.10 y 15.5).
   * **`Unit Tests` (14.2):**
     * Para la lÃ³gica de dominio (`aggregates`, `domain services`), `application services` (`use cases`), y `utility functions` dentro de cada `microservice`.
     * Se usarÃ¡ `pytest` y `unittest.mock` (o `pytest-mock`) para aislar las unidades, `mockeando` dependencias externas (repositorios, otros servicios, `event publishers`).
   * **Pruebas de IntegraciÃ³n (`Integration Tests` - 14.5):**
     * **Nivel de Servicio:** Probar la interacciÃ³n entre los `application services`, `repositories`, y una `test database` temporal (ej. MariaDB/MongoDB en Docker, SQLite `:memory:` para SQLAlchemy en algunos casos).
     * **Nivel de `Endpoint` (Intra-Servicio):** Usar `TestClient` de FastAPI para probar los `endpoints` REST y `WebSocket` de cada `microservice` individualmente, interactuando con su `test database`. Las dependencias de _otros_ `microservices` se `mockearÃ¡n`.
   * **Pruebas de Contrato (`Contract Tests`):**
     * (Opcional, pero recomendado para madurez) Usar herramientas como Pact para verificar que los contratos entre `microservices` (APIs REST, `events`) se cumplen, sin necesidad de un entorno `E2E` completo para cada cambio de contrato.
   * **Pruebas `End-to-End (E2E)` (14.6):**
     * Para `user journeys` crÃ­ticos que abarcan mÃºltiples `microservices` (ej. un `driver` busca un `spot`, reserva, paga, y recibe notificaciÃ³n).
     * Se ejecutarÃ¡n contra un entorno de `staging` o `E2E` dedicado con todos los `microservices` de ParkWise desplegados.
     * UsarÃ¡n clientes HTTP (ej. `httpx`) para interactuar con el `API Gateway` y verificar los resultados y efectos secundarios a travÃ©s de las APIs de los servicios o `event listeners` de prueba.
   * **ValidaciÃ³n de `Events` y `Queues` en `Tests` (14.7):**
     * Pruebas especÃ­ficas para verificar que los `producers` publican los `events` correctos a Kafka y que los `consumers` los procesan correctamente, usando `test topics` y `utility consumers/producers` en los `tests`.
   * **Cobertura de Pruebas (`Code Coverage` - 14.8):**
     * Se medirÃ¡ con `coverage.py` (vÃ­a `pytest-cov`) y se buscarÃ¡ un umbral razonable (ej. >80-85%) para la lÃ³gica crÃ­tica, con informes generados en CI.
   * **Estructura y `Fixtures` (14.9):** Se seguirÃ¡ una estructura de `tests` organizada y se usarÃ¡n `pytest fixtures` extensivamente para `setup/teardown` y datos de prueba.

Este enfoque integral de seguridad, validaciÃ³n y `testing` es fundamental para garantizar que ParkWise sea una plataforma fiable, segura y de alta calidad.



### 16.8 Colas con Kafka y WebSockets para real-time



En el proyecto ParkWise, la comunicaciÃ³n en tiempo real (`real-time`) y los flujos de `events` desacoplados son esenciales. Para esto, **Kafka** serÃ¡ nuestro `message broker` principal para la comunicaciÃ³n asÃ­ncrona entre `microservices` y para alimentar las actualizaciones `real-time` a los `clients` a travÃ©s de **`WebSockets`**. El entorno de desarrollo local se gestionarÃ¡ con **`Docker Compose`**.

1. **Kafka como `Event Backbone` de ParkWise:**
   * **Rol:** Kafka manejarÃ¡ todos los `domain events` y `integration events` significativos publicados por los `microservices` de ParkWise (ej. `ParkingSpotListedEvent`, `BookingConfirmedEvent`, `PaymentProcessedEvent`, `RealtimeAvailabilityUpdate` para un `spot`).
   * **`Topics` Kafka:** Se definirÃ¡n `topics` especÃ­ficos para diferentes tipos de `events` o dominios de negocio, permitiendo a los `microservices` suscribirse solo a los `streams` de `events` que les conciernen.
     * Ejemplos de `Topics`: `parkwise.parking.availability`, `parkwise.booking.lifecycle`, `parkwise.payment.status`, `parkwise.user.notifications`.
   * **`Event Payloads`:** Los `events` publicados en Kafka tendrÃ¡n `payloads` `JSON` bien definidos (validados con Pydantic antes de la publicaciÃ³n y al consumir), incluyendo `metadata` como `event_id`, `timestamp`, `source_service`, y `correlation_id` para trazabilidad.
2. **`WebSockets` para InteracciÃ³n `Real-Time` con `Clients`:**
   * **Casos de Uso en ParkWise:**
     * **Disponibilidad de `Parking Spots`:** Los `clients` (mapas en la app web/mÃ³vil) se suscribirÃ¡n (vÃ­a `WebSocket`) para recibir `updates` en tiempo real sobre la disponibilidad de `spots` en un Ã¡rea o para `spots` especÃ­ficos.
     * **Notificaciones de Reserva:** Confirmaciones, recordatorios, `updates` de estado de una reserva.
     * **Alertas de `Provider`:** Notificaciones a los `providers` sobre nuevas reservas para sus `spots`.
     * **(Futuro) Chat `Provider-Driver`:** Para coordinar llegadas, etc.
   * **GestiÃ³n:** El `Notification Service` (o `FastAPI instances` con capacidad de `gateway WebSocket`) manejarÃ¡ las `WebSocket connections` y la lÃ³gica de `rooms/subscriptions` (como en 10.3 y 10.4).
3. **IntegraciÃ³n Kafka -> `WebSockets` para `Push` de `Events` a `Clients`:**
   * El `Notification Service` (o un componente dedicado dentro de las `FastAPI gateway instances`) actuarÃ¡ como un **consumidor de Kafka** para `topics` relevantes.
   * Cuando el `Notification Service` consume un `event` de Kafka (ej. `ParkingSpotAvailabilityChangedEvent` con `spot_id: "S123", status: "OCCUPIED"`):
     1. Determina quÃ© `WebSocket clients` (o `rooms`) estÃ¡n interesados en este `update` (ej. `clients` visualizando el mapa donde estÃ¡ S123, o `clients` con una reserva activa para S123).
     2. Formatea un `message` `WebSocket` apropiado (ej. `{"type": "SPOT_UPDATE", "spotId": "S123", "status": "OCCUPIED"}`).
     3. Publica este `message` `WebSocket` en el **`WebSocket Pub/Sub Backend`** (Redis, como vimos en 10.4, para `fan-out` a las `FastAPI instances` correctas).
     4. Las `FastAPI instances` con las `WebSocket connections` activas relevantes hacen `push` del `message` a los `clients`.
4. **`Docker Compose` para el Entorno Local de Desarrollo y Pruebas:**\
   El archivo `docker-compose.yml` de ParkWise incluirÃ¡:
   * **Servicio Kafka:**
     * UsarÃ¡ una imagen oficial de Kafka (ej. `confluentinc/cp-kafka` o `bitnami/kafka`).
     * RequerirÃ¡ un servicio **ZooKeeper** (para versiones de Kafka que lo necesiten) o se configurarÃ¡ en modo **KRaft** (para versiones mÃ¡s nuevas de Kafka que eliminan la dependencia de ZooKeeper). Para simplicidad en un entorno local, una configuraciÃ³n Kafka + ZooKeeper es comÃºn, o una imagen "todo-en-uno" si existe y es estable.
     * Se definirÃ¡n variables de entorno para configurar los `brokers`, `topics` por defecto (o se crearÃ¡n mediante `scripts` de inicializaciÃ³n o por los `producers/consumers` al arrancar).
   * **`Microservices` FastAPI (`Producers` y `Consumers` de Kafka):**
     * Cada `microservice` (Identity, Parking Lot, Booking, Payment, Notification, Review) tendrÃ¡ su propia `service definition` en `Docker Compose`.
     * Se les pasarÃ¡n las URLs del `broker` Kafka y los nombres de los `topics` a travÃ©s de `environment variables`.
     * Los `microservices` que actÃºen como `WebSocket gateways` (o el `Notification Service` si es separado) tambiÃ©n tendrÃ¡n la configuraciÃ³n para el `WebSocket Pub/Sub Backend` (ej. URL de Redis).
   * **Redis (para `WebSocket Pub/Sub Backend` y `Caching` opcional):**
     * Un servicio Redis.
   * **Bases de Datos (MariaDB, MongoDB):**
     * Como se definiÃ³ en 13.9 y 16.6, cada `microservice` con persistencia propia tendrÃ¡ su `container` de base de datos o se conectarÃ¡ a uno compartido para su `bounded context`.
   *   **Ejemplo de SecciÃ³n Kafka y ZooKeeper en `docker-compose.yml` (Simplificado):**

       ```yaml
       # docker-compose.yml (extracto)
       services:
         zookeeper:
           image: confluentinc/cp-zookeeper:7.3.2 # Usar versiÃ³n especÃ­fica
           container_name: parkwise_zookeeper
           environment:
             ZOOKEEPER_CLIENT_PORT: 2181
             ZOOKEEPER_TICK_TIME: 2000
           networks:
             - parkwise_network

         kafka:
           image: confluentinc/cp-kafka:7.3.2 # Usar versiÃ³n especÃ­fica
           container_name: parkwise_kafka
           depends_on:
             - zookeeper
           ports: # Exponer puerto para acceso desde el host si es necesario para debug/tools
             - "9092:9092" # Puerto interno de Kafka en el container
           environment:
             KAFKA_BROKER_ID: 1
             KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
             KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
             KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092 
             # PLAINTEXT://kafka:29092 es para comunicaciÃ³n interna entre containers en la misma red Docker
             # PLAINTEXT_HOST://localhost:9092 es para que tu aplicaciÃ³n en el host pueda conectar
             KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
             KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
             KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1 # Para imÃ¡genes Confluent
             KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1 # Para imÃ¡genes Confluent
             # PodrÃ­as aÃ±adir KAFKA_CREATE_TOPICS para crear topics al inicio
             # KAFKA_CREATE_TOPICS: "parkwise.booking.events:1:1,parkwise.parking.events:1:1" (topic:partitions:replication)
           networks:
             - parkwise_network
         
         # ... tus servicios FastAPI (web, identity_service, booking_service, notification_service, etc.) ...
         # que se conectarÃ¡n a 'kafka:29092' (o 'localhost:9092' si el productor/consumidor corre en el host)

         # ... tu servicio Redis ...

       # networks:
       #   parkwise_network:
       #     driver: bridge
       ```

       * **Nota sobre `KAFKA_ADVERTISED_LISTENERS`:** Es crucial para que los `clients` puedan conectarse a Kafka correctamente tanto desde dentro de la red Docker como (opcionalmente) desde el `host`. La configuraciÃ³n puede variar.
5. **ImplementaciÃ³n en los `Microservices` ParkWise:**
   * **Productores (`Producers`):** Los `services` (ej. `BookingService`) usarÃ¡n `aiokafka` (14.7, 9.9) para publicar `domain events` en los `topics` Kafka despuÃ©s de completar operaciones de negocio (idealmente usando el patrÃ³n `Transactional Outbox` - 13.5).
   * **Consumidores (`Consumers`):**
     * El `NotificationService` (o los `FastAPI WebSocket gateways`) consumirÃ¡ `events` de Kafka con `aiokafka`.
     * Otros `microservices` tambiÃ©n pueden consumir `events` para mantener sus propios `read models` o `trigger` lÃ³gica.
     * Los consumidores serÃ¡n `async` y diseÃ±ados para ser idempotentes (14.7, 9.6).
   * **`WebSocket Handlers`:** La lÃ³gica en los `endpoints` `@app.websocket` gestionarÃ¡ las suscripciones de los `clients` (ej. a `updates` para `room_id` especÃ­ficos) y usarÃ¡ el `ConnectionManager` y el `Pub/Sub backend` (Redis) para el `fan-out` de mensajes `real-time`.

**Diagrama `Mermaid` Simplificado del Flujo Kafka -> `WebSocket` en ParkWise (con `Docker Compose` implÃ­cito):**

```mermaid
graph TD
    Booking[Booking Service] -->|1. BookingConfirmedEvent| Kafka[Kafka Broker]
    Kafka -->|2. Evento recibido| Notif[Notification Service]
    Notif -->|3. Publica mensaje| Redis[Redis Pub/Sub]
    Redis -->|4. Push al cliente| WS[WebSocket del Usuario]

```

Este `setup` con `Docker Compose` permitirÃ¡ a los desarrolladores de ParkWise:

* Levantar todo el `stack` (Kafka, ZooKeeper/KRaft, Redis, MariaDBs, MongoDB, y todos los `microservices` FastAPI) localmente con `docker compose up`.
* Desarrollar y probar los flujos `event-driven` y las interacciones `real-time` de manera integral.
* Asegurar que la configuraciÃ³n de conexiÃ³n a Kafka y otros `backing services` sea correcta desde las primeras etapas.


### 16.9 Despliegue automatizado con CI/CD en Kubernetes

Habiendo definido cÃ³mo ParkWise utilizarÃ¡ Kafka y `WebSockets` dentro de un entorno `Docker Compose` para desarrollo (16.8), el siguiente paso es llevar esta complejidad a un entorno de producciÃ³n o `staging` de manera automatizada y escalable. Esto nos lleva al despliegue en **Kubernetes** gestionado por `pipelines` de **CI/CD**.


Para el proyecto ParkWise, el objetivo es desplegar nuestros `microservices` (contenedores Docker) en un `cluster` de Kubernetes, y automatizar este proceso utilizando un `pipeline` de CI/CD. Esto sigue las prÃ¡cticas modernas de DevOps para asegurar despliegues rÃ¡pidos, fiables y consistentes.

1. **Kubernetes como Plataforma de OrquestaciÃ³n de ParkWise:**
   * **ElecciÃ³n:** Kubernetes (K8s) serÃ¡ la plataforma de orquestaciÃ³n para todos los `microservices` de ParkWise y sus `backing services` (Kafka, Redis, MariaDB, MongoDB â€“ aunque las bases de datos en producciÃ³n a menudo se gestionan como servicios externos al `cluster` K8s, como AWS RDS, Google Cloud SQL, o se despliegan con `StatefulSets` y operadores K8s dedicados).
   * **Beneficios para ParkWise:** Escalabilidad, `self-healing`, `rolling updates`, `service discovery` y `load balancing` para cada `microservice`.
2. **Artefactos de Despliegue para Kubernetes:**
   * Para cada `microservice` de ParkWise, se crearÃ¡n `manifests` Kubernetes (o se gestionarÃ¡n a travÃ©s de Helm/Kustomize como vimos en 15.4):
     * **`Deployment`:** Para definir el estado deseado del `microservice` (ej. `image` a usar â€“ versionada semÃ¡nticamente como en 15.2, nÃºmero de `replicas`, `update strategy`).
     * **`Service`:** Para exponer cada `microservice` dentro del `cluster` con un `DNS name` estable y `load balancing` (ej. `ClusterIP service`).
     * **`Ingress` (gestionado por un `API Gateway` o un `Ingress Controller`):** Para exponer ciertos servicios (como el `API Gateway` de ParkWise, o directamente algunos `endpoints` si no hay `gateway` para todo) al trÃ¡fico externo.
     * **`ConfigMap` y `Secret`:** Para gestionar la configuraciÃ³n y los `secrets` de cada `microservice` (URLs de base de datos, credenciales de Kafka, `API keys` de terceros).
     * **`PersistentVolumeClaim` (para `Stateful Services`):** Si las bases de datos o Kafka se despliegan dentro de K8s y necesitan almacenamiento persistente.
     * **`Health Probes` (`liveness` y `readiness`):** Definidas en los `Deployments` para que K8s sepa si los `Pods` de ParkWise estÃ¡n sanos y listos (15.10).
3. **`Pipeline` CI/CD para ParkWise (ej. con GitHub Actions, como en 15.5):**\
   El `pipeline` se encargarÃ¡ del ciclo completo desde el `commit` de cÃ³digo hasta el despliegue.
   * **`Trigger`:** `Push` a `main branch` (para despliegue a `staging`/`production`) o `merge` de `Pull Request`.
   * **Etapas del `Pipeline` CI:**
     1. **`Checkout Code`:** Obtener el cÃ³digo del `microservice` especÃ­fico.
     2. **`Setup Environment`:** Configurar Python, instalar dependencias.
     3. **`Lint & Format Check`:** Ejecutar `flake8`, `black`, `isort`.
     4. **`Unit & Integration Tests`:** Ejecutar `pytest` (14.1-14.5, 14.7). Las pruebas de integraciÃ³n podrÃ­an necesitar `service containers` (Docker-in-Docker si el `runner` CI lo permite, o servicios proveÃ­dos por la plataforma CI) para bases de datos o `brokers` temporales.
     5. **`Code Coverage Check`:** Ejecutar `pytest --cov` y fallar si el `coverage` es inferior al umbral (14.8).
     6. **`Build Docker Image`:** Construir la `Docker image` del `microservice` usando el `Dockerfile` eficiente (15.1).
     7. **`Tag Docker Image`:** Etiquetar la imagen con la versiÃ³n semÃ¡ntica (15.2) y, opcionalmente, con el `git commit SHA`.
     8. **`Push Docker Image`:** Subir la imagen al `container registry` (ej. GHCR, Docker Hub, ECR).
   * **Etapas del `Pipeline` CD (Despliegue Continuo/Entrega Continua):**\
     Esta parte se activa si la CI es exitosa. Para ParkWise, usaremos **GitOps con Argo CD** (15.6) como el mecanismo preferido para CD.
     1. **Actualizar el `Configuration GitOps Repository`:**
        * El `pipeline` CI, despuÃ©s de pushear la nueva `Docker image`, harÃ¡ `checkout` del `Config Repo`.
        * ModificarÃ¡ el `manifest` Kubernetes (o `values.yaml` de Helm, o `kustomization.yaml`) del `microservice` correspondiente para apuntar a la nueva `image tag`.
        * HarÃ¡ `commit` y `push` de este cambio al `Config Repo`.
     2. **Argo CD Detecta y Sincroniza:**
        * Argo CD (desplegado en el `cluster` K8s de `staging` o `production`) detecta el cambio en el `Config Repo`.
        * Compara el estado deseado (Git) con el estado actual del `cluster`.
        * Aplica los cambios para desplegar la nueva versiÃ³n del `microservice` (ej. iniciando un `rolling update`).
     3. **(Opcional) `Smoke Tests` Post-Despliegue:** El `pipeline` podrÃ­a ejecutar un conjunto simple de `tests` contra el `endpoint` reciÃ©n desplegado para una verificaciÃ³n rÃ¡pida.
     4. **(Opcional) NotificaciÃ³n:** Informar al equipo del estado del despliegue.
4. **Entornos (`Environments`):**
   * El `pipeline` CI/CD debe poder desplegar a diferentes entornos (ej. `development`, `staging`, `production`).
   * Esto se gestiona tÃ­picamente con:
     * **`Branches` Git Diferentes en el `Config Repo`:** Una `branch` por entorno.
     * **`Overlays` Kustomize Diferentes:** Un `overlay` por entorno en el `Config Repo`.
     * **Archivos `values` de Helm Diferentes:** `values-staging.yaml`, `values-prod.yaml` en el `Config Repo`.
     * Argo CD se configura para monitorizar la `branch` o `path` del `Config Repo` correspondiente a cada entorno K8s.
5. **`Rollbacks` en el `Pipeline` CI/CD:**
   * **AutomÃ¡tico (vÃ­a Argo CD + Git):** Si un despliegue gestionado por Argo CD resulta en una aplicaciÃ³n `unhealthy`, y se tienen polÃ­ticas de `auto-rollback` (o mediante la reversiÃ³n del `commit` en el `Config Repo`), Argo CD puede revertir al estado estable anterior.
   * **Manual/Semi-AutomÃ¡tico:** Si los `smoke tests` post-despliegue fallan en el `pipeline` CI/CD, el `pipeline` puede `triggerear` un `kubectl rollout undo` o revertir el `commit` en el `Config Repo`.

**Diagrama `Mermaid`: `Pipeline` CI/CD con GitOps para un `Microservice` ParkWise**

```mermaid
graph TD
    A[Dev push a App Repo (BookingService)] --> B{CI Pipeline (GitHub Actions)}
    B --> B1[1. Checkout + Tests + Coverage]
    B1 -->|OK| B2[2. Build Docker Image v1.1.0]
    B2 -->|OK| B3[3. Push al Container Registry]
    B3 -->|OK| B4[4. Update Config Repo a v1.1.0]
    B4 -->|Push| C[GitOps Config Repo]

    C -->|Cambio detectado| D[ArgoCD Controller]
    D -->|Git vs Estado real| K8s_API[Kubernetes API Server]
    K8s_API -->|Estado actual| D
    D -->|OutOfSync â†’ Sync| K8s_API
    K8s_API -->|Aplica cambios| K8s_Cluster[Cluster Kubernetes]

    K8s_Cluster -->|Estado post-deploy| Monitor[Prometheus]

    Note right of K8s_Cluster: Rolling update a BookingService v1.1.0

    Monitor -->|MÃ©tricas o Alertas| Feedback{Feedback Loop}
    Feedback -->|Falla| RB1[Rollback: revertir commit en Config Repo]
    Feedback -->|Falla| RB2[Rollback: sync versiÃ³n anterior]

    B1 -->|Falla| CI_Fail[Notificar fallo CI]
    B2 -->|Falla| CI_Fail
    B3 -->|Falla| CI_Fail
    B4 -->|Falla| CI_Fail
    RB2 -->|Falla rollback| CD_Fail[Notificar fallo despliegue]

    style A fill:#D5F5E3,stroke:#2ECC71
    style C fill:#FFF9C4,stroke:#F1C40F
    style D fill:#AED6F1,stroke:#3498DB
    style K8s_Cluster fill:#E8DAEF,stroke:#8E44AD
    style CI_Fail fill:#FFCDD2,stroke:#C62828
    style CD_Fail fill:#FFCDD2,stroke:#C62828





```

Este `pipeline` automatizado para ParkWise asegura que cada cambio de cÃ³digo en un `microservice` pase por un riguroso proceso de validaciÃ³n y que su despliegue a Kubernetes sea gestionado de forma declarativa, versionada y auditable a travÃ©s de GitOps con Argo CD. Esto aumenta la velocidad de entrega y la fiabilidad del sistema.

***

### 16.10 DocumentaciÃ³n y repositorio versionado
