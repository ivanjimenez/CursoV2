# Tema 15. BUENAS PR√ÅCTICAS Y AUTOMATIZACI√ìN DE DESPLIEGUES

* [Tema 15. BUENAS PR√ÅCTICAS Y AUTOMATIZACI√ìN DE DESPLIEGUES](Tema15.md#tema-15-buenas-pr√°cticas-y-automatizaci√≥n-de-despliegues)
  * [15. Contenidos](Tema15.md#15-contenidos)
    * [15.1 Dockerfiles eficientes para microservicios](Tema15.md#151-dockerfiles-eficientes-para-microservicios)
    * [15.2 Im√°genes versionadas sem√°nticamente](Tema15.md#152-im√°genes-versionadas-sem√°nticamente)
    * [15.3 `docker-compose` para entorno local](Tema15.md#153-docker-compose-para-entorno-local)
    * [15.4 Despliegue en Kubernetes con Helm/Kustomize](Tema15.md#154-despliegue-en-kubernetes-con-helmkustomize)
    * [15.5 Pipelines CI/CD en GitHub Actions/GitLab CI](Tema15.md#155-pipelines-cicd-en-github-actionsgitlab-ci)
    * [15.6 GitOps con ArgoCD o FluxCD](Tema15.md#156-gitops-con-argocd-o-fluxcd)
    * [15.7 Trazabilidad y logging con `structlog`/`loguru`](Tema15.md#157-trazabilidad-y-logging-con-structlogloguru)
    * [15.8 M√©tricas con Prometheus y Grafana](Tema15.md#158-m√©tricas-con-prometheus-y-grafana)
    * [15.9 Logs centralizados con ELK o Loki](Tema15.md#159-logs-centralizados-con-elk-o-loki)
    * [15.10 Rollout y rollback autom√°tico](Tema15.md#1510-rollout-y-rollback-autom√°tico)
  * [Bibliograf√≠a](Tema15.md#bibliograf√≠a)

## 15. Contenidos

### 15.1 Dockerfiles eficientes para microservicios

Este es el punto donde llevamos nuestras aplicaciones FastAPI y `microservices` del entorno de desarrollo al mundo real. Un despliegue robusto, eficiente y automatizado es tan crucial como un buen dise√±o de API o una l√≥gica de dominio s√≥lida.

Iniciaremos con el **15.1**, enfoc√°ndonos en c√≥mo empaquetar nuestros `microservices` de manera √≥ptima utilizando Docker. La creaci√≥n de `Dockerfiles` eficientes es el primer paso para despliegues √°giles y seguros.

***

Docker ha revolucionado la forma en que empaquetamos y desplegamos aplicaciones, especialmente en el contexto de `microservices`. Un `Dockerfile` es la receta, el plano de construcci√≥n para crear una imagen Docker que contendr√° tu `microservice` FastAPI y todas sus dependencias, listo para ser ejecutado en cualquier entorno que soporte Docker.

Pero no todos los `Dockerfiles` son iguales. Un `Dockerfile` _eficiente_ produce im√°genes m√°s peque√±as, se construye m√°s r√°pido y es m√°s seguro.

**Docker y `Microservices`: Una Alianza Natural (Breve Recordatorio) üê≥**

* **¬øQu√© es Docker?** Una plataforma de `containerization` que empaqueta una aplicaci√≥n y sus dependencias en una unidad aislada y portable llamada `container`. Estos `containers` se ejecutan a partir de `images`.
* **¬øPor qu√© es ideal para `microservices`?**
  * **Aislamiento:** Cada `microservice` corre en su propio `container`, con sus propias dependencias, evitando conflictos.
  * **Portabilidad y Consistencia:** Una `image` Docker se ejecuta de la misma manera en el `laptop` del desarrollador, en `staging`, y en producci√≥n.
  * **Escalabilidad:** Es f√°cil crear y gestionar m√∫ltiples instancias de un `container` para escalar un servicio.
  * **Despliegue R√°pido:** Los `containers` son ligeros y se inician r√°pidamente.

**El `Dockerfile`: El Plano de Construcci√≥n de Tu Imagen Docker üìú**

Es un archivo de texto llamado `Dockerfile` (sin extensi√≥n) que contiene una serie de instrucciones secuenciales para ensamblar una `Docker image`. Las instrucciones m√°s comunes que ya podr√≠as conocer son `FROM`, `WORKDIR`, `COPY`, `RUN`, `ENV`, `EXPOSE`, `CMD`, y `ENTRYPOINT`.

**Principios de Eficiencia para `Dockerfiles` Magistrales ‚ú®**

Construir `Dockerfiles` eficientes es un arte que se centra en varios principios:

**A. Minimizando el Tama√±o de la Imagen (`Image Size`): "Viajar Ligero es Viajar Mejor"**\
Im√°genes m√°s peque√±as significan:

* Tiempos de `pull` y `push` m√°s r√°pidos desde/hacia `container registries`.
* Menor consumo de espacio en disco.
* Potencialmente una superficie de ataque de seguridad m√°s reducida.

1. **Elegir una Imagen Base Peque√±a (`Base Image`):**\
   El `FROM` es tu punto de partida.
   * Para Python/FastAPI, en lugar de `FROM python:3.11` (que es grande), considera:
     * `FROM python:3.11-slim-buster` o `python:3.11-slim-bookworm`: Versiones "slim" basadas en Debian que son significativamente m√°s peque√±as pero a√∫n incluyen herramientas comunes.
     * `FROM python:3.11-alpine`: Basadas en Alpine Linux, son extremadamente peque√±as. **Precauci√≥n:** Alpine usa `musl libc` en lugar de `glibc` (com√∫n en otras distros Linux). Esto puede causar problemas de compatibilidad con algunas `wheels` de Python que esperan `glibc` o si necesitas compilar paquetes C con ciertas dependencias. Investiga bien si tus dependencias son compatibles.
2. **`Multi-Stage Builds`: La Estrategia Maestra para la Delgadez:**\
   Esta es una de las t√©cnicas m√°s poderosas. Divides tu `Dockerfile` en m√∫ltiples "etapas" (`stages`). Una etapa inicial (el `builder stage`) puede tener todas las herramientas de `build` y `dev dependencies` (compiladores, librer√≠as de desarrollo, etc.) para compilar tu aplicaci√≥n o instalar dependencias. Luego, una etapa final (`final stage`) copia _solo los artefactos necesarios_ (tu c√≥digo, el `virtual environment` con las `runtime dependencies`) desde el `builder stage` a una imagen base limpia y ligera.
3. **Limpieza Rigurosa en Comandos `RUN`:**\
   Cada comando `RUN` crea una nueva capa en la imagen. Para minimizar el tama√±o de las capas:
   *   Combina m√∫ltiples comandos `apt-get` (o tu `package manager`) y limpia las cach√©s en la misma instrucci√≥n `RUN`:

       ```dockerfile
       RUN apt-get update && \
           apt-get install -y --no-install-recommends some-package && \
           apt-get clean && \
           rm -rf /var/lib/apt/lists/*
       ```
   *   Para `pip`, usa `--no-cache-dir` para evitar almacenar la cach√© de descargas:

       ```dockerfile
       RUN pip install --no-cache-dir -r requirements.txt
       ```
4. **`COPY` Selectivo y `.dockerignore`:**
   * Evita `COPY . .` si no necesitas todo el `build context` en tu imagen. S√© espec√≠fico sobre qu√© archivos y directorios copiar.
   * Usa un archivo `.dockerignore` (similar a `.gitignore`) en la ra√≠z de tu `build context` para excluir archivos y directorios que no son necesarios para construir la imagen (ej. `.git`, `__pycache__`, `venv`, `README.md`, archivos de `test`). Esto reduce el tama√±o del `build context` enviado al `Docker daemon` y previene la copia accidental de archivos sensibles o innecesarios.

**B. Optimizando la Cach√© de Capas (`Layer Caching`): "Construir R√°pido, Reconstruir A√∫n M√°s R√°pido"**

Docker construye im√°genes en capas, y cada instrucci√≥n en el `Dockerfile` corresponde a una capa. Si una instrucci√≥n no ha cambiado y las capas anteriores tampoco, Docker reutilizar√° la capa cacheada, acelerando dr√°sticamente los `rebuilds`.

* **Ordena las Instrucciones de Menos a M√°s Cambiantes:**
  1. `FROM ...` (Cambia raramente).
  2. `ENV ...`, `WORKDIR ...` (Cambian raramente).
  3. `COPY requirements.txt .` (o `pyproject.toml`, `poetry.lock`).
  4. `RUN pip install -r requirements.txt ...` (Esta capa solo se reconstruye si `requirements.txt` cambia).
  5. `COPY . .` (Tu c√≥digo fuente, que es lo que cambia m√°s frecuentemente, va al final).\
     Si solo cambias tu c√≥digo fuente, Docker reutilizar√° todas las capas anteriores, incluyendo la costosa instalaci√≥n de dependencias.

**C. Seguridad como Prioridad (`Security Best Practices`): "Construir Fortalezas, No Caba√±as"**

1.  **Ejecutar como `Non-Root User` (Principio de Menor Privilegio):**\
    Por defecto, los `containers` corren como `root`. Esto es un riesgo de seguridad. Crea un usuario dedicado sin privilegios y √∫salo.

    ```dockerfile
    # Crear grupo y usuario
    RUN groupadd -r appgroup && useradd --no-log-init -r -g appgroup -d /home/appuser -s /sbin/nologin appuser
    # Crear directorio de la aplicaci√≥n y dar permisos
    RUN mkdir -p /home/appuser/app && chown -R appuser:appgroup /home/appuser/app

    USER appuser # Cambiar al usuario no-root
    WORKDIR /home/appuser/app # Establecer el WORKDIR para el usuario no-root
    ```
2. **No Incrustar Secretos:** Nunca `hardcodees` contrase√±as, `API keys`, o cualquier credencial en tu `Dockerfile` o los copies en la imagen. Usa variables de entorno en `runtime`, `Docker secrets`, o soluciones de gesti√≥n de secretos de tu plataforma de orquestaci√≥n.
3. **Minimizar Herramientas Innecesarias:** La imagen final (especialmente en `multi-stage builds`) solo debe contener lo estrictamente necesario para ejecutar tu aplicaci√≥n. Menos herramientas = menor `attack surface`.

**D. Reproducibilidad (`Reproducibility`): "Construir Exactamente lo Mismo, Siempre"**

* **Fijar Versiones de la Imagen Base:** En lugar de `FROM python:3.11`, usa una etiqueta m√°s espec√≠fica como `FROM python:3.11.5-slim-buster` para asegurar que los `rebuilds` usen la misma versi√≥n base.
* **Fijar Versiones de Dependencias:** Usa archivos de `requirements` con versiones fijas (ej. `fastapi==0.100.0`, `pydantic==2.5.0`) o, mejor a√∫n, `poetry.lock` o `Pipfile.lock`. Esto asegura que siempre se instalen las mismas versiones de tus dependencias.

**Ejemplo: Un `Dockerfile` Eficiente para un `Microservice` FastAPI (Multi-Etapa)**

```dockerfile
# --- Stage 1: Builder ---
# Usa una imagen base completa si necesitas herramientas de compilaci√≥n
FROM python:3.11-buster AS builder

LABEL stage="builder"

WORKDIR /opt/app

# Crear y activar un virtual environment
ENV PYTHONDONTWRITEBYTECODE 1
ENV PYTHONUNBUFFERED 1
RUN python -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# Instalar dependencias (primero para aprovechar el cacheo de capas)
COPY ./requirements.txt .
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# Copiar el resto del c√≥digo de la aplicaci√≥n
COPY ./app /opt/app/app


# --- Stage 2: Final ---
# Empezar desde una imagen base slim para la imagen final
FROM python:3.11-slim-buster AS final

# Crear usuario y grupo no-root
RUN groupadd -r appgroup --gid 1001 && \
    useradd --no-log-init -r -g appgroup --uid 1001 -d /home/appuser appuser

# Crear directorio de trabajo y dar permisos
WORKDIR /home/appuser/app
RUN chown -R appuser:appgroup /home/appuser

# Copiar el virtual environment desde el builder stage
COPY --from=builder --chown=appuser:appgroup /opt/venv /opt/venv

# Copiar el c√≥digo de la aplicaci√≥n desde el builder stage
COPY --from=builder --chown=appuser:appgroup /opt/app/app /home/appuser/app

# Establecer el PATH para incluir el venv y cambiar a usuario no-root
ENV PATH="/opt/venv/bin:$PATH"
USER appuser

# Exponer el puerto en el que la aplicaci√≥n FastAPI correr√°
EXPOSE 8000

# Comando para ejecutar la aplicaci√≥n
# Aseg√∫rate de que main.py est√° en /home/appuser/app/main.py
# o ajusta la ruta a app.main:app seg√∫n tu estructura.
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

_En este ejemplo, `app/main.py` ser√≠a el punto de entrada de tu aplicaci√≥n FastAPI._

**Tabla Resumen: Claves para `Dockerfiles` Eficientes**

| Pr√°ctica                      | Por Qu√© Es Clave                                                                              | Ejemplo/Instrucci√≥n Fundamental                         |
| ----------------------------- | --------------------------------------------------------------------------------------------- | ------------------------------------------------------- |
| Usar `Base Images` Ligeras    | Reduce tama√±o final, `attack surface`, tiempos de `pull/push`.                                | `python:3.x-slim-buster`, `python:3.x-alpine`           |
| **`Multi-Stage Builds`**      | **Separa `build-time dependencies` de `runtime dependencies` = im√°genes mucho m√°s peque√±as.** | `FROM ... AS builder`, `COPY --from=builder ...`        |
| Optimizar `Layer Caching`     | Acelera significativamente los `rebuilds` cuando solo cambia el c√≥digo.                       | Ordenar `COPY`/`RUN` (deps primero, luego c√≥digo app).  |
| Limpiar en Comandos `RUN`     | Reduce el tama√±o de cada capa generada.                                                       | `apt-get clean && rm ...`, `pip --no-cache-dir`         |
| Ejecutar como `Non-Root User` | Mejora dr√°sticamente la seguridad (`principle of least privilege`).                           | `USER appuser`                                          |
| Utilizar `.dockerignore`      | Evita copiar archivos innecesarios al `build context`, reduce tama√±o y tiempo.                | Similar a `.gitignore` (ej. `venv/`, `.git/`).          |
| Fijar Versiones (Base y Deps) | Asegura `builds` consistentes y reproducibles a lo largo del tiempo.                          | `FROM python:3.11.5-slim`, `requirements.txt` con `==`. |

**Conclusi√≥n: `Dockerfiles` como Obras de Ingenier√≠a Eficiente üì¶‚ú®**

Un `Dockerfile` bien estructurado y optimizado es mucho m√°s que un simple script; es una declaraci√≥n de c√≥mo tu `microservice` debe ser empaquetado para el mundo. Aplicar estas buenas pr√°cticas ‚Äìespecialmente `multi-stage builds`, optimizaci√≥n de capas, y ejecuci√≥n como `non-root user`‚Äì no solo resultar√° en im√°genes m√°s peque√±as y seguras, sino que tambi√©n mejorar√° la velocidad de tus `builds` y la eficiencia de tus despliegues.

Esta es la base para un `packaging` y despliegue profesional en un ecosistema de `microservices`.

***

### 15.2 Im√°genes versionadas sem√°nticamente

Si en el 15.1 nos convertimos en maestros artesanos de `Dockerfiles` eficientes, ahora debemos aprender a "firmar nuestra obra": c√≥mo versionar sem√°nticamente las `Docker images` que producimos. Esto es crucial para la gesti√≥n de `releases`, la compatibilidad y la cordura general en un ecosistema de `microservices`.

Imagina que cada `Docker image` es una edici√≥n de un libro importante. Necesitamos una forma clara de saber si estamos ante una nueva edici√≥n con cambios mayores, una revisi√≥n con nuevas secciones, o simplemente una correcci√≥n de erratas.

***

Una vez que hemos construido una `Docker image` optimizada para nuestro `microservice` FastAPI, el siguiente paso cr√≠tico es c√≥mo la nombramos y versionamos en nuestro `container registry` (como Docker Hub, AWS ECR, Google GCR, Azure CR, etc.). Usar `el tag :latest` para todo es una receta para el desastre en entornos de producci√≥n. Aqu√≠ es donde el **Versionado Sem√°ntico (`Semantic Versioning` o `SemVer`)** se convierte en nuestro mejor aliado.

**1. Versionado Sem√°ntico (`SemVer`): El ADN de Tus `Releases` (`MAJOR.MINOR.PATCH`)**

`SemVer` es una convenci√≥n simple pero poderosa para asignar n√∫meros de versi√≥n a nuestro `software` (y, por extensi√≥n, a nuestras `Docker images`). El formato es:

**`MAJOR.MINOR.PATCH`** (ej. `1.2.3`)

* **`MAJOR` (Mayor):** Se incrementa cuando realizas **cambios incompatibles con la API (`breaking API changes`)**. Si un `client` que usaba la `v1.0.0` intenta usar la `v2.0.0` sin modificaciones, es probable que falle.
* **`MINOR` (Menor):** Se incrementa cuando a√±ades **funcionalidad nueva de manera retrocompatible (`backward-compatible`)**. Los `clients` existentes deber√≠an poder seguir funcionando sin cambios, pero pueden aprovechar las nuevas `features` si lo desean.
* **`PATCH` (Parche):** Se incrementa cuando realizas **correcciones de `bugs` retrocompatibles (`backward-compatible bug fixes`)**. No se a√±ade nueva funcionalidad (que afecte la API p√∫blica), solo se arreglan problemas.
* **Extensiones Comunes (Breve Menci√≥n):**
  * **`Pre-release tags`:** Para versiones no estables (ej. `1.0.0-alpha.1`, `2.1.0-rc.2`).
  * **`Build metadata`:** Informaci√≥n adicional sobre el `build` (ej. `1.0.0+git.sha.a1b2c3d`).

**Tabla Explicativa de `SemVer`:**

| Componente  | Cu√°ndo Incrementar                                     | Implicaci√≥n Principal para Consumidores de la Imagen/API                 |
| ----------- | ------------------------------------------------------ | ------------------------------------------------------------------------ |
| **`MAJOR`** | Cuando hay `breaking changes` (cambios incompatibles). | Requiere adaptaci√≥n por parte del `client`.                              |
| **`MINOR`** | Cuando se a√±aden `features` retrocompatibles.          | Los `clients` existentes no deber√≠an romperse.                           |
| **`PATCH`** | Cuando se hacen `bug fixes` retrocompatibles.          | Los `clients` existentes no deber√≠an romperse; se recomienda actualizar. |

**2. ¬øPor Qu√© Aplicar `SemVer` a Tus `Docker Images`? Las Ventajas Estrat√©gicas üè∑Ô∏è**

Versionar tus `Docker images` usando `SemVer` no es solo una buena costumbre, es una pr√°ctica profesional con beneficios directos:

* **Claridad y Previsibilidad:** Un `tag` como `myapp:2.1.5` comunica inmediatamente la naturaleza y el impacto potencial de esa versi√≥n en comparaci√≥n con `myapp:2.1.4` o `myapp:1.7.0`.
* **Gesti√≥n de Dependencias Segura:**
  * En tus sistemas de despliegue (ej. `Kubernetes deployment manifests`, `Docker Compose files`), puedes especificar qu√© versiones de imagen usar.
  * Permite estrategias como:
    * Fijar a una versi√≥n exacta: `image: mycompany/myservice:1.2.3` (m√°xima estabilidad).
    * Permitir `patches` autom√°ticos: `image: mycompany/myservice:1.2` (asumiendo que el `tag` `1.2` apunta al √∫ltimo `patch` de la `1.2.x`).
    * (Con m√°s riesgo) Permitir `minor updates`: `image: mycompany/myservice:1`.
* **`Rollbacks` y `Upgrades` Controlados:** Facilita volver a una versi√≥n anterior estable si un nuevo despliegue presenta problemas, o planificar `upgrades` sabiendo el nivel de cambio.
* **Comunicaci√≥n de Equipo y `Release Notes`:** Proporciona un lenguaje com√∫n y puntos de referencia claros para discutir `releases`, `features` y `bugs`.
* **Trazabilidad:** Poder asociar una `Docker image` espec√≠fica con una versi√≥n de c√≥digo fuente y un conjunto de `features`/`fixes`.

**3. Etiquetado (`Tagging`) de `Docker Images` con `SemVer`: Un Arte Pr√°ctico üé®**

Cuando construyes una `Docker image`, puedes asignarle m√∫ltiples `tags`. La estrategia de `tagging` con `SemVer` suele incluir:

* **El `Tag` Completo (El M√°s Espec√≠fico):**`myregistry/my-app:1.2.3`\
  Siempre debes tener este `tag` para cada `release`.
* **`Tags` "Flotantes" (Conveniencia con Precauci√≥n):**\
  Estos `tags` se mueven para apuntar a la √∫ltima `sub-version` correspondiente.
  * `myregistry/my-app:1.2` (apunta al √∫ltimo `patch` de la versi√≥n `1.2`, ej. `1.2.3`, luego `1.2.4`, etc.)
  * `myregistry/my-app:1` (apunta a la √∫ltima versi√≥n `minor.patch` dentro de la `major 1`, ej. `1.2.3`, luego `1.3.0`, etc.)
  * `myregistry/my-app:latest` (tradicionalmente apunta a la √∫ltima `release` estable. **¬°Usar con extrema precauci√≥n en despliegues de producci√≥n que se actualizan autom√°ticamente!** Es mejor ser expl√≠cito con las versiones en producci√≥n).
* **`Tags` Adicionales √ötiles para Trazabilidad y Desarrollo:**
  * `myregistry/my-app:<git-commit-sha>`: Un `tag` con el `hash` completo del `commit` de Git del que se construy√≥ la imagen. Proporciona trazabilidad absoluta.
  * `myregistry/my-app:<branch-name>` (ej. `myregistry/my-app:feature-new-checkout`): Para `builds` de desarrollo o `feature branches`. Estos no suelen seguir `SemVer` estricto.
* **C√≥mo Aplicar M√∫ltiples `Tags` Durante el `Build` y `Push`:**
  1.  **Al construir (`docker build`):**

      ```bash
      VERSION=1.2.3
      docker build -t myapp:${VERSION} \
                   -t myapp:1.2 \
                   -t myapp:1 \
                   -t myapp:latest \
                   -t myapp:$(git rev-parse --short HEAD) . 
      # Asumiendo que est√°s en un repo git y quieres el short SHA
      ```
  2.  **Despu√©s de construir, usando `docker tag`:**

      ```bash
      docker build -t myapp:1.2.3 .
      docker tag myapp:1.2.3 myregistry/myapp:1.2.3
      docker tag myapp:1.2.3 myregistry/myapp:1.2
      docker tag myapp:1.2.3 myregistry/myapp:1
      # ...y as√≠ sucesivamente
      ```
  3.  **Al hacer `push`:** Debes hacer `push` de cada `tag` individualmente o usar `docker push --all-tags myregistry/myapp` (si `myapp` es el nombre base sin `tag` en el `registry`).

      ```bash
      docker push myregistry/myapp:1.2.3
      docker push myregistry/myapp:1.2
      docker push myregistry/myapp:1 
      # etc.
      ```

**4. Automatizando el Versionado y Etiquetado en `Pipelines CI/CD` ‚öôÔ∏è**

Este proceso es ideal para la automatizaci√≥n en tu `pipeline` de `CI/CD`.

* **Determinando la Versi√≥n (`Source of Truth` para la Versi√≥n):**
  1. **`Git Tags` (Muy Recomendado):**
     * Creas un `tag` Git anotado (ej. `git tag -a v1.2.3 -m "Release version 1.2.3"`) y haces `push` del `tag`.
     * Tu `pipeline` CI/CD se dispara con la creaci√≥n de este `tag`.
     * El `pipeline script` extrae la versi√≥n del `git tag` (ej. quita la "v").
  2. **Archivo de Versi√≥n en el `Repository`:**
     * Un archivo `VERSION` (ej. `1.2.3`) o una variable `__version__ = "1.2.3"` en tu c√≥digo (ej. `app/__init__.py`).
     * El `pipeline` lee este archivo. El `bump` de versi√≥n se hace manualmente o con herramientas antes del `commit`.
  3. **A Partir de `Commit Messages` (`Conventional Commits`):**
     * Si sigues la especificaci√≥n de `Conventional Commits` (ej. `fix: ...`, `feat: ...`, `BREAKING CHANGE: ...`), herramientas como `semantic-release` pueden analizar los `commits` desde el √∫ltimo `release`, determinar autom√°ticamente el siguiente n√∫mero de `SemVer`, crear el `git tag`, y disparar el `build`.
* **L√≥gica T√≠pica en el `Script` de CI/CD:**
  1. `Checkout` del c√≥digo en el `commit/tag` espec√≠fico.
  2. **Extraer/Determinar `VERSION`** (ej. del `git tag` `CI_COMMIT_TAG` en GitLab CI, `GITHUB_REF_NAME` en GitHub Actions).
  3. **Extraer `MAJOR`, `MINOR`:** (ej. `MAJOR_MINOR=${VERSION%.*}`).
  4. **Extraer `MAJOR`:** (ej. `MAJOR=${VERSION%%.*}`).
  5.  **Construir la `Docker image`** con m√∫ltiples `tags`:

      ```bash
      # Ejemplo conceptual de script CI
      # VERSION="1.2.3" (obtenido del git tag)
      # IMAGE_NAME="myregistry/myapp"
      # GIT_SHA=$(git rev-parse --short HEAD)

      # docker build -t ${IMAGE_NAME}:${VERSION} \
      #              -t ${IMAGE_NAME}:${VERSION%.*} \    # Ej: myapp:1.2
      #              -t ${IMAGE_NAME}:${VERSION%%.*} \   # Ej: myapp:1
      #              -t ${IMAGE_NAME}:latest \           # Si es un release estable
      #              -t ${IMAGE_NAME}:${GIT_SHA} .
      ```
  6. **Autenticarse en el `Container Registry`.**
  7.  **Hacer `Push` de todos los `tags` relevantes.**

      ```bash
      # docker push ${IMAGE_NAME}:${VERSION}
      # docker push ${IMAGE_NAME}:${VERSION%.*}
      # docker push ${IMAGE_NAME}:${VERSION%%.*}
      # docker push ${IMAGE_NAME}:latest
      # docker push ${IMAGE_NAME}:${GIT_SHA}
      # O, para algunos registries, `docker push --all-tags ${IMAGE_NAME}` podr√≠a funcionar despu√©s de m√∫ltiples tags locales
      ```
* **Diagrama `Mermaid`: `CI/CD Pipeline` para `Docker Image Tagging` y `Push`**

**5. Alineaci√≥n con el Versionado de la Aplicaci√≥n üß©**

Es una pr√°ctica muy sana que la versi√≥n de tu `Docker image` (ej. `myapp:1.2.3`) refleje fielmente la versi√≥n del c√≥digo de la aplicaci√≥n que contiene. Si tu aplicaci√≥n Python tiene una variable `__version__ = "1.2.3"` (quiz√°s le√≠da de un archivo `VERSION` o gestionada por `Poetry/PDM` en `pyproject.toml`), esta deber√≠a ser la misma versi√≥n usada para el `tag` principal de la `Docker image`.

**Conclusi√≥n: `Tags`** **`SemVer` como Hitos Claros en la Evoluci√≥n de Tus `Microservices` üö©**

El versionado sem√°ntico de tus `Docker images` no es una mera formalidad; es una disciplina profesional que introduce **claridad, predictibilidad y seguridad** en tu ciclo de vida de desarrollo, `testing` y despliegue.

* Facilita la gesti√≥n de dependencias entre `microservices` (si un servicio consume la imagen de otro).
* Permite estrategias de `rollout` y `rollback` m√°s seguras y controladas en tus orquestadores de contenedores (como Kubernetes).
* Mejora la comunicaci√≥n y la comprensi√≥n dentro del equipo y con otros `stakeholders` sobre el estado y la evoluci√≥n de cada `microservice`.

Automatizar este proceso de `tagging` sem√°ntico en tu `pipeline` CI/CD es el paso final para asegurar que esta pr√°ctica se aplique de manera consistente y eficiente, liberando a los desarrolladores de tareas manuales propensas a errores.

***

### 15.3 `docker-compose` para entorno local

Despu√©s de aprender a crear `Dockerfiles` eficientes (15.1) y a versionar nuestras `images` sem√°nticamente (15.2), el siguiente paso l√≥gico es simplificar c√≥mo ejecutamos y gestionamos nuestro `microservice` FastAPI ‚Äìjunto con sus dependencias como bases de datos o `message brokers`‚Äì en nuestro **entorno de desarrollo local**.

Aqu√≠ es donde **`Docker Compose`** se convierte en una herramienta indispensable, permiti√©ndonos orquestar m√∫ltiples `containers` como si fueran una √∫nica aplicaci√≥n.

***

Cuando desarrollas `microservices`, raramente trabajas con un solo servicio aislado. Tu `microservice` FastAPI probablemente necesitar√° una base de datos (PostgreSQL, MongoDB), un `cache` (Redis), un `message broker` (RabbitMQ, Kafka), u otros servicios para funcionar. Configurar y ejecutar cada uno de estos manualmente cada vez que inicias tu entorno de desarrollo es tedioso y propenso a errores.

**`Docker Compose`: El Director de Orquesta para Tus `Containers` üéº**

* **¬øQu√© es?** `Docker Compose` es una herramienta para **definir y ejecutar aplicaciones Docker multi-contenedor**. Utiliza un archivo de configuraci√≥n `YAML` (t√≠picamente `docker-compose.yml`) para describir todos los servicios, redes y vol√∫menes que componen tu aplicaci√≥n.
* **El Archivo M√°gico: `docker-compose.yml` ‚Äì Tu Partitura Declarativa:**\
  En este archivo, defines c√≥mo se deben construir y ejecutar tus `containers`, c√≥mo se conectan entre s√≠, qu√© `ports` exponen, qu√© `volumes` usan para persistencia o `live code reloading`, y qu√© variables de entorno necesitan.
* **Ventajas Clave para el Desarrollo Local:**
  1. **Simplicidad:** Levanta todo tu entorno de desarrollo (FastAPI app + BBDD + Redis + etc.) con un solo comando: `docker compose up`.
  2. **Consistencia:** Asegura que todos los miembros del equipo (y tus `pipelines` de CI para ciertos tipos de `tests`) trabajen con la misma configuraci√≥n de entorno.
  3. **Aislamiento y Redes:** Cada servicio corre en su propio `container`, pero `Docker Compose` crea una red por defecto para que puedan comunicarse f√°cilmente entre ellos usando los nombres de servicio definidos en el `YAML`.
  4. **Reproducibilidad:** El archivo `docker-compose.yml` es una definici√≥n declarativa y versionable de tu entorno.

**Anatom√≠a de un Archivo `docker-compose.yml` (Las Secciones Clave) üìú**

Un archivo `docker-compose.yml` t√≠pico tiene la siguiente estructura:

* **`version` (Legado):** En versiones antiguas de `docker-compose` (el comando separado), era com√∫n ver `version: '3.8'` o similar. Con la integraci√≥n de `compose` en el `Docker CLI` (`docker compose ...`), esta declaraci√≥n de versi√≥n de archivo es a menudo opcional o menos cr√≠tica, ya que el `CLI` moderno soporta las √∫ltimas `features`.
* **`services`:** Es la secci√≥n principal. Aqu√≠ defines cada `container` que forma parte de tu aplicaci√≥n. Cada `key` bajo `services` es el nombre de un servicio (ej. `web`, `db`, `cache`).
  * **`build` o `image`:**
    * `build: .` (o `./directorio_del_dockerfile`): Le dice a `Compose` que construya la `image` para este servicio usando el `Dockerfile` en el `path` especificado.
    * `image: postgres:15-alpine`: Le dice a `Compose` que use una `image` pre-construida de un `registry` (como Docker Hub).
  * **`ports`:** Mapea `ports` del `host` al `container` en formato `"HOST_PORT:CONTAINER_PORT"`. Ej: `"8000:8000"`.
  * **`volumes`:** Monta `paths` del `host` en el `container` o define `named volumes` para persistencia.
    * C√≥digo fuente para `live reload`: `- ./app:/app` (monta el directorio `./app` del `host` en `/app` dentro del `container`).
    * Datos de base de datos persistentes: `- postgres_data:/var/lib/postgresql/data` (usa un `named volume` llamado `postgres_data`).
  *   **`environment`:** Define variables de entorno para el `container`.

      ```yaml
      environment:
        - DATABASE_URL=postgresql+asyncpg://user:password@db:5432/appdb
        - DEBUG_MODE=True
      ```
  *   **`depends_on`:** Especifica dependencias entre servicios.

      ```yaml
      depends_on:
        db:
          condition: service_healthy # Espera a que el servicio 'db' est√© 'healthy'
      ```

      _Nota: `condition: service_healthy` requiere que el servicio dependiente (`db` en este caso) tenga un `healthcheck` definido._
  * **`networks`:** Permite conectar servicios a redes Docker personalizadas. Por defecto, `Compose` crea una red para el proyecto.
  * **`command` o `entrypoint`:** Permite sobrescribir el `CMD` o `ENTRYPOINT` por defecto de la `Docker image`.
  * **`healthcheck`:** Define un comando que Docker puede ejecutar peri√≥dicamente para verificar si el `container` est√° funcionando correctamente.
* **`volumes` (Nivel Superior):** Define `named volumes` que pueden ser usados por los servicios para persistir datos m√°s all√° del ciclo de vida de un `container`.
* **`networks` (Nivel Superior):** Define redes personalizadas si necesitas una configuraci√≥n de red m√°s avanzada.

**Ejemplo Pr√°ctico: `docker-compose.yml` para FastAPI + PostgreSQL + Redis üöÄ**

Imaginemos un `microservice` FastAPI que usa PostgreSQL como base de datos y Redis para `caching` o tareas de `background`.

```yaml
# docker-compose.yml
services:
  # Servicio Web FastAPI
  web:
    build: 
      context: . # Directorio donde est√° el Dockerfile de la app FastAPI
      dockerfile: Dockerfile # Nombre del Dockerfile (si no es 'Dockerfile')
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload # Comando para desarrollo con live reload
    volumes:
      - ./app:/app # Monta el c√≥digo fuente de tu app FastAPI para live reload
    ports:
      - "8000:8000" # Mapea el puerto 8000 del host al 8000 del container
    environment:
      - DATABASE_URL=postgresql+asyncpg://app_user:app_password@db:5432/app_db
      - REDIS_URL=redis://cache:6379/0
      - PYTHONUNBUFFERED=1 # Para que los logs de Python aparezcan inmediatamente
    depends_on:
      db:
        condition: service_healthy # Espera a que la BBDD est√© saludable
      cache:
        condition: service_started # Espera a que Redis simplemente inicie (healthcheck m√°s simple)
    networks:
      - app_network

  # Servicio de Base de Datos PostgreSQL
  db:
    image: postgres:15-alpine # Usar una imagen oficial de PostgreSQL
    volumes:
      - postgres_data:/var/lib/postgresql/data/ # Persistir datos de la BBDD
      # Opcional: para ejecutar scripts .sql al iniciar por primera vez
      # - ./init-db.sql:/docker-entrypoint-initdb.d/init-db.sql 
    environment:
      - POSTGRES_USER=app_user
      - POSTGRES_PASSWORD=app_password
      - POSTGRES_DB=app_db
    ports:
      - "5433:5432" # Mapear el puerto 5432 de Postgres a 5433 en el host (para evitar conflictos)
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U app_user -d app_db"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - app_network

  # Servicio de Cache Redis
  cache:
    image: redis:7-alpine
    ports:
      - "6379:6379" # Redis por defecto no necesita mapeo si solo se accede desde otros containers
                     # pero puede ser √∫til para inspecci√≥n desde el host.
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "ping"] # Espera PONG
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - app_network

# Definir vol√∫menes nombrados para persistencia
volumes:
  postgres_data: # Los datos de PostgreSQL persistir√°n aqu√≠

# Definir redes personalizadas (opcional si la red por defecto es suficiente)
networks:
  app_network:
    driver: bridge
```

* **Explicaci√≥n:**
  * El servicio `web` construye la imagen desde el `Dockerfile` local y monta el c√≥digo `app/` para `live reload` con Uvicorn. Depende de `db` y `cache`.
  * El servicio `db` usa una imagen `postgres`, persiste sus datos en un `named volume` `postgres_data`, y tiene un `healthcheck` para que `web` espere a que est√© lista.
  * El servicio `cache` usa una imagen `redis` y tambi√©n tiene un `healthcheck`.
  * Todos los servicios est√°n en la misma `app_network`, permiti√©ndoles comunicarse por sus nombres de servicio (ej. `web` se conecta a `db` en `db:5432`).

**Diagrama `Mermaid`: Orquestaci√≥n Local con `Docker Compose`**

```mermaid
graph TD
    DeveloperMachine["M√°quina del Desarrollador (Docker Host)"]
    
    subgraph "Docker Network ('app_network' gestionada por Compose)"
        WebAppContainer["Servicio 'web'<br/>(FastAPI + Uvicorn --reload)<br/>ContPort: 8000"]
        DBContainer["Servicio 'db'<br/>(PostgreSQL)<br/>ContPort: 5432"]
        CacheContainer["Servicio 'cache'<br/>(Redis)<br/>ContPort: 6379"]
        
        WebAppContainer -- "DATABASE_URL=...@db:5432..." --> DBContainer
        WebAppContainer -- "REDIS_URL=redis://cache:6379..." --> CacheContainer
    end

    DeveloperMachine -- "localhost:8000 (HTTP)" --> WebAppContainer
    DeveloperMachine -- "localhost:5433 (SQL)" --> DBContainer
    DeveloperMachine -- "localhost:6379 (Redis CLI)" --> CacheContainer

    subgraph "Vol√∫menes (en Docker Host o gestionados por Docker)"
        AppCodeLocal["./app (C√≥digo Fuente Local)"] ===o WebAppContainer
        PostgresDataVolume["postgres_data (Named Volume)"] ===o DBContainer
        RedisDataVolume["(Opcional) redis_data (Named Volume)"] -.-> CacheContainer
    end

    style WebAppContainer fill:#D5F5E3,stroke:#2ECC71
    style DBContainer fill:#AED6F1,stroke:#3498DB
    style CacheContainer fill:#FAD7A0,stroke:#F39C12
```

**Comandos Esenciales de `docker compose` (Tu Batuta de Director) ÊåáÊèÆÊ£í**

A partir de Docker Engine v20.10+, `docker-compose` est√° integrado en el `Docker CLI` como `docker compose` (sin el guion).

| Comando                                        | Descripci√≥n                                                                                                           |
| ---------------------------------------------- | --------------------------------------------------------------------------------------------------------------------- |
| `docker compose up`                            | Crea (si no existen) y arranca todos los servicios definidos en `docker-compose.yml` en primer plano. Muestra `logs`. |
| `docker compose up -d`                         | Igual, pero arranca los `containers` en segundo plano (`detached mode`).                                              |
| `docker compose down`                          | Detiene y elimina los `containers`, redes, etc., creados por `up`.                                                    |
| `docker compose down -v`                       | Igual que `down`, pero tambi√©n elimina los `named volumes` definidos en el `compose file` (¬°cuidado con los datos!).  |
| `docker compose ps`                            | Lista los `containers` que est√°n corriendo para el proyecto actual.                                                   |
| `docker compose logs [service_name]`           | Muestra los `logs` de todos los servicios o de uno espec√≠fico.                                                        |
| `docker compose logs -f [service_name]`        | Sigue los `logs` en tiempo real (`follow`).                                                                           |
| `docker compose build [service_name]`          | (Re)construye las `images` para los servicios que tienen una secci√≥n `build` (o para uno espec√≠fico).                 |
| `docker compose pull [service_name]`           | Descarga las `images` m√°s recientes para los servicios que usan `image` (o para uno espec√≠fico).                      |
| `docker compose exec <service_name> <command>` | Ejecuta un comando dentro de un `container` en ejecuci√≥n (ej. `docker compose exec web bash`).                        |
| `docker compose config`                        | Valida y muestra la configuraci√≥n `compose` combinada (√∫til para depurar tu `YAML`).                                  |
| `docker compose stop [service_name]`           | Detiene los servicios en ejecuci√≥n sin eliminarlos.                                                                   |
| `docker compose start [service_name]`          | Inicia servicios previamente detenidos.                                                                               |
| `docker compose restart [service_name]`        | Reinicia servicios.                                                                                                   |

**Desarrollo Interactivo: `Live Reloading` con `Volumes` y `Uvicorn` üî•**

Una de las grandes ventajas de `Docker Compose` para el desarrollo es el `live reloading`:

* **`volumes: - ./app:/app`**: Esta l√≠nea en tu servicio `web` monta tu directorio local `./app` (donde reside tu c√≥digo FastAPI) dentro del `container` en `/app`.
* **`command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload`**: El `flag` `--reload` de Uvicorn monitoriza los cambios en los archivos de c√≥digo (dentro del `container`).
* **Resultado:** Cuando modificas tu c√≥digo Python en tu m√°quina local, los cambios se reflejan instant√°neamente dentro del `container` gracias al `volume mount`, y Uvicorn detecta estos cambios y reinicia autom√°ticamente el servidor FastAPI. ¬°Desarrollo r√°pido y sin fricciones!

**Conclusi√≥n: `Docker Compose` como Tu Mejor Amigo para el Desarrollo Local de `Microservices` üßë‚Äçüíªü§ù**

`Docker Compose` transforma la complejidad de gestionar un entorno local multi-servicio en una tarea simple y declarativa.

* **Simplifica radicalmente** la puesta en marcha y la parada de todo tu `stack` de desarrollo.
* Asegura **consistencia y reproducibilidad** entre los miembros del equipo y entre diferentes m√°quinas.
* Te permite enfocarte en **desarrollar tu aplicaci√≥n FastAPI**, sabiendo que tus servicios dependientes (bases de datos, `caches`, `brokers`) est√°n configurados y listos para usar con un solo comando.

Es una herramienta esencial en el cintur√≥n de cualquier desarrollador moderno que trabaje con `containers` y arquitecturas de `microservices`.

***

### 15.4 Despliegue en Kubernetes con Helm/Kustomize

Con nuestros `microservices` FastAPI empaquetados en `Docker images` eficientes (15.1) y versionados sem√°nticamente (15.2), y con `Docker Compose` facilitando nuestros entornos de desarrollo local (15.3), es hora de mirar hacia el horizonte de la producci√≥n y el escalado real. Aqu√≠ es donde **Kubernetes (K8s)** entra en escena como el orquestador de `containers` dominante, y herramientas como **Helm** y **Kustomize** nos ayudan a domar su complejidad.

Este **15.4** es una introducci√≥n a este vasto y poderoso ecosistema.

***

Cuando tu aplicaci√≥n de `microservices` crece y necesita alta disponibilidad, escalabilidad autom√°tica, `rollouts` sin ca√≠das y una gesti√≥n robusta, `Docker Compose` (ideal para desarrollo local) se queda corto. Necesitas un orquestador de `containers` de nivel de producci√≥n, y el est√°ndar de facto en la industria es **Kubernetes (K8s)**.

**1. Kubernetes (K8s): El Director de Orquesta de Tus `Containers` en Producci√≥n üé∂**

* **¬øQu√© es Kubernetes?** Es una plataforma `open-source` para automatizar el despliegue, escalado y gesti√≥n de aplicaciones en `containers`. Originalmente dise√±ado por Google, ahora es mantenido por la Cloud Native Computing Foundation (CNCF).
* **¬øPor Qu√© K8s para `Microservices`?**
  * **Escalado Autom√°tico (`Autoscaling`):** Puede escalar tus `microservices` hacia arriba o abajo bas√°ndose en la carga (CPU, memoria, `custom metrics`).
  * **`Self-Healing` (Auto-reparaci√≥n):** Reinicia `containers` que fallan, reemplaza y reprograma `containers` en `nodes` que mueren.
  * **`Service Discovery` y `Load Balancing`:** Proporciona `IPs` estables y `DNS names` para tus servicios, y balancea la carga entre las r√©plicas.
  * **`Automated Rollouts and Rollbacks`:** Permite desplegar nuevas versiones de tu aplicaci√≥n gradualmente (ej. `rolling updates`) y volver a versiones anteriores si algo va mal.
  * **Gesti√≥n de Configuraci√≥n y Secretos:** Maneja `config data` y `secrets` de forma segura para tus aplicaciones.
  * **Orquestaci√≥n de `Storage`:** Puede gestionar `persistent storage` para tus aplicaciones `stateful`.
*   **Conceptos Fundamentales de K8s (Tabla Ilustrativa Simplificada):**

    | Objeto K8s   | Analog√≠a / Prop√≥sito Principal                                                                                                                                                                                        |
    | ------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
    | `Pod`        | La "c√°psula" o "carcasa" m√°s peque√±a y b√°sica. Contiene uno o m√°s `containers` (generalmente uno principal por `Pod` para `microservices`) que comparten `storage` y `network`.                                       |
    | `Deployment` | El "manager de r√©plicas". Declara el estado deseado de tu aplicaci√≥n (ej. "quiero 3 r√©plicas de mi `FastAPI app Pod`") y K8s trabaja para mantenerlo. Gestiona `updates` y `rollbacks`.                               |
    | `Service`    | Una "direcci√≥n de red abstracta y estable" (`IP` y `DNS name` dentro del `cluster`) que expone un conjunto de `Pods` (generalmente seleccionados por `labels`). Proporciona `load balancing` interno.                 |
    | `Ingress`    | El "controlador de tr√°fico externo". Gestiona el acceso HTTP y HTTPS desde fuera del `cluster` a los `Services` internos, a menudo con `routing` basado en `hostnames` y `paths`.                                     |
    | `ConfigMap`  | Almacena `configuration data` no sensible en pares clave-valor, que pueden ser consumidos por los `Pods` como `environment variables`, argumentos de l√≠nea de comandos o archivos de configuraci√≥n.                   |
    | `Secret`     | Similar a `ConfigMap`, pero dise√±ado para almacenar `data` sensible como contrase√±as, `tokens` OAuth, o `SSH keys`. Se almacenan (a menudo) codificados en `base64` y pueden tener pol√≠ticas de acceso m√°s estrictas. |
    | `Namespace`  | Un "vecindario virtual" dentro de un `cluster` K8s para organizar y aislar grupos de `resources`. √ötil para separar entornos (`dev`, `staging`, `prod`) o equipos.                                                    |
    | `Node`       | Una m√°quina trabajadora (f√≠sica o virtual) en el `cluster` Kubernetes donde se ejecutan los `Pods`.                                                                                                                   |
    | `Cluster`    | El conjunto completo de `Nodes` (maestros y trabajadores) que ejecutan Kubernetes.                                                                                                                                    |
* **Diagrama `Mermaid` Simplificado de Arquitectura K8s:**

**2. Desplegando FastAPI en K8s: Los Primeros Pasos con `YAML` üìù**

El proceso general para desplegar tu aplicaci√≥n FastAPI (o cualquier `container`) en Kubernetes es:

1. **Construir tu `Docker image`** (15.1).
2. **Subir (`push`) la `image` a un `Container Registry`** (15.2) (ej. Docker Hub, ECR, GCR, ACR).
3. **Escribir `manifest files` de Kubernetes en formato `YAML`**. Estos archivos describen el estado deseado de tus `resources` en el `cluster`.
   *   **`Deployment YAML` (Ejemplo Simplificado):**

       ```yaml
       # my-fastapi-app-deployment.yaml
       apiVersion: apps/v1
       kind: Deployment
       metadata:
         name: fastapi-app-deployment
         labels:
           app: my-fastapi-app
       spec:
         replicas: 3 # Queremos 3 instancias de nuestro Pod
         selector:
           matchLabels:
             app: my-fastapi-app # Debe coincidir con las labels del Pod template
         template: # Definici√≥n del Pod
           metadata:
             labels:
               app: my-fastapi-app
           spec:
             containers:
             - name: fastapi-container
               image: your-registry/your-fastapi-image:1.0.0 # Tu imagen versionada
               ports:
               - containerPort: 8000 # El puerto donde tu app FastAPI escucha dentro del container
               # Aqu√≠ tambi√©n configurar√≠as env vars, resources (cpu/memory), liveness/readiness probes
       ```
   *   **`Service YAML` (Ejemplo Simplificado para exponer el `Deployment` internamente):**

       ```yaml
       # my-fastapi-app-service.yaml
       apiVersion: v1
       kind: Service
       metadata:
         name: fastapi-app-service
       spec:
         selector:
           app: my-fastapi-app # Selecciona los Pods del Deployment anterior
         ports:
           - protocol: TCP
             port: 80       # Puerto por el que el Service es accesible dentro del cluster
             targetPort: 8000 # Puerto en los Pods al que se redirige el tr√°fico
         type: ClusterIP # Solo accesible dentro del cluster. Para acceso externo, usar LoadBalancer o Ingress.
       ```
4.  **Aplicar los `manifests` al `cluster` K8s:**

    ```bash
    kubectl apply -f my-fastapi-app-deployment.yaml
    kubectl apply -f my-fastapi-app-service.yaml
    ```

**3. El Desaf√≠o del `YAML` Puro: Cuando la Simplicidad se Vuelve Compleja ü§Ø**

Escribir y gestionar `YAMLs` de Kubernetes directamente para aplicaciones reales (que pueden tener muchos `microservices`, `ConfigMaps`, `Secrets`, `Ingresses`, etc.) r√°pidamente se vuelve:

* **Verboso:** Los archivos `YAML` pueden ser muy largos.
* **Repetitivo:** Mucha duplicaci√≥n si necesitas configuraciones similares para diferentes entornos (`dev`, `staging`, `production`).
* **Dif√≠cil de Parametrizar:** No hay una forma f√°cil de cambiar `image tags`, n√∫mero de r√©plicas, o URLs de base de datos para diferentes entornos usando solo `YAML` puro.
* **Complejo de Gestionar como un "Paquete":** ¬øC√≥mo versionas y distribuyes la configuraci√≥n completa de tu aplicaci√≥n?

Aqu√≠ es donde entran herramientas como Helm y Kustomize.

**4. Helm: El Gestor de `Packages` para Kubernetes üì¶**

* **¬øQu√© es Helm?** A menudo descrito como "el `apt/yum/homebrew` para Kubernetes". Helm te ayuda a definir, instalar y actualizar aplicaciones Kubernetes complejas.
* **Conceptos Clave:**
  * **`Chart`:** Un `package` Helm. Es una colecci√≥n de archivos organizados en una estructura de directorios predefinida. Estos archivos incluyen `templates` para tus `manifests` Kubernetes (escritos en una mezcla de `YAML` y el lenguaje de `templates` de Go) y un archivo `values.yaml` por defecto.
  * **`Release`:** Una instancia de un `chart` desplegada en un `cluster` Kubernetes. Puedes desplegar el mismo `chart` m√∫ltiples veces con diferentes configuraciones (ej. para `staging` y `production`).
  * **`Values` (`values.yaml` y `--set` / `-f values_override.yaml`):** La forma de **personalizar un `chart` sin modificar sus `templates`**. El archivo `values.yaml` dentro del `chart` provee los valores por defecto. Puedes sobrescribirlos al instalar/actualizar el `chart`.
  * **`Repository`:** Un lugar donde los `charts` pueden ser almacenados y compartidos (ej. Artifact Hub).
* **Beneficios:**
  * **Reusabilidad:** Puedes empaquetar tu aplicaci√≥n como un `chart` y desplegarla f√°cilmente en diferentes `clusters` o `namespaces`. Hay muchos `charts` pre-hechos por la comunidad para software popular (PostgreSQL, Redis, etc.).
  * **Gesti√≥n de Complejidad:** Agrupa todos los `resources` Kubernetes de una aplicaci√≥n en un solo `package`.
  * **Parametrizaci√≥n:** F√°cil de configurar para diferentes entornos.
  * **Ciclo de Vida Gestionado:** Helm maneja `installs`, `upgrades`, `rollbacks` de `releases`.
* **Diagrama Conceptual: `Helm Chart` a `Kubernetes Manifests`**

**5. Kustomize: Personalizaci√≥n Declarativa de `YAML` sin `Templates` üõ†Ô∏è**

* **¬øQu√© es Kustomize?** Una herramienta (integrada en `kubectl` desde la v1.14 como `kubectl kustomize` o `kubectl apply -k`) para personalizar `Kubernetes resource configurations` de una manera declarativa y **sin usar `templates`**.
* **C√≥mo Funciona:**
  1. Tienes un conjunto de archivos `YAML` **base** (ej. `deployment.yaml`, `service.yaml` gen√©ricos).
  2. Creas **`overlays`** para cada entorno o variaci√≥n. Un `overlay` es un directorio que contiene un archivo `kustomization.yaml` y, opcionalmente, `patches` o `YAMLs` adicionales espec√≠ficos para ese `overlay`.
  3. El archivo `kustomization.yaml` le dice a Kustomize:
     * Cu√°les son los `resources` base.
     * Qu√© `patches` aplicar (ej. cambiar el `image tag`, el n√∫mero de `replicas`, a√±adir `labels` o `annotations`).
     * C√≥mo generar `ConfigMaps` o `Secrets`.
     * C√≥mo a√±adir prefijos/sufijos a los nombres de los `resources`.
  4. Ejecutas `kubectl apply -k ./path/to/overlay_directory` y Kustomize genera los `YAMLs` finales y los aplica.
* **Beneficios:**
  * **Menos Complejo que `Templating`:** Evita la necesidad de aprender un lenguaje de `templates` (como el de Go en Helm). Las modificaciones son m√°s directas sobre `YAML`.
  * **Declarativo:** Defines _qu√©_ quieres cambiar, no _c√≥mo_ cambiarlo program√°ticamente.
  * **Reutilizaci√≥n de Bases:** Puedes tener una base com√∫n y m√∫ltiples `overlays` que la personalizan.
  * **Buena Integraci√≥n con GitOps:** La estructura basada en directorios y `YAMLs` se alinea bien con flujos de trabajo GitOps.
* **Diagrama Conceptual: Kustomize Base + `Overlay`**

**6. Helm vs. Kustomize: ¬øCu√°ndo Usar Qu√©? (Una Comparaci√≥n R√°pida)**

| Caracter√≠stica          | Helm                                                                                                                          | Kustomize                                                                                                                      |
| ----------------------- | ----------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------ |
| **Paradigma Principal** | `Packaging` y `Templating` (Go templates).                                                                                    | Personalizaci√≥n declarativa de `YAML` mediante `patches` y `overlays`.                                                         |
| **Complejidad**         | Curva de aprendizaje para el lenguaje de `templates`. Potente pero puede ser verboso.                                         | Generalmente m√°s simple para personalizaciones comunes si ya tienes `YAMLs` base.                                              |
| **Ecosistema**          | Enorme cantidad de `charts` pre-construidos por la comunidad (Artifact Hub).                                                  | Integrado en `kubectl`. Fuerte en la comunidad GitOps.                                                                         |
| **Reusabilidad**        | Alta a trav√©s de `charts` parametrizables y compartibles.                                                                     | Buena mediante `bases` y `components` (una `feature` m√°s nueva).                                                               |
| **Caso de Uso Ideal**   | Desplegar `software` de terceros complejo, empaquetar tu aplicaci√≥n para distribuci√≥n, gesti√≥n de `releases` con `rollbacks`. | Gestionar configuraciones espec√≠ficas de entorno para tus propias aplicaciones, personalizaciones finas de `YAMLs` existentes. |

_Nota: No son mutuamente excluyentes. Puedes usar Kustomize para generar los `YAMLs` que luego son empaquetados en un `chart` de Helm (usando `helm create --starter` o `helm template | kustomize build | kubectl apply`), o Helm para desplegar una base que luego Kustomize afina._

**Conclusi√≥n: Orquestando Tus `Microservices` FastAPI a Escala con Confianza üö¢**

Kubernetes es el est√°ndar de facto para la orquestaci√≥n de `containers` en producci√≥n, ofreciendo una potencia y flexibilidad inmensas. Sin embargo, gestionar sus `manifests` `YAML` directamente puede ser abrumador para aplicaciones complejas o m√∫ltiples entornos.

* **Helm** te proporciona un sistema de `packaging` y `templating` robusto, ideal para aplicaciones complejas y para distribuir o consumir `software` empaquetado.
* **Kustomize** ofrece un enfoque declarativo y sin `templates` para personalizar `YAMLs`, lo cual es excelente para gestionar variaciones entre entornos de tus propias aplicaciones.

Elegir la herramienta adecuada (o una combinaci√≥n inteligente de ambas) simplificar√° dr√°sticamente tus despliegues en Kubernetes, permiti√©ndote aprovechar todo el poder del orquestador mientras mantienes tus configuraciones manejables, versionables y reproducibles. Esto es esencial para llevar tus `microservices` FastAPI del desarrollo local a una producci√≥n escalable y resiliente.

***

### 15.5 Pipelines CI/CD en GitHub Actions/GitLab CI

Nos enfocaremos exclusivamente en **GitHub Actions** para el **15.5**, como has solicitado. Si en el 14.10 introdujimos la idea de automatizar `tests` en `pipelines` CI/CD, ahora vamos a ver c√≥mo construir un `pipeline` m√°s completo usando GitHub Actions, abarcando desde el `linting` y `testing` hasta el `build` y `push` de `Docker images` para nuestros `microservices` FastAPI.

GitHub Actions se ha vuelto incre√≠blemente popular por su integraci√≥n nativa con GitHub, su comunidad y su modelo de precios (generosos `free tiers` para proyectos p√∫blicos y privados).

***

Un `pipeline` de **`Continuous Integration` / `Continuous Delivery` (CI/CD)** es el coraz√≥n de las pr√°cticas modernas de DevOps. Automatiza los pasos necesarios para llevar tu c√≥digo desde el repositorio hasta un entorno de producci√≥n (o `staging`), pasando por validaciones de calidad, `builds` y `tests`. **GitHub Actions** es una herramienta poderosa y flexible integrada en GitHub para construir estos `pipelines` directamente en tus `repositories`.

**¬øQu√© es GitHub Actions? workflow**

* Es una plataforma de automatizaci√≥n que te permite definir `workflows` personalizados que se ejecutan en respuesta a `events` en tu `repository` GitHub (ej. `push` a una `branch`, creaci√≥n de un `Pull Request`, un `release` tag, o incluso `triggers` programados).
* Los `workflows` se definen en archivos `YAML` almacenados en el directorio `.github/workflows/` de tu `repository`.
* Cada `workflow` se compone de uno o m√°s `jobs`, y cada `job` se ejecuta en un `runner` (una m√°quina virtual en la nube o `self-hosted`) y contiene una secuencia de `steps`.
* Los `steps` pueden ejecutar comandos de `shell` o usar `actions` pre-construidas (reutilizables) de la comunidad o de GitHub.

**Construyendo un `Pipeline` CI/CD B√°sico para un `Microservice` FastAPI con GitHub Actions**

Vamos a dise√±ar un `pipeline` que:

1. Se dispara en `pushes` a la `main branch` y en `Pull Requests` a `main`.
2. Configura el entorno Python.
3. Instala dependencias.
4. Ejecuta `linters` y `formatters`.
5. Ejecuta `unit tests` y `integration tests` con `pytest` y `coverage`.
6. (Opcional, si es un `push` a `main` y los `tests` pasan) Construye una `Docker image` y la sube a un `container registry` (ej. GitHub Container Registry - GHCR, o Docker Hub).

**1. Creando el Archivo del `Workflow`:**\
Crea un archivo, por ejemplo, `.github/workflows/ci-cd-pipeline.yml`:

```yaml
# .github/workflows/ci-cd-pipeline.yml
name: FastAPI CI/CD Pipeline

# Triggers: Cu√°ndo se ejecuta el workflow
on:
  push:
    branches: [ main ] # Cuando se hace push a la branch main
  pull_request:
    branches: [ main ] # Cuando se crea o actualiza un Pull Request hacia main

jobs:
  # Job 1: Linting y Formateo
  lint-format:
    name: Lint & Format Check
    runs-on: ubuntu-latest # Especifica el tipo de runner
    steps:
      - name: Checkout code
        uses: actions/checkout@v4 # Acci√≥n oficial para hacer checkout del repo

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11' # Especifica tu versi√≥n de Python
          cache: 'pip' # Cachear dependencias de pip para builds m√°s r√°pidos

      - name: Install dependencies (including linters/formatters)
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt # Asumiendo que tienes linters aqu√≠
          # o poetry install --with dev

      - name: Run linters and formatters
        run: |
          flake8 ./app --count --select=E9,F63,F7,F82 --show-source --statistics
          black ./app --check
          isort ./app --check-only

  # Job 2: Pruebas (Unit & Integration)
  test:
    name: Run Tests & Coverage
    runs-on: ubuntu-latest
    needs: lint-format # Este job depende de que lint-format termine exitosamente
    
    # Si tus integration tests necesitan servicios (ej. PostgreSQL, Redis):
    services:
      postgres_test_db:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: testuser
          POSTGRES_PASSWORD: testpassword
          POSTGRES_DB: testdb
        ports:
          - 5432:5432 # El servicio estar√° disponible en localhost:5432 dentro del runner del job
        options: >- # Opciones para el healthcheck del servicio contenedor
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      # redis_test_cache:
      #   image: redis:7-alpine
      #   ports:
      #     - 6379:6379
      #   options: --health-cmd "redis-cli ping" --health-interval 10s --health-timeout 5s --health-retries 3

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt 
          pip install -r requirements-dev.txt # Para pytest, coverage, etc.

      - name: Run Pytest with Coverage
        env: # Establecer variables de entorno para los tests (si se usan servicios)
          TEST_DATABASE_URL: postgresql+asyncpg://testuser:testpassword@localhost:5432/testdb
          # TEST_REDIS_URL: redis://localhost:6379/0
        run: |
          pytest \
            --cov=app \ # Directorio a medir (tu c√≥digo fuente FastAPI)
            --cov-report=xml:coverage.xml \
            --cov-report=html:htmlcov \
            --cov-report=term-missing \
            --junitxml=pytest-results.xml \
            # --cov-fail-under=80 # Opcional: fallar si la cobertura es menor a 80%
      
      - name: Upload Pytest test results
        uses: actions/upload-artifact@v4
        if: always() # Siempre subir, incluso si los tests fallan, para poder ver el reporte
        with:
          name: pytest-results
          path: pytest-results.xml
          retention-days: 7

      - name: Upload Coverage HTML report
        uses: actions/upload-artifact@v4
        if: success() # Solo subir si los tests y coverage pass (o always() si prefieres)
        with:
          name: coverage-html-report
          path: htmlcov # Directorio generado por --cov-report=html
          retention-days: 7
      
      # Opcional: Subir reporte de cobertura a Codecov o similar
      # - name: Upload coverage to Codecov
      #   uses: codecov/codecov-action@v4
      #   if: success()
      #   with:
      #     token: ${{ secrets.CODECOV_TOKEN }} # Necesitas a√±adir el token como secret en GitHub
      #     files: ./coverage.xml
      #     fail_ci_if_error: true

  # Job 3: Build y Push de Docker Image (solo en push a main y si los tests pasan)
  build-and-push-docker:
    name: Build & Push Docker Image
    runs-on: ubuntu-latest
    needs: test # Depende de que el job 'test' termine exitosamente
    if: github.event_name == 'push' && github.ref == 'refs/heads/main' # Solo para pushes a main

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up QEMU (para multi-platform builds, opcional)
        uses: docker/setup-qemu-action@v3
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry (GHCR)
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }} # Nombre del usuario/organizaci√≥n que ejecuta la acci√≥n
          password: ${{ secrets.GITHUB_TOKEN }} # Token proporcionado por GitHub Actions

      # Extraer versi√≥n (ejemplo simple, puedes usar git tags o un archivo VERSION)
      - name: Extract version (example: from a VERSION file)
        id: get_version
        run: echo "APP_VERSION=$(cat VERSION.txt)" >> $GITHUB_OUTPUT
        # Si usas git tags:
        # run: echo "APP_VERSION=${GITHUB_REF_NAME#refs/tags/}" >> $GITHUB_OUTPUT
        # Aseg√∫rate de que el workflow se dispare con tags para esto:
        # on:
        #   push:
        #     tags:
        #       - 'v*.*.*'


      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: . # Directorio del Dockerfile
          file: ./Dockerfile # Path al Dockerfile
          push: true
          tags: | # M√∫ltiples tags
            ghcr.io/${{ github.repository_owner }}/my-fastapi-app:${{ steps.get_version.outputs.APP_VERSION }}
            ghcr.io/${{ github.repository_owner }}/my-fastapi-app:latest 
            # Podr√≠as a√±adir m√°s tags sem√°nticos (MAJOR.MINOR, MAJOR) aqu√≠
          # Opcional: cache para builds m√°s r√°pidos
          cache-from: type=gha
          cache-to: type=gha,mode=max
```

**Explicaci√≥n del `Workflow` YAML:**

* **`name`:** Nombre del `workflow`.
* **`on`:** Define los `events` que disparan el `workflow`.
  * `push: branches: [main]`: Se ejecuta en cada `push` a la `branch main`.
  * `pull_request: branches: [main]`: Se ejecuta en `pull requests` dirigidos a `main`.
* **`jobs`:** Contiene uno o m√°s `jobs` que se ejecutan en paralelo por defecto (a menos que se especifique `needs`).
  * **`lint-format` (Job):**
    * `runs-on: ubuntu-latest`: Especifica el tipo de `runner` (m√°quina virtual).
    * `steps`: Secuencia de tareas.
      * `actions/checkout@v4`: Acci√≥n oficial para hacer `checkout` del c√≥digo de tu `repository`.
      * `actions/setup-python@v5`: Configura el entorno Python, con `caching` de `pip`.
      * `Install dependencies`: Instala dependencias, incluyendo `linters`.
      * `Run linters`: Ejecuta `flake8`, `black --check`, `isort --check`. Si alguno falla, el `job` falla.
  * **`test` (Job):**
    * `needs: lint-format`: Este `job` solo se ejecuta si `lint-format` fue exitoso.
    * **`services`:** Esta secci√≥n es muy √∫til. Permite definir **`service containers`** que se ejecutan junto a tu `job` y son accesibles por `localhost` dentro del `runner` del `job`. Perfecto para levantar una base de datos PostgreSQL de prueba o un Redis.
      * `image`: La `Docker image` a usar (ej. `postgres:15-alpine`).
      * `env`: Variables de entorno para el `service container`.
      * `ports`: Mapeo de `ports` (el `runner` puede acceder al `port` del `service container` en `localhost:<host_port>`).
      * `options: --health-cmd ...`: Define un `healthcheck` para el `service container`. El `job step` que depende de este servicio (o el propio `job` si la dependencia es a nivel de `job`) esperar√° a que el servicio est√© `healthy`.
    * `steps`:
      * `Checkout`, `Setup Python`, `Install dependencies` (similar al `job` de `lint`).
      * `Run Pytest with Coverage`:
        * `env`: Aqu√≠ puedes pasar la `DATABASE_URL` para que tus `tests` de integraci√≥n usen el `PostgreSQL service container` que definiste.
        * El comando `pytest` incluye `--cov` para `coverage`, `--cov-report` para generar informes XML (para herramientas externas) y HTML (para revisi√≥n humana), y `--junitxml` para un reporte de resultados de `test` que muchas plataformas CI pueden parsear.
      * `Upload ... artifact`: Guarda los resultados de `tests` y `coverage` como "artefactos" del `workflow run`, para que puedas descargarlos e inspeccionarlos.
  * **`build-and-push-docker` (Job):**
    * `if: github.event_name == 'push' && github.ref == 'refs/heads/main'`: Condici√≥n para ejecutar este `job` solo en `pushes` directos a `main` (y despu√©s de que los `tests` pasen debido a `needs: test`).
    * `docker/setup-qemu-action` y `docker/setup-buildx-action`: Para `multi-platform builds` si es necesario.
    * `docker/login-action`: Para autenticarse en un `container registry` (aqu√≠ GHCR, usando el `GITHUB_TOKEN` autom√°tico).
    * `Extract version`: Un paso para determinar la versi√≥n de la `image` (aqu√≠ un ejemplo simple leyendo de `VERSION.txt`, pero idealmente de un `git tag`).
    * `docker/build-push-action`: Acci√≥n oficial para construir y hacer `push` de la `Docker image`.
      * `tags`: Define los `tags` de la `image` (incluyendo la versi√≥n y `latest`).
      * `push: true`: Realmente hace el `push` al `registry`.

**Diagrama `Mermaid` de un `CI Pipeline` B√°sico con GitHub Actions:**

```mermaid
graph TD
    A[Git Push o PR a main] --> B{Trigger GitHub Action Workflow}
    B --> C[Job: Lint y Format]
    C -->|OK| D[Job: Tests y Coverage - usa contenedores DB/Redis]
    D -->|OK| E{¬øEs Push a main?}
    E -->|S√≠| F[Job: Build y Push Docker Image]
    E -->|No, es PR| G[Fin del Workflow - PR Checks OK]
    F -->|OK| H[Notificar √©xito o iniciar despliegue CD]

    C -->|Falla| X[Notificar fallo - bloquea PR]
    D -->|Falla| X
    F -->|Falla| X

    style A fill:#D5F5E3,stroke:#2ECC71
    style H fill:#ABEBC6,stroke:#1E8449
    style G fill:#E8DAEF,stroke:#8E44AD
    style X fill:#FFCDD2,stroke:#C62828

```

**Consideraciones Adicionales:**

* **Secrets:** Usa los `Secrets` de GitHub (`Settings -> Secrets and variables -> Actions`) para almacenar `API keys`, `tokens` de `registry`, etc., y refer√©ncialos en tu `workflow` como \`$\{{ secrets.MI\_SECRET \}}}$.
* **`Caching` de Dependencias:** `actions/setup-python` con `cache: 'pip'` (o `poetry`, `pipenv`) acelera la instalaci√≥n de dependencias en `runs` subsecuentes. Docker tambi√©n tiene mecanismos de `caching` para `layers` (ver 15.1 y el `cache-from`/`cache-to` en `docker/build-push-action`).
* **`Matrix Builds`:** Para probar tu aplicaci√≥n contra m√∫ltiples versiones de Python o diferentes bases de datos.
* **Notificaciones:** Configura notificaciones (email, Slack) para fallos o √©xitos del `workflow`.
* **Despliegue Continuo (CD):** Despu√©s de que la imagen Docker es construida y subida, podr√≠as a√±adir m√°s `jobs` para desplegarla autom√°ticamente a `staging` o producci√≥n usando herramientas como `kubectl`, Helm, o `actions` espec√≠ficas de tu proveedor `cloud` (AWS, GCP, Azure). (Esto se tocar√° en 15.6, 15.10).

**Conclusi√≥n: Automatizaci√≥n como Pilar de la Calidad y Agilidad üöÄ**

Integrar tus `tests`, `linting`, `builds` de `images`, y (eventualmente) despliegues en un `pipeline` CI/CD con GitHub Actions (o una herramienta similar) es transformar tu proceso de desarrollo.

* **Asegura la Calidad Continuamente:** Cada cambio es verificado.
* **Reduce el Esfuerzo Manual:** Automatiza tareas repetitivas y propensas a error.
* **Acelera el `Feedback Loop`:** Los desarrolladores saben r√°pidamente si sus cambios introdujeron problemas.
* **Permite Entregas M√°s Frecuentes y Confiables:** Es la base del DevOps moderno.

Configurar un `pipeline` CI/CD robusto es una inversi√≥n inicial que se paga con creces en t√©rminos de estabilidad del producto, productividad del equipo y capacidad para innovar r√°pidamente.

***

### 15.6 GitOps con ArgoCD o FluxCD

Con nuestro `pipeline` CI/CD (15.5) construyendo y probando nuestras `Docker images`, el siguiente paso l√≥gico en la automatizaci√≥n y robustez de los despliegues, especialmente en Kubernetes, es adoptar una metodolog√≠a como **GitOps**, y **Argo CD** es una de las herramientas estrella para implementarla.

Este **15.6** se centrar√° en Argo CD, mostr√°ndote c√≥mo puede transformar tus despliegues en un proceso declarativo, versionado y auditable.

***

Imagina que el estado deseado de toda tu infraestructura y aplicaciones en Kubernetes no se gestiona con `scripts` imperativos o intervenciones manuales, sino que est√° **declarado y versionado en un repositorio Git**. Cualquier cambio en ese estado deseado se realiza a trav√©s de un `commit` y un `pull request`. Un agente automatizado se encarga entonces de que tu entorno real refleje fielmente lo que est√° en Git. Eso, en esencia, es GitOps, y Argo CD es un agente de primera l√≠nea para esta tarea.

**1. GitOps: La Filosof√≠a de "Git como `Single Source of Truth`" üìú**

GitOps es una metodolog√≠a operativa para `Cloud Native applications` (especialmente en Kubernetes) que se basa en una serie de principios fundamentales:

1. **Declarativo (`Declarative`):** Todo el sistema (infraestructura, aplicaciones) se describe de forma declarativa. Para Kubernetes, esto significa tus `manifests YAML` (o `Helm charts`, `Kustomize configurations` que los generan).
2. **Versionado e Inmutable (`Versioned and Immutable`):** El estado deseado del sistema est√° versionado en un repositorio Git. Git es la √∫nica fuente de verdad. Cada cambio es un `commit`, lo que proporciona un historial completo y la capacidad de `rollback`.
3. **Extra√≠do Autom√°ticamente (`Pulled Automatically`):** Un agente de `software` (como Argo CD) se encarga de extraer autom√°ticamente el estado deseado del repositorio Git y aplicarlo al entorno de destino (tu `cluster` Kubernetes).
4. **Continuamente Reconciliado (`Continuously Reconciled`):** El mismo agente monitoriza continuamente el estado real del sistema y lo compara con el estado deseado en Git. Si detecta una divergencia (`drift`), la corrige para asegurar que el sistema siempre converja al estado declarado en Git.

* **Beneficios de GitOps:**
  * **Auditabilidad y Visibilidad:** Cada cambio en el estado del sistema est√° registrado en Git (`who`, `what`, `when`).
  * **Reproducibilidad y Consistencia:** El estado del sistema se define en c√≥digo, lo que facilita la creaci√≥n de entornos id√©nticos.
  * **`Rollbacks` Sencillos y Fiables:** Revertir un `commit` en Git revierte el sistema al estado anterior.
  * **`Developer-Centric Workflow`:** Los desarrolladores pueden usar el mismo flujo de trabajo de `Pull Requests` que usan para el c√≥digo de la aplicaci√≥n para proponer y aprobar cambios en la configuraci√≥n del despliegue.
  * **Seguridad Mejorada:** Limita el acceso directo a `kubectl` en el `cluster`. Los cambios se gestionan a trav√©s de los permisos y flujos de aprobaci√≥n de Git.

**2. Argo CD: Tu Agente GitOps Nativo para Kubernetes ‚õµ**

* **¬øQu√© es Argo CD?** Es una herramienta de `Continuous Delivery (CD)` declarativa, de c√≥digo abierto y nativa de GitOps, dise√±ada espec√≠ficamente para Kubernetes. Es un proyecto graduado de la CNCF.
* **C√≥mo Funciona el Coraz√≥n de Argo CD (El Bucle de Sincronizaci√≥n):**
  1. **`Monitor`:** Argo CD se configura para "observar" uno o m√°s `Git repositories` (tus "repositorios de configuraci√≥n" o `Config Repos`). Estos `repos` contienen los `manifests` Kubernetes que describen el estado deseado de tus aplicaciones.
  2. **`Compare`:** Peri√≥dicamente (o en respuesta a `webhooks` de Git), Argo CD compara el estado deseado definido en los `manifests` del `Config Repo` con el estado real de los `resources` en tu `Kubernetes cluster`.
  3. **`Report Drift`:** Si hay diferencias (ej. una `image tag` es diferente, el n√∫mero de `replicas` no coincide, un `resource` definido en Git no existe en el `cluster`), Argo CD lo marca como `OutOfSync` y muestra las diferencias en su UI.
  4. **`Sync` (Sincronizar):** Argo CD aplica los cambios necesarios al `cluster` Kubernetes para que su estado real coincida con el estado deseado en Git. Esta sincronizaci√≥n puede ser:
     * **Manual:** Un operador revisa las diferencias y aprueba el `sync` a trav√©s de la UI o CLI de Argo CD.
     * **Autom√°tica (`Automated Sync`):** Argo CD aplica los cambios autom√°ticamente tan pronto como detecta una divergencia. A menudo se combina con `self-heal` (corregir cambios manuales no autorizados en el `cluster`) y `prune` (eliminar `resources` del `cluster` que ya no est√°n definidos en Git).
* **`Features` Destacadas de Argo CD:**
  * Interfaz de usuario web intuitiva para visualizar el estado de las aplicaciones, `sync status`, `health status`, y el historial de despliegues.
  * Soporte para m√∫ltiples formatos de `manifests`: `YAML` puro, `Helm charts`, `Kustomize`, `Jsonnet`, o `plugins` personalizados.
  * Gesti√≥n de `rollbacks` a versiones anteriores (basados en `commits` de Git).
  * `RBAC (Role-Based Access Control)` para definir qui√©n puede hacer qu√©.
  * Soporte `multi-cluster` y `multi-tenant`.
  * `Health assessment` de los `resources` de Kubernetes.
  * `Sync Hooks` (`PreSync`, `Sync`, `PostSync`, `SyncFail`) para ejecutar l√≥gica personalizada durante el proceso de `sync`.
* **Diagrama `Mermaid` Simplificado del Bucle de Argo CD:**

**3. El `Workflow` GitOps con Argo CD para `Microservices` FastAPI üåä**

Un `workflow` GitOps t√≠pico para una aplicaci√≥n FastAPI implica dos repositorios principales:

1. **`Application Code Repository`:**
   * Contiene el c√≥digo fuente de tu `microservice` FastAPI, `Dockerfile`, `tests`, etc.
   * El `pipeline` CI (como el que vimos en 15.5 con GitHub Actions) se dispara aqu√≠.
   * **Salida del CI:** Una `Docker image` versionada (ej. `mycompany/fastapi-service:1.2.3`) subida a un `container registry`.
2. **`Configuration GitOps Repository`:**
   * Contiene los `Kubernetes manifests` (o `Helm charts`, `Kustomize overlays`) que definen c√≥mo se debe desplegar tu `microservice` FastAPI (y otros servicios) en Kubernetes.
   * Estos `manifests` referencian la `Docker image` por su `tag` de versi√≥n (ej. `image: mycompany/fastapi-service:1.2.3`).
   * **Argo CD monitoriza este `repository`.**

**El Flujo Completo:**

1. Un desarrollador hace `push` de cambios de c√≥digo al `Application Code Repository`.
2. El `pipeline` CI se ejecuta:
   * Corre `linters`, `tests`.
   * Construye la `Docker image` (ej. `mycompany/fastapi-service:1.2.4`).
   * Hace `push` de la nueva `image` al `container registry`.
3. **Actualizaci√≥n del `Configuration GitOps Repository`:** Este es el paso clave que conecta CI con CD GitOps.
   * **Opci√≥n A (Automatizada por CI):** El mismo `pipeline` CI, despu√©s de un `push` exitoso de la `image`, tiene un `step` para:
     1. Hacer `checkout` del `Configuration GitOps Repository`.
     2. Modificar el archivo `YAML` relevante (ej. `Deployment.yaml`, o `values.yaml` si usas Helm, o un `patch` Kustomize) para actualizar el `image tag` a la nueva versi√≥n (`1.2.4`).
     3. Hacer `commit` y `push` de este cambio al `Configuration GitOps Repository`.
   * **Opci√≥n B (Manual o Semiautom√°tica):** Un desarrollador o un miembro del equipo de operaciones crea un `Pull Request` en el `Configuration GitOps Repository` con el cambio del `image tag`. Despu√©s de la revisi√≥n y aprobaci√≥n, se hace `merge`.
4. **Argo CD Entra en Acci√≥n:**
   * Argo CD, que est√° monitorizando el `Configuration GitOps Repository` (la `branch` relevante, ej. `main` o `production`), detecta el nuevo `commit`.
   * Compara el nuevo estado deseado (con `image: mycompany/fastapi-service:1.2.4`) con el estado actual en el `cluster` Kubernetes (que podr√≠a estar corriendo `1.2.3`).
   * El `Application` en Argo CD se marcar√° como `OutOfSync`.
   * Si la pol√≠tica de `sync` es autom√°tica, Argo CD iniciar√° el proceso de `sync`. Si es manual, un operador lo har√° a trav√©s de la UI o CLI de Argo CD.
   * Argo CD aplicar√° los cambios al `cluster` Kubernetes (ej. `kubectl apply` del `Deployment` actualizado), lo que t√≠picamente resultar√° en un `rolling update` de tus `Pods` FastAPI a la nueva versi√≥n de la `image`.
5. Argo CD monitoriza el `rollout` y actualiza el estado de la aplicaci√≥n a `Synced` y `Healthy` una vez que el despliegue se completa con √©xito.

**Diagrama `Mermaid` del Flujo GitOps Completo:**

```mermaid
sequenceDiagram
    participant Dev as Developer
    participant AppRepo as App Code Git Repo
    participant CI_Pipeline as CI Pipeline (GitHub Actions)
    participant ImageReg as Docker Image Registry
    participant ConfigRepo as Config GitOps Repo
    participant ArgoCD_Ctrl as Argo CD Controller
    participant K8s_API as Kubernetes API Server

    Dev->>+AppRepo: 1. Push code
    AppRepo->>+CI_Pipeline: 2. Trigger CI
    CI_Pipeline->>CI_Pipeline: 3. Test, Lint, etc.
    CI_Pipeline->>CI_Pipeline: 4. Build Docker image (app:v1.2.4)
    CI_Pipeline->>+ImageReg: 5. Push image app:v1.2.4
    ImageReg-->>-CI_Pipeline: Push OK

    CI_Pipeline->>+ConfigRepo: 6. Update manifest (image: app:v1.2.4), Commit & Push
    ConfigRepo-->>-CI_Pipeline: Config updated

    ArgoCD_Ctrl->>+ConfigRepo: 7. Polls/Webhook: Detects change
    ConfigRepo-->>-ArgoCD_Ctrl: New desired state (image: app:v1.2.4)

    ArgoCD_Ctrl->>ArgoCD_Ctrl: 8. Compare Git state vs K8s state
    Note over ArgoCD_Ctrl: App status: OutOfSync

    ArgoCD_Ctrl->>+K8s_API: 9. Sync: Apply updated K8s manifests
    K8s_API->>K8s_API: (eg. Rolling update of Deployment)
    K8s_API-->>-ArgoCD_Ctrl: Update successful

    ArgoCD_Ctrl->>ArgoCD_Ctrl: 10. App status: Synced, Healthy
```

**4. Configurando una `Application` en Argo CD (Conceptual) üß©**

Dentro de Argo CD, defines una "Aplicaci√≥n" (que es un `CustomResourceDefinition - CRD` de Kubernetes) para cada `workload` que quieres gestionar. Un ejemplo simplificado de su `YAML`:

```yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: my-fastapi-app
  namespace: argocd # Donde corre Argo CD
spec:
  project: default # Proyecto Argo CD

  source:
    repoURL: 'https://github.com/my-org/my-fastapi-config-repo.git' # Tu Config GitOps Repo
    path: 'deploy/production/fastapi-app' # Path a los manifests/Helm/Kustomize dentro del repo
    targetRevision: HEAD # O una branch, tag espec√≠fico
    # Para Helm:
    # chart: ./helm-charts/my-fastapi-app
    # valuesFiles:
    #   - values-production.yaml
    # Para Kustomize:
    # (path apuntar√≠a al directorio con kustomization.yaml)

  destination:
    server: 'https://kubernetes.default.svc' # Cluster K8s destino (el mismo donde corre Argo CD)
    namespace: my-production-namespace # Namespace donde se desplegar√° la app

  syncPolicy:
    automated: # Configuraci√≥n para auto-sync
      prune: true    # Eliminar resources en K8s que ya no est√°n en Git
      selfHeal: true # Corregir drift si el estado en K8s cambia manualmente
    syncOptions:
      - CreateNamespace=true # Crear el namespace si no existe
```

**5. Beneficios de Usar Argo CD para Despliegues FastAPI üöÄ**

* **Despliegue Declarativo Consistente:** El estado deseado de tu aplicaci√≥n FastAPI y su entorno est√°n siempre en Git.
* **Auditabilidad Completa:** Cada cambio en la configuraci√≥n del despliegue es un `commit` trazable.
* **`Rollbacks` Sencillos y Seguros:** Simplemente revierte el `commit` en tu `Config Repo`, y Argo CD se encargar√° de llevar el `cluster` al estado anterior.
* **Visibilidad y Control Centralizados:** La UI de Argo CD te da una visi√≥n clara del estado de todas tus aplicaciones desplegadas, diferencias con Git, y el historial de `syncs`.
* **Seguridad Mejorada:** Se promueve el cambio a trav√©s de `Git workflows` (PRs, aprobaciones) en lugar de acceso `kubectl` directo a producci√≥n.
* **Potencial para `Developer Self-Service` (Controlado):** Los equipos de desarrollo pueden proponer cambios a sus despliegues (ej. actualizar una `image tag`, cambiar `resource limits`) mediante PRs al `Config Repo`, que luego pueden ser revisados y aprobados por el equipo de operaciones o plataforma.

**Conclusi√≥n: GitOps con Argo CD ‚Äì Tu Br√∫jula para Despliegues Confiables, Auditables y Automatizados üß≠**

GitOps no es solo una herramienta; es una **metodolog√≠a operativa** que aporta disciplina, automatizaci√≥n y los beneficios de las pr√°cticas de desarrollo de `software` (control de versiones, revisi√≥n de c√≥digo) a la gesti√≥n de la infraestructura y los despliegues.

**Argo CD** es una implementaci√≥n de primera l√≠nea de GitOps para Kubernetes. Al usarlo para tus `microservices` FastAPI:

* Centralizas la definici√≥n de tu estado deseado en Git.
* Automatizas la sincronizaci√≥n de ese estado con tus `clusters` Kubernetes.
* Ganas una enorme confianza en tus despliegues, mejoras la colaboraci√≥n y aceleras tu capacidad para entregar `software` de forma segura y predecible.

Es un paso significativo hacia un modelo de `Continuous Delivery` maduro y eficiente.

***

### 15.7 Trazabilidad y logging con `structlog`/`loguru`

Con nuestros `pipelines` CI/CD (15.5) listos para automatizar despliegues y GitOps con Argo CD (15.6) ofreciendo una gesti√≥n declarativa, es fundamental que nuestros `microservices` FastAPI, una vez en producci√≥n, nos hablen claro. No solo cuando las cosas van mal, sino tambi√©n para entender su comportamiento normal. Aqu√≠ es donde un sistema de `logging` robusto y estructurado entra en juego, y para ello, nos centraremos en **`structlog`** en este **15.7**.

Imagina que cada `microservice` es un explorador en una vasta jungla. Un `logging` tradicional ser√≠a como si el explorador solo gritara "¬°Ayuda!" o "¬°Todo bien!" de vez en cuando. El `logging` estructurado con `structlog` es como si cada explorador llevara una bit√°cora detallada, geolocalizada y con metadatos, permiti√©ndonos entender exactamente qu√© vio, qu√© hizo y d√≥nde estuvo en cada momento.

***

En el mundo de los `microservices`, donde una sola petici√≥n de usuario puede desencadenar una cascada de interacciones entre m√∫ltiples servicios, el `logging` simple con `print()` o el m√≥dulo `logging` est√°ndar de Python con mensajes de texto plano se queda corto r√°pidamente. Necesitamos `logs` que sean:

* **F√°ciles de `parsear` y `query` por m√°quinas.**
* **Ricos en contexto** (ej. `request ID`, `user ID`, `service name`).
* **Consistentes** a trav√©s de todos nuestros servicios.

Esto es lo que nos ofrece el **`logging` estructurado**, y **`structlog`** es una biblioteca Python de primera l√≠nea para implementarlo con elegancia y flexibilidad.

**1. El Poder del `Logging` Estructurado: De Texto Plano a Datos Inteligentes üß†**

* **¬øQu√© es?** En lugar de generar `log messages` como `strings` de formato libre, el `logging` estructurado produce `logs` en un formato de pares clave-valor, com√∫nmente `JSON`. Cada `log entry` se convierte en un `object` con `fields` bien definidos.
*   **Ejemplo Comparativo:**

    | `Logging` Tradicional (Texto Plano)                                   | `Logging` Estructurado (ej. JSON con `structlog`)                                                                 |
    | --------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------- |
    | `INFO: User 'alice' logged in from IP 192.168.1.100 at 2025-05-20...` | `{"event": "user_login", "level": "info", "user_id": "alice", "ip_address": "192.168.1.100", "timestamp": "..."}` |
*   **Ventajas Clave:**

    | Caracter√≠stica          | `Logging` Tradicional           | `Logging` Estructurado                                                      |
    | ----------------------- | ------------------------------- | --------------------------------------------------------------------------- |
    | **Legibilidad M√°quina** | Dif√≠cil, `regex` fr√°giles.      | F√°cil de `parsear` y `query` por sistemas de `log management`.              |
    | **Filtrado/B√∫squeda**   | Limitado (`grep`).              | Potente y preciso (ej. `user_id="alice" AND level="error"`).                |
    | **Agregaci√≥n/An√°lisis** | Muy complejo.                   | Facilita la creaci√≥n de `dashboards`, m√©tricas y alertas basadas en `logs`. |
    | **Contexto**            | A menudo manual, inconsistente. | F√°cil de a√±adir `metadata` rica y consistente (`request_id`, `trace_id`).   |

**2. `structlog`: Tu Aliado para un `Logging` Estructurado y Flexible en Python üìú**

* **¬øQu√© es `structlog`?** Una biblioteca Python avanzada para `logging` que facilita la creaci√≥n de `logs` estructurados. No reemplaza completamente el m√≥dulo `logging` est√°ndar de Python, sino que a menudo se integra con √©l o lo envuelve para a√±adir sus `features`.
* **Caracter√≠sticas Principales:**
  * **`Processor Pipeline`:** Su caracter√≠stica m√°s potente. Los `log events` pasan a trav√©s de una cadena de `processors` (funciones) que pueden a√±adir, modificar o eliminar datos del `log entry` antes de que sea renderizado (formateado) y enviado a su destino.
  * **Compatibilidad con `stdlib logging`:** Puede configurarse para que los `loggers` de `structlog` env√≠en sus `log entries` finales a los `handlers` del m√≥dulo `logging` est√°ndar. Esto es √∫til para que los `logs` de librer√≠as de terceros (que usan `logging` est√°ndar) tambi√©n puedan ser capturados y, hasta cierto punto, estructurados.
  * **`Context Binding`:** Permite a√±adir contexto (`key-value pairs`) a un `logger` que se incluir√° autom√°ticamente en todos los `log messages` emitidos por ese `logger` (o `loggers` derivados). `structlog.contextvars` lo hace especialmente poderoso para contextos as√≠ncronos como en FastAPI.
  * **Flexibilidad de `Output`:** Soporta varios `renderers` para diferentes formatos de salida (ej. `JSON` para producci√≥n, texto coloreado amigable para la consola de desarrollo).

**3. Configuraci√≥n Inicial de `structlog` en Tu Aplicaci√≥n FastAPI ‚ú®**

La configuraci√≥n de `structlog` se realiza una vez, t√≠picamente al inicio de tu aplicaci√≥n (ej. en `main.py` o en un m√≥dulo dedicado `logging_config.py`).

*   **Instalaci√≥n:**

    ```bash
    pip install structlog "uvicorn[standard]" # uvicorn[standard] para logging coloreado en dev
    ```
*   **Configuraci√≥n del `Processor Pipeline` y `stdlib logging` Integration:**\
    Este es un ejemplo de una configuraci√≥n robusta que se integra bien con `stdlib logging` y Uvicorn/Gunicorn.

    ```python
    # app/core/logging_config.py (o en main.py)
    import logging
    import sys
    import structlog
    from structlog.types import Processor

    def setup_logging(log_level: str = "INFO", json_logs: bool = False):
        # 1. Configuraci√≥n base para el logging est√°ndar (afecta a librer√≠as de terceros)
        logging.basicConfig(
            format="%(message)s", # structlog se encargar√° del formato final
            stream=sys.stdout,    # Enviar a stdout
            level=log_level.upper()
        )

        # 2. Definir la cadena de processors para structlog
        shared_processors: List[Processor] = [
            structlog.stdlib.add_logger_name,      # A√±ade el nombre del logger (ej. 'app.main')
            structlog.stdlib.add_log_level,        # A√±ade el nivel del log (ej. 'info', 'error')
            structlog.stdlib.ExtraAdder(),         # Permite a√±adir extras al log event
            structlog.processors.TimeStamper(fmt="iso", utc=True), # Timestamp en ISO8601 UTC
            structlog.dev.set_exc_info,            # Si hay una excepci√≥n, la a√±ade
            structlog.processors.StackInfoRenderer(), # Para stack traces (opcional)
            structlog.processors.format_exc_info,  # Formatea la informaci√≥n de la excepci√≥n
            # Un-comment to add caller info (useful for dev, can be expensive for prod)
            # structlog.processors.CallsiteParameterAdder(
            #     [
            #         structlog.processors.CallsiteParameter.FILENAME,
            #         structlog.processors.CallsiteParameter.LINENO,
            #         structlog.processors.CallsiteParameter.FUNC_NAME,
            #     ]
            # ),
        ]

        if json_logs:
            # Processors para producci√≥n (JSON)
            processors = shared_processors + [
                structlog.stdlib.ProcessorFormatter.wrap_for_formatter, # Prepara para el stdlib Formatter
            ]
            # El stdlib Formatter usar√° JSONRenderer
            formatter = structlog.stdlib.ProcessorFormatter.‡§¨‡•Ä‡§ü‡§æ_Renderer(
                 structlog.processors.JSONRenderer()
            )
            handler = logging.StreamHandler() # O un handler a un sistema de logs
            handler.setFormatter(formatter)
            
            # Eliminar handlers por defecto y a√±adir el nuestro para el root logger
            # Esto es para asegurar que TODO pase por nuestro JSONRenderer
            root_logger = logging.getLogger()
            for h in root_logger.handlers[:]: # Iterar sobre una copia
                root_logger.removeHandler(h)
                h.close()
            root_logger.addHandler(handler)
            
        else:
            # Processors para desarrollo (consola coloreada)
            processors = shared_processors + [
                 structlog.dev.ConsoleRenderer(colors=True), # Renderizado amigable para la consola
            ]

        # 3. Configurar structlog
        structlog.configure(
            processors=processors,
            logger_factory=structlog.stdlib.LoggerFactory(), # Usa la factor√≠a del stdlib
            wrapper_class=structlog.stdlib.BoundLogger,    # Para que get_logger devuelva un logger compatible
            cache_logger_on_first_use=True,
        )
        
        logger = structlog.get_logger("app.setup_logging")
        logger.info("Logging configured", log_level=log_level, json_logs=json_logs)

    # En main.py:
    # from app.core.logging_config import setup_logging
    # from app.core.config import settings # Asumiendo que tienes settings.LOG_LEVEL y settings.JSON_LOGS

    # @app.on_event("startup")
    # async def startup_event():
    #     setup_logging(log_level=settings.LOG_LEVEL, json_logs=settings.JSON_LOGS)
    ```

    * **Procesadores Clave Explicados:**
      * `structlog.stdlib.add_logger_name`, `structlog.stdlib.add_log_level`: Integran informaci√≥n del `logger` est√°ndar.
      * `structlog.processors.TimeStamper(fmt="iso", utc=True)`: A√±ade `timestamps` consistentes.
      * `structlog.dev.set_exc_info`, `structlog.processors.format_exc_info`: Para un buen `logging` de excepciones.
      * `structlog.dev.ConsoleRenderer(colors=True)`: Para un `output` legible y coloreado en desarrollo.
      * `structlog.processors.JSONRenderer()`: Para `output` `JSON` en producci√≥n, ideal para ser ingerido por sistemas como ELK, Loki, Splunk, Datadog.
      * `structlog.stdlib.ProcessorFormatter.wrap_for_formatter`: Si quieres que los `logs` de `structlog` sean finalmente manejados por un `handler` del `logging` est√°ndar (lo cual es com√∫n para usar `handlers` existentes o para asegurar que los `logs` de librer√≠as de terceros sigan el mismo `path`).

**4. Registrando `Events` con `structlog`: M√°s que Simples Mensajes üó£Ô∏è**

*   **Obtener un `Logger`:**

    ```python
    logger = structlog.get_logger(__name__) # Buena pr√°ctica usar __name__
    # o un nombre espec√≠fico: logger = structlog.get_logger("mi_servicio_especifico")
    ```
*   **`Logging` B√°sico con Niveles:**

    ```python
    logger.debug("Mensaje de depuraci√≥n detallado")
    logger.info("Operaci√≥n completada exitosamente")
    logger.warning("Algo inesperado pero no cr√≠tico ocurri√≥")
    logger.error("Un error manejable ocurri√≥")
    logger.critical("Un error cr√≠tico que podr√≠a afectar el sistema")
    ```
*   **A√±adiendo Contexto (Pares Clave-Valor) ‚Äì ¬°Aqu√≠ est√° el Poder!**\
    Cualquier `keyword argument` adicional se a√±ade al `log entry` estructurado.

    ```python
    user_id = 123
    item_id = "XYZ789"
    logger.info(
        "item_added_to_cart", # 'event' o nombre del mensaje
        user_id=user_id, 
        item_id=item_id,
        quantity=2,
        source_ip="192.168.1.50"
    )
    # Output JSON (simplificado):
    # {"event": "item_added_to_cart", "user_id": 123, "item_id": "XYZ789", 
    #  "quantity": 2, "source_ip": "192.168.1.50", "level": "info", "timestamp": "..."}
    ```
*   **`Context Binding` para `Request-Scoped Logging` (La Magia de `bind` y `contextvars`):**\
    A menudo quieres que _todos_ los `logs` dentro del `scope` de un `request` HTTP (o cualquier otra unidad de trabajo) incluyan `metadata` com√∫n como un `request_id`. `structlog` lo facilita con `bind_contextvars` y `clear_contextvars`.

    ```python
    # En un middleware de FastAPI (ver punto 6)
    # import uuid
    # from structlog.contextvars import bind_contextvars, clear_contextvars

    # request_id = str(uuid.uuid4())
    # bind_contextvars(request_id=request_id, client_host=request.client.host)

    # # ... luego, en cualquier parte de tu c√≥digo que se ejecute en este contexto de request ...
    # logger_interno = structlog.get_logger("mi_modulo_interno")
    # logger_interno.info("procesando_datos") 
    # # Este log autom√°ticamente incluir√° request_id y client_host

    # # Al final del request, en el middleware:
    # clear_contextvars()
    ```
*   **Registrando Excepciones:**`logger.exception("mensaje_descriptivo")` (o `logger.error("mensaje", exc_info=True)`) autom√°ticamente captura y formatea la informaci√≥n de la excepci√≥n actual, incluyendo el `stack trace`.

    ```python
    # try:
    #     # ... algo que podr√≠a fallar ...
    #     result = 10 / 0
    # except ZeroDivisionError:
    #     logger.exception("division_by_zero_error", dividend=10)
    # # Output JSON incluir√° 'exception', 'exc_info' con el stack trace.
    ```

**5. Integraci√≥n Profunda con FastAPI: `Middleware` para Contexto Autom√°tico üõÇ**

Un `middleware` es el lugar perfecto para a√±adir contexto de `request` a tus `logs` autom√°ticamente.

```python
# app/middleware/logging_middleware.py
import time
import uuid
from fastapi import Request, Response
from starlette.middleware.base import BaseHTTPMiddleware, RequestResponseEndpoint
from structlog.contextvars import bind_contextvars, clear_contextvars, get_contextvars
import structlog

logger = structlog.get_logger("app.middleware")

class StructuredLoggingMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next: RequestResponseEndpoint) -> Response:
        # Limpiar contexto de un request anterior (por si acaso, aunque FastAPI deber√≠a manejar esto)
        clear_contextvars()
        
        # Generar/Obtener Request ID (ej. de header X-Request-ID o generar uno nuevo)
        request_id = request.headers.get("X-Request-ID", str(uuid.uuid4()))
        
        # Bindear contexto inicial
        bind_contextvars(
            request_id=request_id,
            client_ip=request.client.host if request.client else "unknown",
            http_method=request.method,
            http_path=request.url.path,
        )

        start_time = time.monotonic()
        
        try:
            logger.info("request_started") # Log inicial con el contexto ya bindeado
            response = await call_next(request)
            duration_ms = (time.monotonic() - start_time) * 1000
            
            # Bindear informaci√≥n de la respuesta
            bind_contextvars(
                http_status_code=response.status_code,
                response_duration_ms=round(duration_ms, 2)
            )
            logger.info("request_finished")
            
        except Exception as e:
            # Loggear la excepci√≥n antes de que sea manejada por los exception_handlers de FastAPI
            # (o despu√©s, dependiendo de c√≥mo quieras tu logging de errores)
            # Esto es √∫til si quieres asegurar que CUALQUIER excepci√≥n no capturada se loguee aqu√≠.
            bind_contextvars(http_status_code=500) # Asumir 500 si no se maneja
            logger.exception("unhandled_exception_in_request")
            raise e # Re-lanzar para que FastAPI la maneje
        finally:
            # Importante: Limpiar el contexto para el siguiente request
            # Esto es especialmente crucial si el mismo worker de Uvicorn maneja m√∫ltiples requests.
            logger.info("request_context_cleared", context_vars_before_clear=get_contextvars()) # Log opcional para debug
            clear_contextvars()
            
        return response

# En main.py:
# from app.middleware.logging_middleware import StructuredLoggingMiddleware
# app.add_middleware(StructuredLoggingMiddleware)
```

Con este `middleware`, cualquier `logger = structlog.get_logger()` llamado dentro de un `endpoint` o servicio invocado por ese `request` heredar√° autom√°ticamente el `request_id`, `client_ip`, etc.

**6. `Processors`: El Coraz√≥n de la Personalizaci√≥n de `structlog` ‚öôÔ∏è**

El `pipeline` de `processors` es donde `structlog` realmente brilla. Cada `log event` (un `dict` en `structlog`) pasa a trav√©s de esta cadena de funciones. Cada funci√≥n puede modificar el `dict` del `event`, a√±adir o quitar `keys`, o formatear valores.

* **Diagrama `Mermaid` del `Processor Pipeline` (Conceptual):**

**7. `Output`: De la Consola Amigable al `JSON` Listo para Producci√≥n üñ•Ô∏è‚û°Ô∏èüíæ**

* **Desarrollo:** `structlog.dev.ConsoleRenderer(colors=True)` es tu amigo. Hace los `logs` legibles y agradables en la terminal.
* **Producci√≥n:** `structlog.processors.JSONRenderer()` (o `structlog.twisted.JSONRenderer` si usas Twisted) es esencial. Genera `strings` `JSON` que pueden ser f√°cilmente ingeridos, indexados y buscados por sistemas de `log management` como ELK Stack (Elasticsearch, Logstash, Kibana), Grafana Loki, Splunk, Datadog, etc. (Tema 15.9).

**8. Trazabilidad (`Traceability`) Mejorada con `Logging` Estructurado üìà**

Cuando cada `log entry` en todo tu sistema distribuido (a trav√©s de m√∫ltiples `microservices`) incluye `IDs` consistentes como:

* **`trace_id`:** Un ID que sigue una petici√≥n completa a trav√©s de todos los servicios que toca.
* **`request_id`:** Un ID para una petici√≥n espec√≠fica a un servicio.
* **`user_id`, `tenant_id`, `order_id`, etc.:** Identificadores de negocio relevantes.

... entonces, en tu sistema de `log aggregation`, puedes buscar por estos `IDs` y reconstruir la historia completa de una interacci√≥n, ver c√≥mo fluy√≥ a trav√©s de los servicios, y depurar problemas de forma mucho m√°s eficiente. `structlog` facilita la adici√≥n de estos campos de forma consistente.

**Conclusi√≥n: `structlog` Como Tu Narrador Inteligente para un Sistema Observable üßê**

El `logging` estructurado con `structlog` no es solo una "mejora"; es una transformaci√≥n fundamental en c√≥mo entiendes y operas tus `microservices` FastAPI. Convierte tus `logs` de un simple flujo de texto en una **rica fuente de datos estructurados y consultables.**

* Facilita dr√°sticamente la **depuraci√≥n (`debugging`)** y el **an√°lisis de causa ra√≠z (`root cause analysis`)**.
* Es un pilar para la **monitorizaci√≥n (`monitoring`)**, la creaci√≥n de **alertas (`alerting`)** y el **an√°lisis de comportamiento (`analytics`)**.
* Mejora enormemente la **trazabilidad (`traceability`)** en sistemas distribuidos.

Invertir en una configuraci√≥n de `logging` estructurado s√≥lida con `structlog` desde el principio es una de las mejores inversiones que puedes hacer para la `observability` y mantenibilidad a largo plazo de tu aplicaci√≥n.

***

### 15.8 M√©tricas con Prometheus y Grafana

Continuamos con el **15.8**, y prestar√© especial atenci√≥n para que los diagramas `Mermaid` est√©n formateados correctamente para su correcta visualizaci√≥n en `Markdown`.

Si el `logging` estructurado (15.7) nos da la bit√°cora detallada de los eventos en nuestros `microservices`, las **m√©tricas** nos ofrecen el panel de instrumentos: una visi√≥n cuantitativa y agregada del rendimiento y la salud de nuestro sistema en tiempo real. Para esto, **Prometheus** y **Grafana** forman un d√∫o incre√≠blemente popular y potente.

***

En un sistema de `microservices` distribuido, simplemente saber que los servicios "funcionan" no es suficiente. Necesitamos entender _c√≥mo_ est√°n funcionando: ¬øest√°n respondiendo r√°pidamente? ¬øCu√°ntos `requests` est√°n manejando? ¬øCu√°ntos errores est√°n ocurriendo? ¬øEst√°n consumiendo demasiados recursos? Las **m√©tricas (`metrics`)** nos proporcionan estas respuestas cuantitativas, y **Prometheus** junto con **Grafana** son herramientas est√°ndar de la industria para recolectarlas y visualizarlas.

**1. ¬øPor Qu√© M√©tricas? M√°s All√° de los `Logs` ‚Äì Cuantificando el Comportamiento üìä**

Mientras que los `logs` (como los de `structlog`) nos dan informaci√≥n detallada sobre eventos espec√≠ficos (el "qu√©, cu√°ndo y d√≥nde" de un suceso), las m√©tricas nos ofrecen una visi√≥n agregada y num√©rica del comportamiento del sistema a lo largo del tiempo.

* **Beneficios Clave de las M√©tricas:**
  * **Monitorizaci√≥n del Rendimiento en Tiempo Real (`Real-time Performance Monitoring`):** Ver latencias, `throughput` (`requests` por segundo), tasas de error.
  * **Alertas (`Alerting`):** Configurar alertas cuando las m√©tricas exceden umbrales cr√≠ticos (ej. latencia > 500ms, tasa de error > 5%). Prometheus tiene un `Alertmanager` para esto.
  * **`Capacity Planning`:** Entender el uso de recursos (`CPU`, memoria, `network`) y predecir cu√°ndo se necesitar√° m√°s capacidad.
  * **Identificaci√≥n de Tendencias y Anomal√≠as:** Detectar degradaciones de rendimiento o comportamientos inusuales a lo largo del tiempo.
  * **`Debugging` y `Troubleshooting`:** Correlacionar picos en m√©tricas con `deployments` o incidentes.
  * **Informes de Nivel de Servicio (`SLIs/SLOs`):** Medir y reportar sobre los objetivos de nivel de servicio.

**2. Prometheus: El Recolector de M√©tricas `Time-Series` ‚è∞**

* **¬øQu√© es Prometheus?**\
  Es un sistema de monitorizaci√≥n y alerta `open-source` originalmente construido en SoundCloud, ahora un proyecto graduado de la CNCF. Est√° dise√±ado para la fiabilidad y la escalabilidad.
* **Modelo de Datos:**\
  Prometheus recolecta m√©tricas como **`time series`**: flujos de valores `timestamped` pertenecientes a la misma m√©trica y al mismo conjunto de `labels` (pares clave-valor que dimensionan la m√©trica).
  * Ejemplo: `http_requests_total{method="POST", handler="/api/v1/items", status_code="201"} 1027`
* **Arquitectura `Pull-Model`:**
  * Tus aplicaciones (o `exporters` especializados) exponen sus m√©tricas en un `endpoint` HTTP (generalmente `/metrics`) en un formato espec√≠fico que Prometheus puede entender.
  * El servidor Prometheus est√° configurado para "raspar" (`scrape`) estos `endpoints` a intervalos regulares para recolectar las m√©tricas.
* **Tipos de M√©tricas Principales en Prometheus:**
  1. **`Counter`:** Un valor que solo puede incrementarse (o resetearse a cero en un reinicio). Ideal para contar el n√∫mero total de `requests`, errores, tareas completadas.
     * Ejemplo: `http_requests_total`, `database_errors_total`.
  2. **`Gauge`:** Un valor num√©rico que puede subir y bajar arbitrariamente. Ideal para m√©tricas que representan un valor instant√°neo.
     * Ejemplo: `cpu_usage_percent`, `memory_in_use_bytes`, `active_websocket_connections`.
  3. **`Histogram`:** Muestra la distribuci√≥n de observaciones (ej. latencias de `request`). Agrupa las observaciones en `buckets` configurables y tambi√©n expone una suma (`_sum`) y un conteo (`_count`) de todas las observaciones. Permite calcular cuantiles (ej. percentil 95 de latencia).
     * Ejemplo: `http_request_duration_seconds_bucket{le="0.5"}` (n√∫mero de `requests` que tardaron <= 0.5s).
  4. **`Summary`:** Similar al `histogram`, tambi√©n observa eventos y calcula cuantiles configurables directamente en el lado del `client` (la aplicaci√≥n que expone las m√©tricas). M√°s costoso para el `client`, pero los cuantiles son m√°s precisos.
     * (Los `Histograms` son generalmente preferidos sobre los `Summaries` para la agregaci√≥n en el `server` Prometheus).

**3. Instrumentando Tu Aplicaci√≥n FastAPI para Prometheus Instrumented**

Para que Prometheus pueda recolectar m√©tricas de tu aplicaci√≥n FastAPI, necesitas "instrumentarla", es decir, a√±adir c√≥digo que exponga esas m√©tricas. La librer√≠a cliente oficial de Python para Prometheus es `prometheus_client`. Existen tambi√©n integraciones espec√≠ficas para `frameworks` como FastAPI.

*   **Instalaci√≥n:**

    ```bash
    pip install prometheus_client prometheus-fastapi-instrumentator
    ```

    (`prometheus-fastapi-instrumentator` es una librer√≠a muy √∫til que autom√°ticamente instrumenta muchos aspectos de FastAPI).
*   **Uso B√°sico de `prometheus-fastapi-instrumentator`:**\
    Esta librer√≠a puede a√±adir autom√°ticamente m√©tricas est√°ndar de `request` (latencia, conteos) y un `endpoint` `/metrics`.

    ```python
    # app/main.py
    from fastapi import FastAPI
    from prometheus_fastapi_instrumentator import Instrumentator # Importar

    app = FastAPI()

    # Aplicar el instrumentador a la app
    # Esto expondr√° un endpoint /metrics por defecto
    Instrumentator().instrument(app).expose(app) 

    @app.get("/")
    async def root():
        return {"message": "Hello World"}

    @app.get("/items/{item_id}")
    async def read_item(item_id: int, q: str = None):
        # Simular algo de trabajo
        import time, random
        await asyncio.sleep(random.uniform(0.01, 0.1))
        if item_id == 99:
            raise HTTPException(status_code=500, detail="Simulated error")
        return {"item_id": item_id, "q": q}
    ```

    * Con esto, si visitas `/metrics` en tu `app` FastAPI, ver√°s m√©tricas como `http_requests_total`, `http_request_duration_seconds_bucket`, etc., listas para ser `scrapeadas` por Prometheus.
*   **M√©tricas Personalizadas (`Custom Metrics`):**\
    Puedes definir tus propias m√©tricas para aspectos espec√≠ficos de tu aplicaci√≥n.

    ```python
    # from prometheus_client import Counter, Gauge, Histogram

    # # Definir m√©tricas personalizadas (globalmente o en un m√≥dulo)
    # ORDERS_CREATED_TOTAL = Counter(
    #     "my_app_orders_created_total",
    #     "Total number of orders created."
    # )
    # ACTIVE_USERS_GAUGE = Gauge(
    #     "my_app_active_users",
    #     "Number of currently active users."
    # )
    # PAYMENT_PROCESSING_DURATION_SECONDS = Histogram(
    #     "my_app_payment_processing_duration_seconds",
    #     "Histogram of payment processing duration in seconds."
    # )

    # # En tu l√≥gica de servicio o endpoint:
    # async def process_new_order(order_data):
    #     # ... l√≥gica para crear la orden ...
    #     ORDERS_CREATED_TOTAL.inc() # Incrementar el counter
    #     # ...

    # async def track_active_users():
    #     # ACTIVE_USERS_GAUGE.set(current_active_user_count)
    #     # O .inc() / .dec() si es m√°s apropiado
    #     pass

    # async def process_payment():
    #     # start_time = time.monotonic()
    #     # ... l√≥gica de pago ...
    #     # duration = time.monotonic() - start_time
    #     # PAYMENT_PROCESSING_DURATION_SECONDS.observe(duration)
    #     pass
    ```

**4. Grafana: El Lienzo para Visualizar Tus M√©tricas üé®**

* **¬øQu√© es Grafana?**\
  Es una plataforma `open-source` l√≠der para la anal√≠tica y visualizaci√≥n interactiva de `time-series data`. Se integra perfectamente con Prometheus (y muchas otras `datasources`).
* **C√≥mo Funciona con Prometheus:**
  1. Configuras Prometheus como una `datasource` en Grafana.
  2. Creas `dashboards` en Grafana.
  3. En cada `panel` del `dashboard`, escribes `queries` en **PromQL** (el `query language` de Prometheus) para seleccionar y agregar las m√©tricas que quieres visualizar (ej. gr√°ficos de l√≠neas, `gauges`, `stat panels`, tablas).
* **Visualizaciones Comunes:**
  * Tasa de `requests` (usando `rate(http_requests_total[5m])`).
  * Tasa de errores (ej. `rate(http_requests_total{status_code=~"5.."}[5m]) / rate(http_requests_total[5m])`).
  * Percentiles de latencia (ej. `histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, handler))`).
  * Uso de CPU/Memoria.
  * M√©tricas de negocio personalizadas.

**Diagrama `Mermaid`: Flujo de M√©tricas con Prometheus y Grafana**

```mermaid
graph TD
    subgraph "Aplicaciones FastAPI Instrumentadas"
        App1["FastAPI App 1<br/>(expone /metrics)"]
        App2["FastAPI App 2<br/>(expone /metrics)"]
        AppN["FastAPI App N<br/>(expone /metrics)"]
    end

    subgraph "Sistema de Monitorizaci√≥n"
        Prometheus[Prometheus Server] -- 1. Scrapes /metrics --> App1
        Prometheus -- 1. Scrapes /metrics --> App2
        Prometheus -- 1. Scrapes /metrics --> AppN
        
        Prometheus -- 2. Stores Metrics --> TSDB[(Prometheus Time Series DB)]
        
        TSDB -->|3. Queried by Grafana| Grafana[Grafana Server]
        
        Grafana -- 4. Displays Dashboards --> User[Developer / Operator]
        
        Prometheus -- Manages --> Alertmanager[Alertmanager]
        Alertmanager -- Sends Alerts --> Notifications[Email, Slack, PagerDuty]
    end

    style Prometheus fill:#F44336,stroke:#FFF,color:#FFF
    style Grafana fill:#F9A825,stroke:#FFF,color:#FFF
    style TSDB fill:#4CAF50,stroke:#FFF,color:#FFF
    style Alertmanager fill:#FF9800,stroke:#FFF,color:#000
```

**5. Configuraci√≥n de Prometheus para `Scrape` (Conceptual):**

Prometheus se configura con un archivo `prometheus.yml`:

```yaml
# prometheus.yml (ejemplo muy b√°sico)
global:
  scrape_interval: 15s # Cada cu√°nto hacer scrape por defecto

scrape_configs:
  - job_name: 'fastapi_apps'
    # Aqu√≠ ir√≠a la configuraci√≥n para descubrir tus instancias FastAPI
    # Podr√≠a ser static_configs, o service discovery con Kubernetes, Consul, etc.
    static_configs:
      - targets: ['fastapi_app1_host:8000', 'fastapi_app2_host:8000'] 
        # Si corren localmente o con IPs/DNS conocidos
        # En Kubernetes, se usar√≠a kubernetes_sd_configs
    # metrics_path: '/metrics' # Por defecto ya es /metrics
```

**6. Despliegue en Entornos de `Containers` (Docker, Kubernetes):**

* **Prometheus y Grafana** se despliegan com√∫nmente como `containers` Docker.
* En **Kubernetes**, existen `Helm charts` populares para desplegar una pila completa de monitorizaci√≥n (Prometheus, Grafana, Alertmanager, `node_exporter`, etc.), como `kube-prometheus-stack`.
* La **`Service Discovery`** en Kubernetes permite a Prometheus descubrir autom√°ticamente los `pods` de tu aplicaci√≥n FastAPI que exponen `/metrics` (bas√°ndose en `annotations` o `labels`).

**Conclusi√≥n: M√©tricas como los Ojos y O√≠dos de Tu Sistema en Producci√≥n üëÅÔ∏èüëÇ**

Mientras que los `logs` te cuentan la historia de _lo que pas√≥_, las m√©tricas te muestran _c√≥mo est√° pasando_ en tiempo real y de forma agregada.

* **Prometheus** te da el poder de recolectar y almacenar eficientemente `time-series metrics` de tus `microservices` FastAPI (y de toda tu infraestructura).
* **Grafana** te permite transformar esas m√©tricas en `dashboards` visuales, intuitivos y accionables.
* La instrumentaci√≥n de tu c√≥digo FastAPI con librer√≠as como `prometheus-fastapi-instrumentator` y la definici√≥n de `custom metrics` relevantes para tu negocio son pasos clave.

Esta combinaci√≥n no solo te ayuda a detectar y diagnosticar problemas m√°s r√°pidamente, sino que tambi√©n te proporciona la informaci√≥n necesaria para optimizar el rendimiento, planificar la capacidad y, en √∫ltimaSN instancia, construir sistemas m√°s fiables y robustos. Es un componente esencial de la `observability` moderna.

***

### 15.9 Logs centralizados con ELK o Loki

Si en el 15.7 hablamos de la importancia del `logging` estructurado con `structlog` y en el 15.8 de las m√©tricas con Prometheus y Grafana, ahora en el **15.9** nos enfocaremos en c√≥mo gestionar esos valiosos `logs` cuando provienen de m√∫ltiples `microservices` (o m√∫ltiples instancias de un mismo `microservice`). La soluci√≥n es el **`logging` centralizado**, y nos centraremos principalmente en el **Stack ELK (Elasticsearch, Logstash, Kibana)**, con una menci√≥n a Loki como alternativa.

Imagina que cada `microservice` es un barco en una gran flota, y cada uno lleva su propia bit√°cora (`logs`). Intentar revisar cada bit√°cora individualmente durante una tormenta (un incidente de producci√≥n) es ineficiente. Necesitamos un "Cuartel General de Inteligencia" donde todas las bit√°coras se recopilen, indexen y analicen centralizadamente.

***

A medida que tu arquitectura de `microservices` crece, la cantidad de `logs` generados por cada servicio puede volverse abrumadora. Acceder a cada `server` o `container` individualmente para ver sus `logs` es impr√°ctico para la depuraci√≥n, la monitorizaci√≥n y el an√°lisis de causa ra√≠z. El **`logging` centralizado** resuelve este problema al agregar `logs` de m√∫ltiples fuentes en un √∫nico lugar, haci√©ndolos f√°cilmente buscables y analizables.

El **Stack ELK (Elasticsearch, Logstash, Kibana)** ha sido durante mucho tiempo una soluci√≥n `open-source` incre√≠blemente popular y potente para esto.

**1. ¬øPor Qu√© `Logging` Centralizado? El Poder de la Visi√≥n Unificada üî≠**

* **B√∫squeda y An√°lisis Eficientes:** Busca `logs` de todos tus servicios en un solo lugar usando `queries` potentes. Filtra por `timestamp`, `service name`, `request_id`, `user_id`, nivel de `log`, etc. (¬°Aqu√≠ es donde el `logging` estructurado del 15.7 realmente brilla!).
* **Correlaci√≥n de `Events` entre Servicios:** Sigue un `trace_id` o `request_id` a trav√©s de m√∫ltiples `microservices` para entender un flujo de usuario completo o diagnosticar problemas distribuidos.
* **`Dashboards` y Visualizaciones:** Crea `dashboards` (en Kibana) para visualizar tendencias en los `logs`, tasas de error, `patterns` de `log`, etc.
* **Alertas Basadas en `Logs`:** Configura alertas si ciertos patrones de `error` aparecen o si el volumen de ciertos `logs` excede umbrales.
* **Retenci√≥n a Largo Plazo y Auditor√≠a:** Almacena `logs` de forma segura para an√°lisis hist√≥ricos o cumplimiento de normativas.

**2. El Stack ELK: Un Tr√≠o Poderoso para Tus `Logs`**

* **E - Elasticsearch:**
  * **Rol:** El coraz√≥n del `stack`. Es un motor de b√∫squeda y anal√≠tica distribuido, altamente escalable, construido sobre Apache Lucene.
  * **Funci√≥n:** Almacena, indexa y hace que los `log data` (que le llegan en formato `JSON` o similar) sean r√°pidamente buscables.
* **L - Logstash (o alternativas como Fluentd, Filebeat):**
  * **Rol:** Un `pipeline` de procesamiento de datos del lado del `server`.
  * **Funci√≥n:** Recopila `logs` de diversas fuentes (`log files`, `network protocols`, `message brokers`), los **transforma** (`parsea` `strings` no estructurados, enriquece con `metadata` como `geolocation` a partir de una IP, filtra `fields`), y los **env√≠a** a un `stash` (almac√©n), que t√≠picamente es Elasticsearch.
  * **Alternativa Com√∫n (Beats):** A menudo, se usan agentes m√°s ligeros llamados **`Beats`** (especialmente **`Filebeat`**) en los `servers` de aplicaci√≥n para recolectar `log files` o `stdout/stderr` de `containers` y enviarlos directamente a Elasticsearch o a un Logstash intermedio para un procesamiento m√°s pesado.
* **K - Kibana:**
  * **Rol:** La interfaz de usuario web para visualizar y explorar los datos almacenados en Elasticsearch.
  * **Funci√≥n:** Permite crear `dashboards` interactivos, buscar y filtrar `logs` con un `query language` (KQL - Kibana Query Language o Lucene query syntax), generar gr√°ficos, mapas, etc.

**Diagrama `Mermaid` del Flujo B√°sico del Stack ELK:**

```mermaid
graph TD
    subgraph Sources["Fuentes de Logs: Microservicios FastAPI"]
        MS1["FastAPI Microservice 1 (Containerized)"] --> Agent1["Agent: Filebeat / Fluentd"]
        MS2["FastAPI Microservice 2 (Containerized)"] --> Agent2["Agent: Filebeat / Fluentd"]
        MS3["Otros Microservicios"] --> Agent3["Otros Agents"]
    end

    Agent1 --> Ingest[Logstash / Ingest Node]
    Agent2 --> Ingest
    Agent3 --> Ingest

    subgraph Pipeline["Procesamiento y Almacenamiento"]
        Ingest --> ES["Elasticsearch Cluster: Indexing y Storage"]
    end

    subgraph Visual["Visualizaci√≥n y An√°lisis"]
        ES --> Kibana["Kibana: Dashboards y Discover"]
        User["Usuario: Dev / Ops"] --> Kibana
    end

    style MS1 fill:#D5F5E3,stroke:#2ECC71
    style MS2 fill:#D5F5E3,stroke:#2ECC71
    style MS3 fill:#D5F5E3,stroke:#2ECC71
    style Agent1 fill:#AED6F1,stroke:#3498DB
    style Agent2 fill:#AED6F1,stroke:#3498DB
    style Agent3 fill:#AED6F1,stroke:#3498DB
    style Ingest fill:#FAD7A0,stroke:#F39C12
    style ES fill:#F44336,stroke:#FFF,color:#FFF
    style Kibana fill:#82E0AA,stroke:#1E8449

```

**3. Configurando Tu Aplicaci√≥n FastAPI para `Logging` Centralizado con ELK:**

El `logging` estructurado que configuramos con `structlog` en 15.7 es el **prerrequisito fundamental**.

1.  **Asegurar `Logs` Estructurados en `JSON` en Producci√≥n:**\
    Tu configuraci√≥n de `structlog` (o la que elijas) debe estar produciendo `logs` en formato `JSON` a `stdout/stderr` cuando tu aplicaci√≥n FastAPI corre dentro de un `container`.

    ```python
    # En tu logging_config.py o main.py, como vimos en 15.7:
    # if settings.JSON_LOGS: # Variable de entorno para producci√≥n
    #     processors = shared_processors + [
    #         structlog.stdlib.ProcessorFormatter.wrap_for_formatter,
    #     ]
    #     formatter = structlog.stdlib.ProcessorFormatter.beta_get_formatter(
    #         structlog.processors.JSONRenderer()
    #     )
    #     # ... configurar el root logger para usar este formatter ...
    ```
2. **Recolecci√≥n de `Logs` de `Containers`:**
   * **Est√°ndar de Oro:** Configura tus `containers` Docker (y tu orquestador como Kubernetes) para que los `logs` de `stdout` y `stderr` de tus aplicaciones sean gestionados por el `Docker logging driver`.
   * **Agentes Recolectores (`Log Shippers`):**
     * **`Filebeat` (Parte del Elastic Stack):** Es un agente ligero que se instala en tus `hosts` (o se ejecuta como un `DaemonSet` en Kubernetes en cada `node`, o como un `sidecar container` en un `Pod`) para recolectar `log files` o `container logs` y enviarlos a Logstash o directamente a Elasticsearch.
     * **`Fluentd` / `Fluent Bit`:** Alternativas `open-source` muy populares y potentes, tambi√©n proyectos de la CNCF. `Fluent Bit` es a√∫n m√°s ligero.
3. **Configuraci√≥n de Logstash (Si se usa para `Parsing` y Enriquecimiento):**\
   Defines un `pipeline` en Logstash (ej. `logstash.conf`) que:
   * **Input:** Recibe `logs` de `Beats` (ej. `input { beats { port => 5044 } }`).
   *   **Filter:** `Parsea` los `logs` (si no vienen ya en `JSON` perfecto), extrae `fields`, a√±ade `metadata` (ej. `tags`, `geolocalizaci√≥n` a partir de IPs), transforma datos. El `filter` `json` es √∫til si tus `logs` son `JSON strings`.

       ```conf
       # filter {
       #   if [message] =~ /^{.*}$/ { # Si el mensaje parece JSON
       #     json {
       #       source => "message" # Parsea el campo 'message'
       #       target => "log_event" # Guarda el JSON parseado en 'log_event'
       #     }
       #     # Mover campos de log_event al nivel ra√≠z si se desea
       #     # mutate { rename => { "[log_event][event]" => "event" } }
       #   }
       #   # Otros filtros: grok para parsear texto no estructurado, date para parsear timestamps, etc.
       # }
       ```
   *   **Output:** Env√≠a los `logs` procesados a Elasticsearch.

       ```conf
       # output {
       #   elasticsearch {
       #     hosts => ["http://elasticsearch_host:9200"]
       #     index => "fastapi-logs-%{+YYYY.MM.dd}" # Crear √≠ndices diarios
       #   }
       # }
       ```
4. **Elasticsearch: Indexaci√≥n y B√∫squeda:**\
   Elasticsearch autom√°ticamente indexa los `documents` (tus `log entries`) que recibe, haci√©ndolos buscables. La creaci√≥n de `index patterns` en Kibana es necesaria para decirle a Kibana c√≥mo encontrar y mostrar tus `logs`.
5. **Kibana: Visualizaci√≥n y Exploraci√≥n:**
   * **`Discover`:** La herramienta principal en Kibana para buscar, filtrar y explorar tus `logs` en tiempo real o hist√≥ricamente. Usas KQL o Lucene `query syntax`.
   * **`Dashboards`:** Crea visualizaciones (gr√°ficos de barras, l√≠neas, tartas, tablas, mapas) a partir de tus `log data` para monitorizar tendencias, tasas de error, etc.
   * **`Alerting`:** Kibana (o Elasticsearch X-Pack `features`) permite configurar alertas basadas en `queries` sobre tus `logs`.

**Una Alternativa M√°s Ligera: Grafana Loki ü¶é**

Mientras que ELK es extremadamente potente, tambi√©n puede ser complejo y consumir bastantes recursos. **Grafana Loki** es un sistema de agregaci√≥n de `logs` inspirado en Prometheus, dise√±ado para ser:

* **M√°s Eficiente en Costes:** Indexa solo `metadata` (`labels`) sobre tus `logs` (como `service_name`, `level`, `request_id`), no el contenido completo del `log message`. Esto reduce dr√°sticamente las necesidades de almacenamiento e indexaci√≥n.
* **Integrado con Grafana:** Usa Grafana para `querying` (con `LogQL`) y visualizaci√≥n, igual que con Prometheus.
* **F√°cil de Operar:** Generalmente m√°s simple de desplegar y gestionar que el `stack` ELK completo.
* **Agentes Recolectores:** `Promtail` es el agente oficial para Loki (similar a `Filebeat`). Tambi√©n puede recibir `logs` de `Fluentd/Fluent Bit`.

**Flujo con Loki:**`Microservice Logs -> Promtail -> Loki -> Grafana (con LogQL)`

Loki es una excelente opci√≥n si ya usas Prometheus y Grafana para m√©tricas y quieres una soluci√≥n de `logging` m√°s ligera y bien integrada, especialmente si tu principal caso de uso es la correlaci√≥n de `logs` con `metrics` y el `debugging` basado en `labels`.

**Desaf√≠os y Consideraciones:**

* **Volumen de `Logs` y Coste de Almacenamiento:** Los `logs` pueden crecer muy r√°pido. Necesitas pol√≠ticas de retenci√≥n y considerar el coste de almacenamiento y procesamiento (especialmente con ELK).
* **`Parsing` y Normalizaci√≥n:** Si tus `logs` no son 100% `JSON` estructurado desde el origen, el `parsing` en Logstash/Fluentd puede ser complejo. `structlog` ayuda enormemente aqu√≠.
* **Rendimiento del `Stack` de `Logging`:** El sistema de `logging` centralizado en s√≠ mismo debe ser performante y escalable para no convertirse en un cuello de botella.
* **Seguridad:** Proteger el acceso a tu `stack` ELK/Loki y los datos de `log` que contiene.

**Conclusi√≥n: Dando Sentido al Diluvio de `Logs` con Centralizaci√≥n Inteligente üåä‚û°Ô∏èüèûÔ∏è**

El `logging` centralizado es indispensable para la `observability` en arquitecturas de `microservices`.

* El **Stack ELK** es una soluci√≥n `feature-rich` y probada en batalla para la ingesta, almacenamiento, b√∫squeda y visualizaci√≥n de `logs` a gran escala.
* **Grafana Loki** ofrece una alternativa m√°s ligera y eficiente en costes, especialmente si ya est√°s en el ecosistema Grafana/Prometheus.

La clave del √©xito, independientemente de la herramienta, es **producir `logs` estructurados y ricos en contexto** desde tus `microservices` FastAPI (gracias a `structlog`). Esto es lo que realmente desbloquea el poder de tu sistema de `logging` centralizado, permiti√©ndote transformar un torrente de `log data` en `insights` accionables y una comprensi√≥n profunda del comportamiento de tu sistema.

***

### 15.10 Rollout y rollback autom√°tico

Con el **15.10** cerramos este m√≥dulo sobre despliegues, enfoc√°ndonos en c√≥mo hacer que la entrega de nuevas versiones sea un proceso fluido y, crucialmente, c√≥mo recuperarnos r√°pidamente si algo sale mal. Hablaremos de estrategias de **`rollout` (despliegue progresivo)** y la importancia del **`rollback` autom√°tico (o semi-autom√°tico)**.

Y despu√©s, como solicitaste, una conclusi√≥n para el Tema 15 y una bibliograf√≠a concisa y espec√≠fica para este tema.

***

Desplegar nuevo c√≥digo en producci√≥n siempre conlleva un riesgo inherente, por muy exhaustivas que hayan sido nuestras pruebas. El objetivo de las estrategias modernas de `rollout` y `rollback` es minimizar este riesgo, asegurar una transici√≥n suave para los usuarios y permitir una recuperaci√≥n r√°pida en caso de problemas. La automatizaci√≥n es clave.

**1. `Rollout` y `Rollback`: Conceptos Fundamentales del Despliegue Moderno üöÄüîÑ**

* **`Rollout` (Despliegue Progresivo):** Es el proceso de introducir una nueva versi√≥n de tu aplicaci√≥n (ej. una nueva `Docker image` de tu `microservice` FastAPI) en un entorno (ej. `staging`, producci√≥n). En lugar de un "big bang" donde todo se actualiza de golpe, las estrategias modernas buscan hacerlo de forma gradual y controlada.
* **`Rollback` (Reversi√≥n):** Si una nueva versi√≥n desplegada resulta ser defectuosa (introduce `bugs`, degrada el rendimiento, causa errores), el `rollback` es el proceso de volver a la √∫ltima versi√≥n estable conocida de la aplicaci√≥n.
* **La Importancia de la Automatizaci√≥n:**
  * **Velocidad y Frecuencia:** Permite desplegar m√°s a menudo y con menos esfuerzo manual.
  * **Fiabilidad y Consistencia:** Reduce el error humano inherente a los procesos manuales.
  * **Recuperaci√≥n R√°pida (`MTTR - Mean Time To Recover`):** Un `rollback` r√°pido y automatizado minimiza el impacto de un despliegue fallido.

**2. Estrategias de `Rollout` en Kubernetes (Habilitando la Automatizaci√≥n):**

Kubernetes, como orquestador, ofrece varias estrategias de `deployment` que facilitan los `rollouts` controlados:

* **1. `Rolling Update` (El Est√°ndar Progresivo de K8s):**
  * **C√≥mo Funciona:** Es la estrategia por defecto para los `Deployments` en Kubernetes. Reemplaza gradualmente las instancias (`Pods`) de la versi√≥n antigua de tu aplicaci√≥n con instancias de la nueva versi√≥n, una a una o en lotes.
  * **Par√°metros Clave en el `Deployment YAML`:**
    * `spec.strategy.type: RollingUpdate`
    * `spec.strategy.rollingUpdate.maxUnavailable`: Cu√°ntos `Pods` pueden estar no disponibles durante la actualizaci√≥n (n√∫mero o porcentaje).
    * `spec.strategy.rollingUpdate.maxSurge`: Cu√°ntos `Pods` adicionales se pueden crear por encima del n√∫mero deseado de r√©plicas durante la actualizaci√≥n.
  * **Ventajas:** `Zero downtime` si se configura correctamente, despliegue gradual.
  * **Desventajas:** El `rollback` puede ser un poco m√°s lento que en `Blue/Green`. Durante el `update`, ambas versiones (antigua y nueva) est√°n corriendo y sirviendo tr√°fico.
  * **Diagrama `Mermaid` de `Rolling Update`:**
* **2. `Blue/Green Deployment` (El Clon Seguro):**
  * **C√≥mo Funciona:** Mantienes dos entornos de producci√≥n id√©nticos: "Blue" (con la versi√≥n actual en vivo) y "Green" (donde despliegas la nueva versi√≥n). Todo el tr√°fico va inicialmente a Blue.
  * Despliegas la nueva versi√≥n en el entorno Green y realizas pruebas.
  * Cuando Green est√° verificado, cambias el `router` (ej. `K8s Service selector`, `DNS`, `load balancer`) para que todo el tr√°fico apunte a Green. Green se convierte en el nuevo Blue.
  * El entorno Blue original se mantiene por un tiempo como `backup` para un `rollback` instant√°neo.
  * **Ventajas:** `Rollback` casi instant√°neo (simplemente vuelves a apuntar el tr√°fico a Blue). Sin impacto en la versi√≥n en vivo durante el despliegue de la nueva.
  * **Cons:** Requiere (temporalmente) el doble de infraestructura, lo que puede ser costoso.
  * **Diagrama `Mermaid` de `Blue/Green`:**
*   **3. `Canary Release` (El Explorador Cauteloso):**

    * **C√≥mo Funciona:** Liberas la nueva versi√≥n de la aplicaci√≥n a un peque√±o subconjunto de usuarios o `requests` (el "canario"). Monitorizas de cerca su rendimiento y la tasa de errores.
    * Si el canario funciona bien, aumentas gradualmente el porcentaje de tr√°fico que va a la nueva versi√≥n hasta que el 100% del tr√°fico la est√© usando.
    * Si el canario muestra problemas, haces `rollback` r√°pidamente, afectando solo a ese peque√±o subconjunto de usuarios.
    * **Ventajas:** Exposici√≥n al riesgo muy limitada. `Feedback` del mundo real sobre la nueva versi√≥n antes de un `full rollout`.
    * **Cons:** M√°s complejo de implementar y gestionar el `traffic splitting` (a menudo requiere `service mesh` como Istio/Linkerd, o `features` avanzadas del `API Gateway` o `load balancer`). La monitorizaci√≥n debe ser muy precisa.
    * **Diagrama `Mermaid` de `Canary Release`:**

    **Tabla Comparativa R√°pida de Estrategias de `Rollout`:**

    | Estrategia       | Velocidad `Rollout`  | Riesgo Inicial | Complejidad Infra. | Facilidad `Rollback`  | Impacto Recursos  |
    | ---------------- | -------------------- | -------------- | ------------------ | --------------------- | ----------------- |
    | `Rolling Update` | Moderada             | Moderado       | Baja-Moderada      | Moderada              | Bajo (`maxSurge`) |
    | `Blue/Green`     | R√°pida (el `switch`) | Baja           | Alta (duplicada)   | Muy R√°pida            | Alto              |
    | `Canary`         | Lenta (gradual)      | Muy Baja       | Alta               | R√°pida (para canario) | Moderado          |

**3. El Papel Vital de los `Health Checks`: `Liveness` y `Readiness Probes` ‚ù§Ô∏èü©π**

Para que Kubernetes (y otras herramientas de orquestaci√≥n) puedan automatizar `rollouts` y `rollbacks` de forma efectiva, necesitan saber si tus instancias de aplicaci√≥n est√°n "vivas" y "listas" para servir tr√°fico.

* **`Liveness Probes`:**
  * **Pregunta:** "¬øEst√° tu aplicaci√≥n viva y funcionando (no colgada o en un `deadlock`)?"
  * **Acci√≥n de K8s si falla:** Reinicia el `container`.
  * **FastAPI:** Un `endpoint` simple (ej. `/health/live`) que devuelve `200 OK` si la aplicaci√≥n est√° fundamentalmente operativa.
* **`Readiness Probes`:**
  * **Pregunta:** "¬øEst√° tu aplicaci√≥n lista para aceptar nuevo tr√°fico?" (Ej. ¬øHa terminado de iniciarse? ¬øTiene conexiones a la BBDD? ¬øHa cargado su cach√© inicial?).
  * **Acci√≥n de K8s si falla:** No env√≠a tr√°fico al `Pod` (lo saca temporalmente del `pool` del `Service`). Un `Deployment` no considerar√° un `Pod` de una nueva versi√≥n como "listo" hasta que su `readiness probe` pase.
  * **FastAPI:** Un `endpoint` (ej. `/health/ready`) que verifica dependencias cr√≠ticas.
* **Importancia para `Rollouts`:** Si los `Pods` de una nueva versi√≥n fallan sus `readiness probes` consistentemente, Kubernetes detendr√° el `rolling update` (seg√∫n `spec.progressDeadlineSeconds` en el `Deployment`). Esto es una forma de `rollback` autom√°tico del `rollout` en s√≠ mismo.

**4. Mecanismos de `Rollback` Automatizado (o Semi-Automatizado) ‚è™**

Un `rollout` exitoso no garantiza que no haya `bugs` sutiles. Necesitamos formas de revertir r√°pidamente.

* **Nativo de Kubernetes:**
  * `kubectl rollout undo deployment/<nombre-deployment>`: Comando manual para volver a la revisi√≥n anterior del `Deployment`.
  * `kubectl rollout history deployment/<nombre-deployment>`: Ver el historial.
  * **`Progress Deadline`:** Si un `Deployment` no logra progresar (los nuevos `Pods` no se vuelven `ready`) dentro de `spec.progressDeadlineSeconds`, K8s lo marcar√° como fallido. Esto no hace un `rollback` autom√°tico a la versi√≥n anterior, pero detiene el `rollout` defectuoso.
* **Con Herramientas CI/CD (ej. GitHub Actions - 15.5):**
  * Tu `pipeline` de CD puede incluir `steps` para:
    1. Desplegar la nueva versi√≥n (ej. `kubectl apply` o `helm upgrade`).
    2. Ejecutar `smoke tests` o verificar m√©tricas clave inmediatamente despu√©s.
    3. Si los `smoke tests` fallan o las m√©tricas se degradan significativamente, el `pipeline` puede ejecutar autom√°ticamente `kubectl rollout undo ...` o un comando de `rollback` de Helm.
* **GitOps con Argo CD (Como en 15.6):**
  * **La Forma GitOps Pura:** El `rollback` es tan simple como hacer `git revert` del `commit` que introdujo la nueva versi√≥n en tu `Configuration GitOps Repository`. Argo CD detectar√° este cambio en Git y sincronizar√° el `cluster` de vuelta al estado anterior.
  * **`Rollback` en la UI de Argo CD:** Argo CD mantiene un historial de `syncs` y te permite hacer `rollback` a un estado sincronizado anterior con unos pocos clics.
  * **`Automated Sync Failure Rollback`:** Argo CD puede configurarse para intentar un `rollback` si un `sync operation` falla repetidamente o si la aplicaci√≥n desplegada se reporta como no saludable (`unhealthy`) despu√©s de un `sync`.
* **Basado en Monitorizaci√≥n y Alertas (Prometheus + Alertmanager - 15.8):**\
  Este es el nivel m√°s avanzado de automatizaci√≥n de `rollback`.
  1. Una nueva versi√≥n es desplegada.
  2. Prometheus monitoriza m√©tricas clave (tasa de errores, latencia, `resource usage`).
  3. Si estas m√©tricas exceden umbrales de alerta definidos (Alertmanager), se dispara una alerta.
  4. Esta alerta puede (a trav√©s de un `webhook` o integraci√≥n) `triggerear` un `workflow` automatizado (ej. un `script`, un `job` CI/CD, una acci√≥n en Argo CD) que inicia el `rollback` a la versi√≥n estable anterior.
  5. **Diagrama `Mermaid`: `Rollback` Autom√°tico por Monitorizaci√≥n**

**Conclusi√≥n del Tema 15: Hacia Despliegues `Zero-Downtime`, Resilientes y Confiables üèóÔ∏è‚ú®**

Hemos recorrido un camino completo en este Tema 15, desde la creaci√≥n de `Dockerfiles` eficientes y el versionado sem√°ntico de `images`, pasando por la orquestaci√≥n local con `Docker Compose` y el salto a producci√≥n con Kubernetes, Helm, Kustomize, y la filosof√≠a GitOps con Argo CD. Hemos visto c√≥mo asegurar la `observability` con `logging` estructurado (`structlog`) y m√©tricas (Prometheus/Grafana).

Este √∫ltimo punto sobre **`rollouts` y `rollbacks` autom√°ticos** cierra el ciclo, enfoc√°ndose en c√≥mo entregar `software` no solo de forma continua, sino tambi√©n segura y resiliente.

* Las estrategias de `rollout` de Kubernetes (`RollingUpdate`, `Blue/Green`, `Canary`) te dan el control para introducir cambios gradualmente.
* Los `health checks` (`liveness` y `readiness probes`) son los sensores que le dicen a Kubernetes si tu aplicaci√≥n est√° sana.
* La automatizaci√≥n del `rollback`, ya sea a trav√©s de `scripts` CI/CD, herramientas GitOps como Argo CD, o impulsada por la monitorizaci√≥n, es tu red de seguridad para minimizar el impacto de despliegues problem√°ticos.

El objetivo final es lograr **despliegues `zero-downtime`** que inspiren confianza, permitiendo a tu equipo entregar valor a los usuarios de forma m√°s r√°pida y frecuente, sabiendo que existen mecanismos robustos para gestionar tanto el √©xito como el fracaso. ¬°Es la culminaci√≥n de las buenas pr√°cticas DevOps aplicadas a tus `microservices` FastAPI!

***

## Bibliograf√≠a

1. **Docker Official Documentation:**
   * _Enlace:_ [docs.docker.com](https://docs.docker.com/) (Especialmente "Get Started", "Develop with Docker", "Dockerfile best practices").
   * _Por qu√©:_ Fundamental para entender `Dockerfiles`, `images`, `containers`, y `Docker Compose`. (Relevante para 15.1, 15.3).
2. **Semantic Versioning 2.0.0:**
   * _Enlace:_ [semver.org](https://semver.org/)
   * _Por qu√©:_ La especificaci√≥n oficial para el versionado sem√°ntico. (Relevante para 15.2).
3. **Kubernetes Official Documentation:**
   * _Enlace:_ [kubernetes.io/docs/](https://kubernetes.io/docs/) (Especialmente "Concepts", "Tasks", "Tutorials").
   * _Por qu√©:_ La fuente definitiva para aprender Kubernetes, sus objetos y c√≥mo operar un `cluster`. (Relevante para 15.4, 15.10).
4. **Helm Official Documentation:**
   * _Enlace:_ [helm.sh/docs/](https://helm.sh/docs/)
   * _Por qu√©:_ Para aprender a empaquetar y gestionar aplicaciones Kubernetes con `Charts`. (Relevante para 15.4).
5. **Kustomize Official Documentation:**
   * _Enlace:_ [kustomize.io/](https://kustomize.io/) (y la documentaci√≥n de `kubectl apply -k`).
   * _Por qu√©:_ Para la personalizaci√≥n declarativa de `manifests` Kubernetes. (Relevante para 15.4).
6. **GitHub Actions Documentation:**
   * _Enlace:_ [docs.github.com/en/actions](https://docs.github.com/en/actions)
   * _Por qu√©:_ Para construir `pipelines` CI/CD nativos en GitHub. (Relevante para 15.5).
7. **Argo CD Official Documentation:**
   * _Enlace:_ [argo-cd.readthedocs.io](https://argo-cd.readthedocs.io/)
   * _Por qu√©:_ Gu√≠a completa para implementar GitOps `Continuous Delivery` con Argo CD. (Relevante para 15.6).
8. **`structlog` Official Documentation:**
   * _Enlace:_ [www.structlog.org/en/stable/](https://www.structlog.org/en/stable/)
   * _Por qu√©:_ Para dominar el `logging` estructurado en Python. (Relevante para 15.7).
9. **Prometheus Official Documentation:**
   * _Enlace:_ [prometheus.io/docs/](https://prometheus.io/docs/introduction/overview/)
   * _Por qu√©:_ Para aprender sobre monitorizaci√≥n con Prometheus, PromQL, y `exporters`. (Relevante para 15.8).
10. **Grafana Official Documentation:**
    * _Enlace:_ [grafana.com/docs/grafana/latest/](https://grafana.com/docs/grafana/latest/)
    * _Por qu√©:_ Para crear `dashboards` y visualizar tus m√©tricas (y `logs` si usas Loki). (Relevante para 15.8, 15.9).
11. **Elastic Stack (ELK) Documentation:**
    * _Enlace:_ [www.elastic.co/guide/index.html](https://www.elastic.co/guide/index.html)
    * _Por qu√©:_ Para `logging` centralizado a gran escala con Elasticsearch, Logstash, y Kibana. (Relevante para 15.9).
